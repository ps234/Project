Jan 26 00:11:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 00:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 00:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 00:11:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 00:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 00:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 00:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 00:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 00:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 00:11:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1588, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 00:11:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1588 (ref=pe_calc-dc-1579993864-2027) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:11:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1588 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 00:11:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 00:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 00:26:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 00:26:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 00:26:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 00:26:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 00:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 00:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 00:26:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 00:26:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 00:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 00:26:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1589, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:26:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 00:26:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1589 (ref=pe_calc-dc-1579994764-2028) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:26:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1589 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 00:26:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 00:26:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 00:41:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 00:41:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 00:41:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 00:41:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 00:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 00:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 00:41:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 00:41:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 00:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 00:41:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1590, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:41:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 00:41:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1590 (ref=pe_calc-dc-1579995664-2029) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:41:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1590 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 00:41:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 00:41:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 00:56:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 00:56:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 00:56:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 00:56:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 00:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 00:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 00:56:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 00:56:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 00:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 00:56:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1591, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:56:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 00:56:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1591 (ref=pe_calc-dc-1579996564-2030) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 00:56:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1591 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 00:56:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 00:56:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 01:11:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 01:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 01:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 01:11:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 01:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 01:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 01:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 01:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 01:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 01:11:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1592, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 01:11:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1592 (ref=pe_calc-dc-1579997464-2031) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:11:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1592 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 01:11:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 01:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 01:26:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 01:26:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 01:26:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 01:26:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 01:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 01:26:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 01:26:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 01:26:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 01:26:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 01:26:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1593, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:26:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 01:26:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1593 (ref=pe_calc-dc-1579998364-2032) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:26:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1593 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 01:26:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 01:26:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 01:41:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 01:41:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 01:41:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 01:41:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 01:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 01:41:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 01:41:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 01:41:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 01:41:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 01:41:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1594, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:41:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 01:41:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1594 (ref=pe_calc-dc-1579999264-2033) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:41:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1594 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 01:41:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 01:41:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 01:56:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 01:56:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 01:56:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 01:56:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 01:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 01:56:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 01:56:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 01:56:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 01:56:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 01:56:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1595, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:56:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 01:56:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1595 (ref=pe_calc-dc-1580000164-2034) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 01:56:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1595 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 01:56:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 01:56:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 02:11:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 02:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 02:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 02:11:04 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 02:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 02:11:04 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 02:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 02:11:04 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 02:11:04 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 02:11:04 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1596, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:11:04 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 02:11:04 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1596 (ref=pe_calc-dc-1580001064-2035) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:11:04 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1596 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 02:11:04 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 02:11:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 02:26:04 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 02:26:04 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 02:26:04 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 02:26:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 02:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 02:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 02:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 02:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 02:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 02:26:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1597, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:26:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 02:26:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1597 (ref=pe_calc-dc-1580001965-2036) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:26:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1597 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 02:26:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 02:26:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 02:41:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 02:41:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 02:41:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 02:41:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 02:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 02:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 02:41:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 02:41:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 02:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 02:41:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1598, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:41:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 02:41:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1598 (ref=pe_calc-dc-1580002865-2037) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:41:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1598 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 02:41:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 02:41:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 02:44:41 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 02:56:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 02:56:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 02:56:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 02:56:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 02:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 02:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 02:56:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 02:56:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 02:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 02:56:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1599, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:56:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 02:56:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1599 (ref=pe_calc-dc-1580003765-2038) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 02:56:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1599 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 02:56:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 02:56:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 03:11:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 03:11:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 03:11:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 03:11:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 03:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 03:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 03:11:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 03:11:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 03:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 03:11:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1600, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:11:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 03:11:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1600 (ref=pe_calc-dc-1580004665-2039) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:11:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1600 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 03:11:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 03:11:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 03:26:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 03:26:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 03:26:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 03:26:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 03:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 03:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 03:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 03:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 03:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 03:26:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1601, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:26:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 03:26:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1601 (ref=pe_calc-dc-1580005565-2040) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:26:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1601 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 03:26:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 03:26:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 03:41:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 03:41:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 03:41:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 03:41:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 03:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 03:41:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 03:41:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 03:41:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 03:41:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 03:41:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1602, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:41:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 03:41:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1602 (ref=pe_calc-dc-1580006465-2041) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:41:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1602 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 03:41:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 03:41:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 03:56:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 03:56:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 03:56:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 03:56:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 03:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 03:56:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 03:56:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 03:56:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 03:56:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 03:56:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1603, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:56:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 03:56:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1603 (ref=pe_calc-dc-1580007365-2042) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 03:56:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1603 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 03:56:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 03:56:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:11:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 04:11:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 04:11:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 04:11:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:11:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:11:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:11:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:11:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:11:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:11:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1604 (ref=pe_calc-dc-1580008265-2043) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 04:11:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1604 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 04:11:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:11:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:11:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1604, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 04:14:06 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:14:19 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:14:49 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 163 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:14:49 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/163)
Jan 26 04:14:49 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/163, version=1.575.41)
Jan 26 04:14:49 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 163 for #health-cpu: OK (0)
Jan 26 04:14:49 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 163 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 04:14:54 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 40caba80e2ec3275659774427afbdc2f for 1.575.41 (0x55b8bb736630 0)
Jan 26 04:15:25 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:15:52 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:16:22 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 164 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:16:22 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/164)
Jan 26 04:16:22 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/164, version=1.575.41)
Jan 26 04:16:22 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 164 for #health-cpu: OK (0)
Jan 26 04:16:22 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 164 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 04:16:27 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 40caba80e2ec3275659774427afbdc2f for 1.575.41 (0x55b8bb736630 0)
Jan 26 04:16:32 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:16:58 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:17:28 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 165 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:17:28 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/165)
Jan 26 04:17:28 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/165, version=1.575.41)
Jan 26 04:17:28 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 165 for #health-cpu: OK (0)
Jan 26 04:17:28 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 165 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 04:17:33 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 40caba80e2ec3275659774427afbdc2f for 1.575.41 (0x55b8bb736630 0)
Jan 26 04:26:05 [1594] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jan 26 04:26:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 04:26:05 [1594] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jan 26 04:26:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:26:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:26:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:26:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:26:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1605, saving inputs in /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 04:26:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:26:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1605 (ref=pe_calc-dc-1580009165-2044) derived from /var/lib/pacemaker/pengine/pe-input-498.bz2
Jan 26 04:26:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1605 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-498.bz2): Complete
Jan 26 04:26:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:26:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:36:44 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:36:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:25 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.575.41 2
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.576.0 90384f1ab87b53cd955c76e651e6444a
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/configuration/resources/group[@id='grp_DEV_ci']/primitive[@id='vip_DEV_CI']/meta_attributes[@id='vip_DEV_CI-meta_attributes']
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/configuration/resources/group[@id='grp_DEV_ci']/primitive[@id='rsc_DEV_CI']/meta_attributes[@id='rsc_DEV_CI-meta_attributes']
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=576, @num_updates=0
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/group[@id='grp_DEV_ci']/meta_attributes[@id='grp_DEV_ci-meta_attributes']/nvpair[@id='grp_DEV_ci-meta_attributes-target-role']:  @value=Stopped
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.576.0)
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1605 aborted by deletion of meta_attributes[@id='vip_DEV_CI-meta_attributes']: Configuration change | cib=1.576.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/group[@id='grp_DEV_ci']/primitive[@id='vip_DEV_CI']/meta_attributes[@id='vip_DEV_CI-meta_attributes'] complete=true
Jan 26 04:39:28 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: stonith_device_remove:	Device 'vip_DEV_CI' not found (1 active devices)
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: stonith_device_remove:	Device 'rsc_DEV_CI' not found (1 active devices)
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='grp_DEV_ci-meta_attributes-target-role']
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.576.0
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-77.raw
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.576.0 of the CIB to disk (digest: 8a27aa5462fa92ef085eade82b228cb2)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.rzcXkI (digest: /var/lib/pacemaker/cib/cib.wbh2aC)
Jan 26 04:39:28 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:39:28 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:39:28 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500 (disabled)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500 (disabled)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped (disabled)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:39:28 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:39:28 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_CI cannot run anywhere
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: native_color:	Resource vip_DEV_CI cannot run anywhere
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       fs_DEV_CI              (              vmi243500 )   due to node availability
Jan 26 04:39:28 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       vip_DEV_CI             (              vmi243500 )   due to node availability
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:39:28 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:39:28 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1606, saving inputs in /var/lib/pacemaker/pengine/pe-input-499.bz2
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:39:28 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1606 (ref=pe_calc-dc-1580009968-2045) derived from /var/lib/pacemaker/pengine/pe-input-499.bz2
Jan 26 04:39:28 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation vip_DEV_CI_stop_0 locally on vmi243500 | action 48
Jan 26 04:39:28 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_CI_monitor_10000
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=48:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_CI_stop_0
Jan 26 04:39:28 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:stop call_id:382
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2365)
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: Cancelled | call=380 key=vip_DEV_CI_monitor_10000 confirmed=true
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.576.0 2
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.576.1 (null)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_stop_0, @operation=stop, @transition-key=48:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;48:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580009968, @last-rc-change=1580009968, @exec-time=0
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2365, version=1.576.1)
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.576.1
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:28 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:stop call_id:382 pid:8078 exit-code:0 exec-time:132ms queue-time:0ms
Jan 26 04:39:28 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_CI on vmi243500: 0 (ok) | call=382 key=vip_DEV_CI_stop_0 confirmed=true cib-update=2366
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2366)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.576.1 2
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.576.2 (null)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;48:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=382, @rc-code=0, @op-status=0, @exec-time=132
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2366, version=1.576.2)
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.576.2
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_stop_0 (48) confirmed on vmi243500 (rc=0)
Jan 26 04:39:28 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_CI_stop_0 locally on vmi243500 | action 47
Jan 26 04:39:28 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_CI_monitor_20000
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=47:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_CI_stop_0
Jan 26 04:39:28 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:stop call_id:384
Jan 26 04:39:28 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: Cancelled | call=378 key=fs_DEV_CI_monitor_20000 confirmed=true
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2367)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.576.2 2
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.576.3 (null)
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_stop_0, @operation=stop, @transition-key=47:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;47:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580009968, @last-rc-change=1580009968, @exec-time=0
Jan 26 04:39:28 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2367, version=1.576.3)
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.576.3
Jan 26 04:39:28 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:29 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:30 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:30 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:31 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:31 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:33 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: ab83a5d88fa00745b5340a0575a00ad6 for 1.576.3 (0x55b8bb990120 0)
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ umount: /usr/sap/DEV/DVEBMGS01: target is busy. ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ ocf-exit-reason:Couldn't unmount /usr/sap/DEV/DVEBMGS01; trying cleanup with TERM ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ umount: /usr/sap/DEV/DVEBMGS01: target is busy. ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ ocf-exit-reason:Couldn't unmount /usr/sap/DEV/DVEBMGS01; trying cleanup with TERM ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ umount: /usr/sap/DEV/DVEBMGS01: target is busy. ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ ocf-exit-reason:Couldn't unmount /usr/sap/DEV/DVEBMGS01; trying cleanup with TERM ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ umount: /usr/sap/DEV/DVEBMGS01: target is busy. ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:8128:stderr [ ocf-exit-reason:Couldn't unmount /usr/sap/DEV/DVEBMGS01; trying cleanup with KILL ]
Jan 26 04:39:34 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:stop call_id:384 pid:8128 exit-code:0 exec-time:5485ms queue-time:0ms
Jan 26 04:39:34 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_CI on vmi243500: 0 (ok) | call=384 key=fs_DEV_CI_stop_0 confirmed=true cib-update=2368
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2368)
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.576.3 2
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.576.4 (null)
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;47:1606:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=384, @rc-code=0, @op-status=0, @exec-time=5485
Jan 26 04:39:34 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 04:39:34 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.576.4
Jan 26 04:39:34 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2368, version=1.576.4)
Jan 26 04:39:34 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_stop_0 (47) confirmed on vmi243500 (rc=0)
Jan 26 04:39:34 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1606 (Complete=5, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-499.bz2): Complete
Jan 26 04:39:34 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:39:34 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:39:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:37 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:37 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:39 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: ef1ba6fc26e9d704326df7aae9ac50c9 for 1.576.4 (0x55b8bb990120 0)
Jan 26 04:39:41 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.576.4 2
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.0 (null)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/configuration/resources/group[@id='grp_DEV_database']/primitive[@id='fs_DEV_database']/meta_attributes[@id='fs_DEV_database-meta_attributes']
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=577, @num_updates=0
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/group[@id='grp_DEV_database']/meta_attributes[@id='grp_DEV_database-meta_attributes']/nvpair[@id='grp_DEV_database-meta_attributes-target-role']:  @value=Stopped
Jan 26 04:39:44 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1606 aborted by deletion of meta_attributes[@id='fs_DEV_database-meta_attributes']: Configuration change | cib=1.577.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/group[@id='grp_DEV_database']/primitive[@id='fs_DEV_database']/meta_attributes[@id='fs_DEV_database-meta_attributes'] complete=true
Jan 26 04:39:44 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:     info: stonith_device_remove:	Device 'fs_DEV_database' not found (1 active devices)
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='grp_DEV_database-meta_attributes-target-role']
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.0
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.577.0)
Jan 26 04:39:44 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:39:44 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:39:44 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500 (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500 (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500 (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped (disabled)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:39:44 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:39:44 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_database cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_database: Rolling back scores from rsc_DEV_database
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource vip_DEV_database cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_database cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_CI cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource vip_DEV_CI cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:39:44 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       fs_DEV_database        (              vmi243500 )   due to node availability
Jan 26 04:39:44 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       vip_DEV_database       (              vmi243500 )   due to node availability
Jan 26 04:39:44 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       rsc_DEV_database       (              vmi243500 )   due to node availability
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Stopped)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Stopped)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:39:44 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:39:44 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1607, saving inputs in /var/lib/pacemaker/pengine/pe-input-500.bz2
Jan 26 04:39:44 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:39:44 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1607 (ref=pe_calc-dc-1580009984-2048) derived from /var/lib/pacemaker/pengine/pe-input-500.bz2
Jan 26 04:39:44 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_database_stop_0 locally on vmi243500 | action 23
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-78.raw
Jan 26 04:39:44 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation rsc_DEV_database_monitor_120000
Jan 26 04:39:44 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_stop_0
Jan 26 04:39:44 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:stop call_id:386
Jan 26 04:39:44 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: Cancelled | call=137 key=rsc_DEV_database_monitor_120000 confirmed=true
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2370)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.577.0 of the CIB to disk (digest: fada377516b3c5e9466504505ba02f5e)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.0 2
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.1 (null)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_stop_0, @operation=stop, @transition-key=23:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;23:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580009984, @last-rc-change=1580009
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.TiSv8K (digest: /var/lib/pacemaker/cib/cib.LXPdcg)
Jan 26 04:39:44 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2370, version=1.577.1)
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.1
Jan 26 04:39:44 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:39:44 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:45 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:46 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:46 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:47 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:39:49 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: ed452730986e86538a31a73d0137a22b for 1.577.1 (0x55b8bb9cb810 0)
Jan 26 04:40:33 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:stop call_id:386 pid:8925 exit-code:0 exec-time:49441ms queue-time:0ms
Jan 26 04:40:33 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_database on vmi243500: 0 (ok) | call=386 key=rsc_DEV_database_stop_0 confirmed=true cib-update=2371
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2371)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.1 2
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.2 (null)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;23:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=386, @rc-code=0, @op-status=0, @exec-time=49441
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.2
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_stop_0 (23) confirmed on vmi243500 (rc=0)
Jan 26 04:40:33 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation vip_DEV_database_stop_0 locally on vmi243500 | action 22
Jan 26 04:40:33 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_database_monitor_10000
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_database_stop_0
Jan 26 04:40:33 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:stop call_id:388
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2371, version=1.577.2)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2372)
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: Cancelled | call=135 key=vip_DEV_database_monitor_10000 confirmed=true
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.2 2
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.3 (null)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_stop_0, @operation=stop, @transition-key=22:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;22:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580010033, @last-rc-change=1580010
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2372, version=1.577.3)
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.3
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:40:33 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:stop call_id:388 pid:10692 exit-code:0 exec-time:174ms queue-time:0ms
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2373)
Jan 26 04:40:33 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_database on vmi243500: 0 (ok) | call=388 key=vip_DEV_database_stop_0 confirmed=true cib-update=2373
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.3 2
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.4 (null)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;22:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=388, @rc-code=0, @op-status=0, @exec-time=174
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.4
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2373, version=1.577.4)
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_stop_0 (22) confirmed on vmi243500 (rc=0)
Jan 26 04:40:33 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_database_stop_0 locally on vmi243500 | action 21
Jan 26 04:40:33 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_database_monitor_20000
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_database_stop_0
Jan 26 04:40:33 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:stop call_id:390
Jan 26 04:40:33 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: Cancelled | call=133 key=fs_DEV_database_monitor_20000 confirmed=true
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2374)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.4 2
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.5 (null)
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_stop_0, @operation=stop, @transition-key=21:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;21:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580010033, @last-rc-change=1580010033
Jan 26 04:40:33 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2374, version=1.577.5)
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.5
Jan 26 04:40:33 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:40:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:40:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:40:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:40:36 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:10746:stderr [ umount: /sapdb: target is busy. ]
Jan 26 04:40:36 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:10746:stderr [ ocf-exit-reason:Couldn't unmount /sapdb; trying cleanup with TERM ]
Jan 26 04:40:36 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:10746:stderr [ /usr/lib/ocf/resource.d/heartbeat/Filesystem: line 497: kill: (2072) - No such process ]
Jan 26 04:40:36 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:stop call_id:390 pid:10746 exit-code:0 exec-time:2712ms queue-time:0ms
Jan 26 04:40:36 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_database on vmi243500: 0 (ok) | call=390 key=fs_DEV_database_stop_0 confirmed=true cib-update=2375
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2375)
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.5 2
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.577.6 (null)
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;21:1607:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=390, @rc-code=0, @op-status=0, @exec-time=2712
Jan 26 04:40:36 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 04:40:36 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.577.6
Jan 26 04:40:36 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2375, version=1.577.6)
Jan 26 04:40:36 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:40:36 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_stop_0 (21) confirmed on vmi243500 (rc=0)
Jan 26 04:40:36 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1607 (Complete=6, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-500.bz2): Complete
Jan 26 04:40:36 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:40:36 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:40:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:37 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:37 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:38 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:39 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:39 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:40 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:40:41 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: b80f8707a0d0d84f0adc6fb1e69a8430 for 1.577.6 (0x55b8bb9cb810 0)
Jan 26 04:43:08 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:43:11 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.577.6 2
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.0 0ad2a4549494798b69afaeee60d25458
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=578, @num_updates=0
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/group[@id='grp_DEV_database']/meta_attributes[@id='grp_DEV_database-meta_attributes']/nvpair[@id='grp_DEV_database-meta_attributes-target-role']:  @value=Started
Jan 26 04:43:12 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1607 aborted by grp_DEV_database-meta_attributes-target-role doing modify target-role=Started: Configuration change | cib=1.578.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/group[@id='grp_DEV_database']/meta_attributes[@id='grp_DEV_database-meta_attributes']/nvpair[@id='grp_DEV_database-meta_attributes-target-role'] complete=true
Jan 26 04:43:12 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='grp_DEV_database-meta_attributes-target-role']
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.0
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.578.0)
Jan 26 04:43:12 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:43:12 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:43:12 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-79.raw
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped (disabled)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped (disabled)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped (disabled)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:43:12 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_CI cannot run anywhere
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: native_color:	Resource vip_DEV_CI cannot run anywhere
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243500
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.578.0 of the CIB to disk (digest: 8e9a3a283f20799ed613634b04af9085)
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.0qkBtN (digest: /var/lib/pacemaker/cib/cib.B3wO6l)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:43:12 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        (              vmi243500 )  
Jan 26 04:43:12 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       (              vmi243500 )  
Jan 26 04:43:12 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       (              vmi243500 )  
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Stopped)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Stopped)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:43:12 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:43:12 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1608, saving inputs in /var/lib/pacemaker/pengine/pe-input-501.bz2
Jan 26 04:43:12 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:43:12 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1608 (ref=pe_calc-dc-1580010192-2052) derived from /var/lib/pacemaker/pengine/pe-input-501.bz2
Jan 26 04:43:12 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_database_start_0 locally on vmi243500 | action 18
Jan 26 04:43:12 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=18:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_database_start_0
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2377)
Jan 26 04:43:12 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:start call_id:391
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.0 2
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.1 (null)
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_start_0, @operation=start, @transition-key=18:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;18:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580010192, @last-rc-change=15800101
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.1
Jan 26 04:43:12 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2377, version=1.578.1)
Jan 26 04:43:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:14 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:start call_id:391 pid:14104 exit-code:0 exec-time:2054ms queue-time:0ms
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_database on vmi243500: 0 (ok) | call=391 key=fs_DEV_database_start_0 confirmed=true cib-update=2378
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2378)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.1 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.2 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;18:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=391, @rc-code=0, @op-status=0, @exec-time=2054
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_start_0 (18) confirmed on vmi243500 (rc=0)
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_database_monitor_20000 locally on vmi243500 | action 19
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=19:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_database_monitor_20000
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_database_start_0 locally on vmi243500 | action 20
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=20:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_database_start_0
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.2
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2378, version=1.578.2)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2379)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2380)
Jan 26 04:43:14 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:start call_id:393
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.2 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.3 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-key=19:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;19:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580010194, @exec-time=0
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2379, version=1.578.3)
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.3
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.3 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.4 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_start_0, @operation=start, @transition-key=20:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;20:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580010194, @last-rc-change=15800
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2380, version=1.578.4)
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.4
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: 0 (ok) | call=392 key=fs_DEV_database_monitor_20000 confirmed=false cib-update=2381
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2381)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.4 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.5 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-magic=0:0;19:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=392, @rc-code=0, @op-status=0, @exec-time=163
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2381, version=1.578.5)
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_monitor_20000 (19) confirmed on vmi243500 (rc=0)
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.5
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:start call_id:393 pid:14208 exit-code:0 exec-time:238ms queue-time:0ms
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_database on vmi243500: 0 (ok) | call=393 key=vip_DEV_database_start_0 confirmed=true cib-update=2382
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2382)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.5 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.6 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;20:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=393, @rc-code=0, @op-status=0, @exec-time=238
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.6
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_start_0 (20) confirmed on vmi243500 (rc=0)
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_database_monitor_10000 locally on vmi243500 | action 21
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_database_monitor_10000
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2382, version=1.578.6)
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_database_start_0 locally on vmi243500 | action 22
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_start_0
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2383)
Jan 26 04:43:14 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:start call_id:395
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.6 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.7 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-key=21:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;21:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580010194, @exec-time=0
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.7
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2383, version=1.578.7)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2384)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.7 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.8 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @transition-key=22:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;22:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580010194, @last-rc-change=15800
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.8
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2384, version=1.578.8)
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: 0 (ok) | call=394 key=vip_DEV_database_monitor_10000 confirmed=false cib-update=2385
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2385)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.8 2
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.9 (null)
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-magic=0:0;21:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=394, @rc-code=0, @op-status=0, @exec-time=136, @queue-time=1
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.9
Jan 26 04:43:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:43:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2385, version=1.578.9)
Jan 26 04:43:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_monitor_10000 (21) confirmed on vmi243500 (rc=0)
Jan 26 04:43:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:43:19 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 78e9b5975eb1befef0a5c6dd48820704 for 1.578.9 (0x55b8bb6753f0 0)
Jan 26 04:44:48 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:45:14 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:45:41 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:45:54 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:46:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 26 04:46:21 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:46:34 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:46:47 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:47:14 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:47:44 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 166 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:47:44 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/166)
Jan 26 04:47:44 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/166, version=1.578.9)
Jan 26 04:47:44 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 166 for #health-cpu: OK (0)
Jan 26 04:47:44 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 166 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 04:47:49 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 78e9b5975eb1befef0a5c6dd48820704 for 1.578.9 (0x55b8bb6753f0 0)
Jan 26 04:48:07 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:48:37 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 167 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/167)
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.9 2
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.10 (null)
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 04:48:37 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/167, version=1.578.10)
Jan 26 04:48:37 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1608 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.578.10 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 04:48:37 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 167 for #health-cpu: OK (0)
Jan 26 04:48:37 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 167 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 04:48:38 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:38 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:39 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:40 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:41 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:41 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:48:42 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: a5bec745c8149da75d0d68995aed5aee for 1.578.10 (0x55b8bb6753f0 0)
Jan 26 04:49:13 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:49:26 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:49:39 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:50:06 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 04:50:19 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 04:50:49 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 168 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/168)
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.10 2
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.11 (null)
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 04:50:49 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/168, version=1.578.11)
Jan 26 04:50:49 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 168 for #health-cpu: OK (0)
Jan 26 04:50:49 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1608 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.578.11 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 04:50:49 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 168 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 04:50:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:51 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:52 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:52 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:53 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:50:54 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 9d6d866112a9b0906e43a074864d9993 for 1.578.11 (0x55b8bb6753f0 0)
Jan 26 04:51:36 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 26 04:52:25 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:55:25 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:56:56 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:57:05 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:start call_id:395 pid:14318 exit-code:0 exec-time:830681ms queue-time:0ms
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2386)
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_database on vmi243500: 0 (ok) | call=395 key=rsc_DEV_database_start_0 confirmed=true cib-update=2386
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.11 2
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.12 (null)
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;22:1608:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=395, @rc-code=0, @op-status=0, @exec-time=830681
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2386, version=1.578.12)
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_start_0 (22) confirmed on vmi243500 (rc=0)
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1608 (Complete=7, Pending=0, Fired=0, Skipped=1, Incomplete=1, Source=/var/lib/pacemaker/pengine/pe-input-501.bz2): Stopped
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.12
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:57:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:57:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:57:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped (disabled)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped (disabled)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped (disabled)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:57:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_CI cannot run anywhere
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: native_color:	Resource vip_DEV_CI cannot run anywhere
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Stopped)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Stopped)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:57:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:57:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1609, saving inputs in /var/lib/pacemaker/pengine/pe-input-502.bz2
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1609 (ref=pe_calc-dc-1580011025-2060) derived from /var/lib/pacemaker/pengine/pe-input-502.bz2
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_database_monitor_120000 locally on vmi243500 | action 26
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_monitor_120000
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2388)
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.12 2
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.13 (null)
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-key=26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580011025, @exec-time=0
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.13
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2388, version=1.578.13)
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 0 (ok) | call=396 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=2389
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2389)
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.13 2
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.578.14 (null)
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-magic=0:0;26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=396, @rc-code=0, @op-status=0, @exec-time=103
Jan 26 04:57:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2389, version=1.578.14)
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_monitor_120000 (26) confirmed on vmi243500 (rc=0)
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1609 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-502.bz2): Complete
Jan 26 04:57:05 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.578.14
Jan 26 04:57:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:57:05 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:06 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:06 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:07 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:08 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:08 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:09 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:57:10 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 8a0daa532890433814d6f1b9d89a8047 for 1.578.14 (0x55b8bb6753f0 0)
Jan 26 04:58:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.578.14 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.0 5d836383a01b6c1b290b62a1fe06d1f1
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=579, @num_updates=0
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/group[@id='grp_DEV_ci']/meta_attributes[@id='grp_DEV_ci-meta_attributes']/nvpair[@id='grp_DEV_ci-meta_attributes-target-role']:  @value=Started
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1609 aborted by grp_DEV_ci-meta_attributes-target-role doing modify target-role=Started: Configuration change | cib=1.579.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/group[@id='grp_DEV_ci']/meta_attributes[@id='grp_DEV_ci-meta_attributes']/nvpair[@id='grp_DEV_ci-meta_attributes-target-role'] complete=true
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.579.0)
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='grp_DEV_ci-meta_attributes-target-role']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.0
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:58:16 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:58:16 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:58:16 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243500
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              (              vmi243500 )  
Jan 26 04:58:16 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             (              vmi243500 )  
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:58:16 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1610 (ref=pe_calc-dc-1580011096-2062) derived from /var/lib/pacemaker/pengine/pe-input-503.bz2
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_CI_start_0 locally on vmi243500 | action 45
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=45:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_CI_start_0
Jan 26 04:58:16 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:start call_id:397
Jan 26 04:58:16 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1610, saving inputs in /var/lib/pacemaker/pengine/pe-input-503.bz2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2391)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.0 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.1 (null)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @transition-key=45:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;45:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011096, @last-rc-change=1580011096, @exec-time=0
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2391, version=1.579.1)
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.1
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-80.raw
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.579.0 of the CIB to disk (digest: 0da4bf980718232ff8990c402619020b)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.ZNlPGs (digest: /var/lib/pacemaker/cib/cib.0Dzom3)
Jan 26 04:58:16 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:start call_id:397 pid:6936 exit-code:0 exec-time:333ms queue-time:0ms
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_CI on vmi243500: 0 (ok) | call=397 key=fs_DEV_CI_start_0 confirmed=true cib-update=2392
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2392)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.1 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.2 (null)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;45:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=397, @rc-code=0, @op-status=0, @exec-time=333
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2392, version=1.579.2)
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.2
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_start_0 (45) confirmed on vmi243500 (rc=0)
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_CI_monitor_20000 locally on vmi243500 | action 46
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=46:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_CI_monitor_20000
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2393)
Jan 26 04:58:16 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_CI_start_0 locally on vmi243500 | action 47
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=47:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_CI_start_0
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2394)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.2 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.3 (null)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-key=46:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;46:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580011096, @exec-time=0, @queue-time=0
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2393, version=1.579.3)
Jan 26 04:58:16 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:start call_id:399
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.3 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.4 (null)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @transition-key=47:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;47:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011096, @last-rc-change=1580011096, @exec-time=
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2394, version=1.579.4)
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.3
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.4
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: 0 (ok) | call=398 key=fs_DEV_CI_monitor_20000 confirmed=false cib-update=2395
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2395)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.4 2
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.5 (null)
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;46:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=398, @rc-code=0, @op-status=0, @exec-time=105, @queue-time=1
Jan 26 04:58:16 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2395, version=1.579.5)
Jan 26 04:58:16 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_monitor_20000 (46) confirmed on vmi243500 (rc=0)
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.5
Jan 26 04:58:16 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:17 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:start call_id:399 pid:7003 exit-code:0 exec-time:195ms queue-time:1ms
Jan 26 04:58:17 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_CI on vmi243500: 0 (ok) | call=399 key=vip_DEV_CI_start_0 confirmed=true cib-update=2396
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2396)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.5 2
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.6 (null)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;47:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=399, @rc-code=0, @op-status=0, @exec-time=195, @queue-time=1
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.6
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2396, version=1.579.6)
Jan 26 04:58:17 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_start_0 (47) confirmed on vmi243500 (rc=0)
Jan 26 04:58:17 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_CI_monitor_10000 locally on vmi243500 | action 48
Jan 26 04:58:17 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=48:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_CI_monitor_10000
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2397)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.6 2
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.7 (null)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-key=48:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;48:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580011097, @exec-time=0
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.7
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2397, version=1.579.7)
Jan 26 04:58:17 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: 0 (ok) | call=400 key=vip_DEV_CI_monitor_10000 confirmed=false cib-update=2398
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2398)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.7 2
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.579.8 (null)
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;48:1610:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=400, @rc-code=0, @op-status=0, @exec-time=103
Jan 26 04:58:17 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_monitor_10000 (48) confirmed on vmi243500 (rc=0)
Jan 26 04:58:17 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1610 (Complete=5, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-503.bz2): Complete
Jan 26 04:58:17 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:58:17 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.579.8
Jan 26 04:58:17 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2398, version=1.579.8)
Jan 26 04:58:17 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:58:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:19 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:20 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:20 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:21 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:58:22 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 6fb486614081ae5242e657033f8c90b8 for 1.579.8 (0x55b8bb289bf0 0)
Jan 26 04:59:28 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.579.8 2
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.0 2530e9ae5580c44e68d8517b573305df
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=580, @num_updates=0
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/configuration/resources/group[@id='grp_DEV_ci']/primitive[@id='rsc_DEV_CI']:  <meta_attributes id="rsc_DEV_CI-meta_attributes"/>
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                                      <nvpair id="rsc_DEV_CI-meta_attributes-target-role" name="target-role" value="Started"/>
Jan 26 04:59:30 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                                    </meta_attributes>
Jan 26 04:59:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.580.0)
Jan 26 04:59:31 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1610 aborted by meta_attributes.rsc_DEV_CI-meta_attributes 'create': Configuration change | cib=1.580.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/group[@id='grp_DEV_ci']/primitive[@id='rsc_DEV_CI'] complete=true
Jan 26 04:59:31 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:59:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create primitive[@id='rsc_DEV_CI']
Jan 26 04:59:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.580.0
Jan 26 04:59:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:59:31 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-81.raw
Jan 26 04:59:31 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.580.0 of the CIB to disk (digest: 2a5b57f62cf4ad2728892c0f5a777488)
Jan 26 04:59:31 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.oeVaYG (digest: /var/lib/pacemaker/cib/cib.zy2esa)
Jan 26 04:59:31 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:59:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:59:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:59:31 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 04:59:31 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:59:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:59:31 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1611, saving inputs in /var/lib/pacemaker/pengine/pe-input-504.bz2
Jan 26 04:59:31 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:59:31 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1611 (ref=pe_calc-dc-1580011171-2067) derived from /var/lib/pacemaker/pengine/pe-input-504.bz2
Jan 26 04:59:31 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1611 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-504.bz2): Complete
Jan 26 04:59:31 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 04:59:31 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 04:59:31 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:36 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 2530e9ae5580c44e68d8517b573305df for 1.580.0 (0x55b8bb9c3560 0)
Jan 26 04:59:49 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#monitor_120000[vmi243500]: 1 -> (null) from vmi243500
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 169 with 2 changes for fail-count-rsc_DEV_CI#monitor_120000, id=<n/a>, set=(null)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#monitor_120000[vmi243500]: 1579785401 -> (null) from vmi243500
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/2400)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/169)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 170 with 2 changes for last-failure-rsc_DEV_CI#monitor_120000, id=<n/a>, set=(null)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: 1579785728 -> (null) from vmi243500
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 171 with 2 changes for last-failure-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: INFINITY -> (null) from vmi243500
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 172 with 2 changes for fail-count-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.0 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.1 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/2400, version=1.580.0)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: delete_resource:	Removing resource rsc_DEV_CI for 86409eb5-ef37-4b0a-8590-ead84f25a4ce (hacluster) on vmi243500
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: notify_deleted:	Notifying 86409eb5-ef37-4b0a-8590-ead84f25a4ce on vmi243500 that rsc_DEV_CI was deleted
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.0 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.1 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.monitor_120000']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/169, version=1.580.1)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/2401)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/170)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/171)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by deletion of nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.monitor_120000']: Transient attribute change | cib=1.580.1 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.monitor_120000'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/172)
Jan 26 04:59:50 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 169 for fail-count-rsc_DEV_CI#monitor_120000: OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 169 for fail-count-rsc_DEV_CI#monitor_120000[vmi243500]=(null): OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 169 for fail-count-rsc_DEV_CI#monitor_120000[vmi243493]=(null): OK (0)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.1 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.2 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 04:59:50 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: delete lrm_resource[@id='rsc_DEV_CI']
Jan 26 04:59:50 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.580.2
Jan 26 04:59:50 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by deletion of lrm_resource[@id='rsc_DEV_CI']: Resource state removal | cib=1.580.2 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/2401, version=1.580.2)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.2 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.3 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.monitor_120000']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/170, version=1.580.3)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by deletion of nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.monitor_120000']: Transient attribute change | cib=1.580.3 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.monitor_120000'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.3 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.4 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/171, version=1.580.4)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by deletion of nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0']: Transient attribute change | cib=1.580.4 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.4 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.580.5 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0']
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/172, version=1.580.5)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by deletion of nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0']: Transient attribute change | cib=1.580.5 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/2403)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 170 for last-failure-rsc_DEV_CI#monitor_120000: OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 170 for last-failure-rsc_DEV_CI#monitor_120000[vmi243500]=(null): OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 170 for last-failure-rsc_DEV_CI#monitor_120000[vmi243493]=(null): OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 171 for last-failure-rsc_DEV_CI#start_0: OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 171 for last-failure-rsc_DEV_CI#start_0[vmi243500]=(null): OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 171 for last-failure-rsc_DEV_CI#start_0[vmi243493]=1579785934: OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 172 for fail-count-rsc_DEV_CI#start_0: OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 172 for fail-count-rsc_DEV_CI#start_0[vmi243500]=(null): OK (0)
Jan 26 04:59:50 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 172 for fail-count-rsc_DEV_CI#start_0[vmi243493]=INFINITY: OK (0)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.580.5 2
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.0 (null)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=581, @num_updates=0
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/crm_config/cluster_property_set[@id='cib-bootstrap-options']/nvpair[@id='cib-bootstrap-options-last-lrm-refresh']:  @value=1580011190
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/2403, version=1.581.0)
Jan 26 04:59:50 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1611 aborted by cib-bootstrap-options-last-lrm-refresh doing modify last-lrm-refresh=1580011190: Configuration change | cib=1.581.0 source=te_update_diff_v2:500 path=/cib/configuration/crm_config/cluster_property_set[@id='cib-bootstrap-options']/nvpair[@id='cib-bootstrap-options-last-lrm-refresh'] complete=true
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-82.raw
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.581.0 of the CIB to disk (digest: 0a26a7d999f39eada5bf565dfba5c13c)
Jan 26 04:59:50 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.xuhQ05 (digest: /var/lib/pacemaker/cib/cib.yqOzpk)
Jan 26 04:59:51 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jan 26 04:59:51 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 04:59:51 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 04:59:51 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 04:59:51 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             (              vmi243500 )  
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 04:59:51 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 04:59:51 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1612, saving inputs in /var/lib/pacemaker/pengine/pe-input-505.bz2
Jan 26 04:59:51 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 04:59:51 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1612 (ref=pe_calc-dc-1580011191-2069) derived from /var/lib/pacemaker/pengine/pe-input-505.bz2
Jan 26 04:59:51 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_CI_monitor_0 locally on vmi243500 | action 21
Jan 26 04:59:51 [1591] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (17 active resources)
Jan 26 04:59:51 [1591] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (18 active resources)
Jan 26 04:59:51 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:1612:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_monitor_0
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2412)
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.0 2
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.1 (null)
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="21:1612:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="-1:193;21:1612:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 04:59:51 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2412, version=1.581.1)
Jan 26 04:59:51 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 04:59:51 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.1
Jan 26 04:59:51 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 04:59:52 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:52 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:53 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:54 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:54 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:55 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 04:59:56 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 579faa84357d7a96e1373cd2fb1e99fd for 1.581.1 (0x55b8bb70abe0 0)
Jan 26 05:00:14 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=405 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=2413
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2413)
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.1 2
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.2 (null)
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;21:1612:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=405, @rc-code=7, @op-status=0, @exec-time=22637
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2413, version=1.581.2)
Jan 26 05:00:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_monitor_0 (21) confirmed on vmi243500 (rc=7)
Jan 26 05:00:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_CI_start_0 locally on vmi243500 | action 52
Jan 26 05:00:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_start_0
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.2
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:00:14 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:406
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2414)
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.2 2
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.3 (null)
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @transition-key=52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011214, @last-rc-change=1580011214, @exec-time=
Jan 26 05:00:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2414, version=1.581.3)
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.3
Jan 26 05:00:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:00:14 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:00:19 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 2d9f9060540699ca3251daddc01bafb1 for 1.581.3 (0x55b8bb70abe0 0)
Jan 26 05:01:09 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:01:39 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 173 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/173)
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.3 2
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.4 (null)
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 05:01:39 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1612 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.581.4 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:01:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/173, version=1.581.4)
Jan 26 05:01:39 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 173 for #health-cpu: OK (0)
Jan 26 05:01:39 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 173 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 05:01:39 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:40 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:41 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:42 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:42 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:43 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:01:44 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: c29062a5d97868ebae8aa4e50f66325a for 1.581.4 (0x55b8bb70abe0 0)
Jan 26 05:02:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 26 05:02:42 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:03:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 26 05:03:12 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 174 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/174)
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.4 2
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.5 (null)
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 05:03:12 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1612 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.581.5 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:03:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/174, version=1.581.5)
Jan 26 05:03:12 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 174 for #health-cpu: OK (0)
Jan 26 05:03:12 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 174 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:03:12 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:14 [1591] vmi243500       lrmd:  warning: child_timeout_callback:	rsc_DEV_CI_start_0 process (PID 11918) timed out
Jan 26 05:03:14 [1591] vmi243500       lrmd:  warning: operation_finished:	rsc_DEV_CI_start_0:11918 - timed out after 180000ms
Jan 26 05:03:14 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:406 pid:11918 exit-code:1 exec-time:180003ms queue-time:0ms
Jan 26 05:03:14 [1594] vmi243500       crmd:    error: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: Timed Out | call=406 key=rsc_DEV_CI_start_0 timeout=180000ms
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2415)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.5 2
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.6 (null)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=2:1;52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=406, @rc-code=1, @op-status=2, @exec-time=180003
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="2:1;52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_node="vmi243500" ca
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.6
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:03:14 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 52 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1612 aborted by operation rsc_DEV_CI_start_0 'modify' on vmi243500: Event failed | magic=2:1;52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.581.6 source=match_graph_event:299 complete=false
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (52) confirmed on vmi243500 (rc=1)
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1580011394)
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1612.52) rsc_DEV_CI_start_0.406=unknown error: failed
Jan 26 05:03:14 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 52 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1612 aborted by operation rsc_DEV_CI_start_0 'create' on vmi243500: Event failed | magic=2:1;52:1612:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.581.6 source=match_graph_event:299 complete=false
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (52) confirmed on vmi243500 (rc=1)
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1580011394)
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1612.52) rsc_DEV_CI_start_0.406=unknown error: failed
Jan 26 05:03:14 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1612 (Complete=3, Pending=0, Fired=0, Skipped=0, Incomplete=2, Source=/var/lib/pacemaker/pengine/pe-input-505.bz2): Complete
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: (null) -> INFINITY from vmi243500
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 175 with 2 changes for fail-count-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: (null) -> 1580011394 from vmi243500
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 176 with 2 changes for last-failure-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2415, version=1.581.6)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/175)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/176)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.6 2
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.7 (null)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1612 aborted by status-771304931-fail-count-rsc_DEV_CI.start_0 doing create fail-count-rsc_DEV_CI#start_0=INFINITY: Transient attribute change | cib=1.581.7 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/175, version=1.581.7)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 175 for fail-count-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 175 for fail-count-rsc_DEV_CI#start_0[vmi243500]=INFINITY: OK (0)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 175 for fail-count-rsc_DEV_CI#start_0[vmi243493]=INFINITY: OK (0)
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.7 2
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.8 (null)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1580011394"/>
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1612 aborted by status-771304931-last-failure-rsc_DEV_CI.start_0 doing create last-failure-rsc_DEV_CI#start_0=1580011394: Transient attribute change | cib=1.581.8 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/176, version=1.581.8)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 176 for last-failure-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 176 for last-failure-rsc_DEV_CI#start_0[vmi243500]=1580011394: OK (0)
Jan 26 05:03:14 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 176 for last-failure-rsc_DEV_CI#start_0[vmi243493]=1579785934: OK (0)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_CI             (              vmi243500 )  
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1613, saving inputs in /var/lib/pacemaker/pengine/pe-input-506.bz2
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: handle_response:	pe_calc calculation pe_calc-dc-1580011394-2074 is obsolete
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:03:14 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       rsc_DEV_CI             (              vmi243500 )   due to node availability
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:03:14 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:03:14 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1614 (ref=pe_calc-dc-1580011394-2075) derived from /var/lib/pacemaker/pengine/pe-input-507.bz2
Jan 26 05:03:14 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_CI_stop_0 locally on vmi243500 | action 15
Jan 26 05:03:14 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=15:1614:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_stop_0
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2419)
Jan 26 05:03:14 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1614, saving inputs in /var/lib/pacemaker/pengine/pe-input-507.bz2
Jan 26 05:03:14 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:stop call_id:407
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.8 2
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.9 (null)
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=15:1614:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;15:1614:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011394, @last-rc-change=1580011394, @exec-time=0
Jan 26 05:03:14 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2419, version=1.581.9)
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.9
Jan 26 05:03:14 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:03:14 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:17 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:03:19 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: fb94339f306837e0215cf31d6579f121 for 1.581.9 (0x55b8bb70abe0 0)
Jan 26 05:03:35 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> red from vmi243500
Jan 26 05:03:36 [1594] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 10.410000
Jan 26 05:03:36 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0010 (was 0000)
Jan 26 05:03:48 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: red -> green from vmi243500
Jan 26 05:04:01 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:04:06 [1594] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 11.280000
Jan 26 05:04:31 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 177 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/177)
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.9 2
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.10 (null)
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 05:04:31 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1614 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.581.10 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:04:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/177, version=1.581.10)
Jan 26 05:04:31 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 177 for #health-cpu: OK (0)
Jan 26 05:04:31 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 177 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 05:04:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:04:36 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 4150d52d676cfa8ef1f75ed33c089922 for 1.581.10 (0x55b8bb70abe0 0)
Jan 26 05:04:36 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0010)
Jan 26 05:04:41 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:04:54 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:05:08 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:05:34 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:05:46 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:stop call_id:407 pid:18745 exit-code:0 exec-time:152418ms queue-time:0ms
Jan 26 05:05:46 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=407 key=rsc_DEV_CI_stop_0 confirmed=true cib-update=2420
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2420)
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.10 2
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.11 (null)
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;15:1614:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=407, @rc-code=0, @op-status=0, @exec-time=152418
Jan 26 05:05:46 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_stop_0 (15) confirmed on vmi243500 (rc=0)
Jan 26 05:05:46 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1614 (Complete=4, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-507.bz2): Complete
Jan 26 05:05:46 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:05:46 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:05:46 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.11
Jan 26 05:05:46 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2420, version=1.581.11)
Jan 26 05:05:46 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:05:46 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:05:46 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:05:46 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:05:46 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:05:46 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:05:46 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:05:46 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1615, saving inputs in /var/lib/pacemaker/pengine/pe-input-508.bz2
Jan 26 05:05:46 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:05:46 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1615 (ref=pe_calc-dc-1580011546-2079) derived from /var/lib/pacemaker/pengine/pe-input-508.bz2
Jan 26 05:05:46 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1615 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-508.bz2): Complete
Jan 26 05:05:46 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:05:46 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:05:47 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:47 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:05:47 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:49 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:49 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:05:51 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 95387ab995986fa73ce7ff98eccd12f2 for 1.581.11 (0x55b8bb70abe0 0)
Jan 26 05:06:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 26 05:06:17 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 178 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/178)
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.11 2
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.12 (null)
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 05:06:17 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/178, version=1.581.12)
Jan 26 05:06:17 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 178 for #health-cpu: OK (0)
Jan 26 05:06:17 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 178 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:06:17 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1615 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.581.12 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=true
Jan 26 05:06:17 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 05:06:17 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:06:17 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:06:17 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:06:17 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:06:17 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:06:17 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:06:17 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1616, saving inputs in /var/lib/pacemaker/pengine/pe-input-509.bz2
Jan 26 05:06:17 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:06:17 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1616 (ref=pe_calc-dc-1580011577-2081) derived from /var/lib/pacemaker/pengine/pe-input-509.bz2
Jan 26 05:06:17 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1616 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-509.bz2): Complete
Jan 26 05:06:17 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:06:17 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:06:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:18 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:19 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:19 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:20 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:21 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:06:22 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 2bf5840bc293c06ea66a4ba34e54f6a2 for 1.581.12 (0x55b8bb70abe0 0)
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 7 (not running) | call=396 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=2423
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2423)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.12 2
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.13 (null)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']:  <lrm_rsc_op id="rsc_DEV_database_last_failure_0" operation_key="rsc_DEV_database_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="0:7;26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reaso
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1616 aborted by operation rsc_DEV_database_monitor_120000 'create' on vmi243500: Old event | magic=0:7;26:1609:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.581.13 source=process_graph_event:486 complete=true
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_database on vmi243500 after failed monitor: rc=7 (update=value++, time=1580011745)
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1609.26) rsc_DEV_database_monitor_120000.396=not running: failed
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_client_update:	Expanded fail-count-rsc_DEV_database#monitor_120000=value++ to 1
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_database']
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.13
Jan 26 05:09:05 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2423, version=1.581.13)
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_database#monitor_120000[vmi243500]: (null) -> 1 from vmi243500
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 179 with 1 changes for fail-count-rsc_DEV_database#monitor_120000, id=<n/a>, set=(null)
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_database#monitor_120000[vmi243500]: (null) -> 1580011745 from vmi243500
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 180 with 1 changes for last-failure-rsc_DEV_database#monitor_120000, id=<n/a>, set=(null)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/179)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/180)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.13 2
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.14 (null)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_database.monitor_120000" name="fail-count-rsc_DEV_database#monitor_120000" value="1"/>
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/179, version=1.581.14)
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 179 for fail-count-rsc_DEV_database#monitor_120000: OK (0)
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 179 for fail-count-rsc_DEV_database#monitor_120000[vmi243500]=1: OK (0)
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1616 aborted by status-771304931-fail-count-rsc_DEV_database.monitor_120000 doing create fail-count-rsc_DEV_database#monitor_120000=1: Transient attribute change | cib=1.581.14 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.14 2
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.15 (null)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_database.monitor_120000" name="last-failure-rsc_DEV_database#monitor_120000" value="1580011745"/>
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/180, version=1.581.15)
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 180 for last-failure-rsc_DEV_database#monitor_120000: OK (0)
Jan 26 05:09:05 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 180 for last-failure-rsc_DEV_database#monitor_120000[vmi243500]=1580011745: OK (0)
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1616 aborted by status-771304931-last-failure-rsc_DEV_database.monitor_120000 doing create last-failure-rsc_DEV_database#monitor_120000=1580011745: Transient attribute change | cib=1.581.15 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	FAILED vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_database       (              vmi243500 )  
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1617, saving inputs in /var/lib/pacemaker/pengine/pe-input-510.bz2
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: handle_response:	pe_calc calculation pe_calc-dc-1580011745-2082 is obsolete
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	FAILED vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_database       (              vmi243500 )  
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:09:05 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1618, saving inputs in /var/lib/pacemaker/pengine/pe-input-511.bz2
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:09:05 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1618 (ref=pe_calc-dc-1580011745-2083) derived from /var/lib/pacemaker/pengine/pe-input-511.bz2
Jan 26 05:09:05 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_database_stop_0 locally on vmi243500 | action 9
Jan 26 05:09:05 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation rsc_DEV_database_monitor_120000
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_stop_0
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2427)
Jan 26 05:09:05 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:stop call_id:409
Jan 26 05:09:05 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: Cancelled | call=396 key=rsc_DEV_database_monitor_120000 confirmed=true
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.15 2
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.16 (null)
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_stop_0, @operation=stop, @transition-key=9:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;9:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011745, @last-rc-change=158001174
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.16
Jan 26 05:09:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2427, version=1.581.16)
Jan 26 05:09:06 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:07 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:07 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:08 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:09 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:09 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:10 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 5bb14cd0d6ee681bc4ce21e86f8347d2 for 1.581.16 (0x55b8bb70abe0 0)
Jan 26 05:09:22 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:stop call_id:409 pid:10236 exit-code:0 exec-time:16800ms queue-time:0ms
Jan 26 05:09:22 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_database on vmi243500: 0 (ok) | call=409 key=rsc_DEV_database_stop_0 confirmed=true cib-update=2428
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2428)
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.16 2
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.17 (null)
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;9:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=409, @rc-code=0, @op-status=0, @exec-time=16800
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2428, version=1.581.17)
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.17
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:22 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_stop_0 (9) confirmed on vmi243500 (rc=0)
Jan 26 05:09:22 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_database_start_0 locally on vmi243500 | action 28
Jan 26 05:09:22 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=28:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_start_0
Jan 26 05:09:22 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:start call_id:410
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2429)
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.17 2
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.18 (null)
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @transition-key=28:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;28:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580011762, @last-rc-change=15800
Jan 26 05:09:22 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2429, version=1.581.18)
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.18
Jan 26 05:09:22 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:23 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:23 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:24 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:24 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:25 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:26 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:27 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: bdc0d160763452a41149cc8ae29fa22c for 1.581.18 (0x55b8bb70abe0 0)
Jan 26 05:09:56 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: 7 (not running) | call=357 key=rsc_DEV_ASCS00_monitor_120000 confirmed=false cib-update=2430
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2430)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.18 2
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.19 (null)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']:  <lrm_rsc_op id="rsc_DEV_ASCS00_last_failure_0" operation_key="rsc_DEV_ASCS00_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="36:513:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="0:7;36:513:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2430, version=1.581.19)
Jan 26 05:09:56 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1618 aborted by operation rsc_DEV_ASCS00_monitor_120000 'create' on vmi243500: Old event | magic=0:7;36:513:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.581.19 source=process_graph_event:486 complete=false
Jan 26 05:09:56 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_ASCS00 on vmi243500 after failed monitor: rc=7 (update=value++, time=1580011796)
Jan 26 05:09:56 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ASCS00']
Jan 26 05:09:56 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.19
Jan 26 05:09:56 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (513.36) rsc_DEV_ASCS00_monitor_120000.357=not running: failed
Jan 26 05:09:56 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_client_update:	Expanded fail-count-rsc_DEV_ASCS00#monitor_120000=value++ to 1
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_ASCS00#monitor_120000[vmi243500]: (null) -> 1 from vmi243500
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 181 with 1 changes for fail-count-rsc_DEV_ASCS00#monitor_120000, id=<n/a>, set=(null)
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_ASCS00#monitor_120000[vmi243500]: (null) -> 1580011796 from vmi243500
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/181)
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 182 with 1 changes for last-failure-rsc_DEV_ASCS00#monitor_120000, id=<n/a>, set=(null)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/182)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.19 2
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.20 (null)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_ASCS00.monitor_120000" name="fail-count-rsc_DEV_ASCS00#monitor_120000" value="1"/>
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/181, version=1.581.20)
Jan 26 05:09:56 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1618 aborted by status-771304931-fail-count-rsc_DEV_ASCS00.monitor_120000 doing create fail-count-rsc_DEV_ASCS00#monitor_120000=1: Transient attribute change | cib=1.581.20 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=false
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 181 for fail-count-rsc_DEV_ASCS00#monitor_120000: OK (0)
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 181 for fail-count-rsc_DEV_ASCS00#monitor_120000[vmi243500]=1: OK (0)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.20 2
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.21 (null)
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_ASCS00.monitor_120000" name="last-failure-rsc_DEV_ASCS00#monitor_120000" value="1580011796"/>
Jan 26 05:09:56 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/182, version=1.581.21)
Jan 26 05:09:56 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1618 aborted by status-771304931-last-failure-rsc_DEV_ASCS00.monitor_120000 doing create last-failure-rsc_DEV_ASCS00#monitor_120000=1580011796: Transient attribute change | cib=1.581.21 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=false
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 182 for last-failure-rsc_DEV_ASCS00#monitor_120000: OK (0)
Jan 26 05:09:56 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 182 for last-failure-rsc_DEV_ASCS00#monitor_120000[vmi243500]=1580011796: OK (0)
Jan 26 05:09:56 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:57 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:59 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:09:59 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:10:00 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:01 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 1fe958162668f4847fd304a672121c23 for 1.581.21 (0x55b8bb70abe0 0)
Jan 26 05:10:29 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 183 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/183)
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.21 2
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.22 (null)
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 05:10:29 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1618 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.581.22 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:10:29 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/183, version=1.581.22)
Jan 26 05:10:29 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 183 for #health-cpu: OK (0)
Jan 26 05:10:29 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 183 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 05:10:30 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:30 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:31 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:10:34 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: bcfb6d297f9b1c780998a19f44efc725 for 1.581.22 (0x55b8bb70abe0 0)
Jan 26 05:10:52 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:11:05 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:11:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 26 05:11:19 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:11:32 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:11:45 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:12:12 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:12:25 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:12:55 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 184 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/184)
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.22 2
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.23 (null)
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 05:12:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/184, version=1.581.23)
Jan 26 05:12:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 184 for #health-cpu: OK (0)
Jan 26 05:12:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 184 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:12:55 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1618 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.581.23 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:12:56 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:12:57 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:12:57 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:12:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:12:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:12:59 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:13:00 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 398979a7fbb55dcf6bcf783df3568b50 for 1.581.23 (0x55b8bb70abe0 0)
Jan 26 05:13:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:start call_id:410 pid:11129 exit-code:0 exec-time:488403ms queue-time:1ms
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2431)
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_database on vmi243500: 0 (ok) | call=410 key=rsc_DEV_database_start_0 confirmed=true cib-update=2431
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.23 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.24 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;28:1618:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=410, @rc-code=0, @op-status=0, @exec-time=488403, @queue-time=1
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_start_0 (28) confirmed on vmi243500 (rc=0)
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1618 (Complete=7, Pending=0, Fired=0, Skipped=1, Incomplete=1, Source=/var/lib/pacemaker/pengine/pe-input-511.bz2): Stopped
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2431, version=1.581.24)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.24
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243500
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_ASCS00         (              vmi243500 )  
Jan 26 05:17:31 [1593] vmi243500    pengine:   notice: LogAction:	 * Restart    fs_2_DEV_ASCS          (              vmi243500 )   due to required rsc_DEV_ASCS00 start
Jan 26 05:17:31 [1593] vmi243500    pengine:   notice: LogAction:	 * Restart    fs_3_DEV_ASCS          (              vmi243500 )   due to required fs_2_DEV_ASCS start
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:17:31 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:17:31 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1619, saving inputs in /var/lib/pacemaker/pengine/pe-input-512.bz2
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1619 (ref=pe_calc-dc-1580012251-2088) derived from /var/lib/pacemaker/pengine/pe-input-512.bz2
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_database_monitor_120000 locally on vmi243500 | action 29
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=29:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_monitor_120000
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2433)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.24 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.25 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-key=29:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;29:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580012251, @exec-time=0
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2433, version=1.581.25)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.25
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_3_DEV_ASCS_stop_0 locally on vmi243500 | action 41
Jan 26 05:17:31 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_3_DEV_ASCS_monitor_20000
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=41:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_3_DEV_ASCS_stop_0
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:stop call_id:413
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2434)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.25 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.26 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_stop_0, @operation=stop, @transition-key=41:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;41:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580012251, @last-rc-change=1580012251, @exe
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: Cancelled | call=368 key=fs_3_DEV_ASCS_monitor_20000 confirmed=true
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.26
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2434, version=1.581.26)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 0 (ok) | call=411 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=2435
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2435)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.26 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.27 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-magic=0:0;29:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=411, @rc-code=0, @op-status=0, @exec-time=103, @queue-time=1
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2435, version=1.581.27)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.27
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_monitor_120000 (29) confirmed on vmi243500 (rc=0)
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:stop call_id:413 pid:28009 exit-code:0 exec-time:252ms queue-time:0ms
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=413 key=fs_3_DEV_ASCS_stop_0 confirmed=true cib-update=2436
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2436)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.27 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.28 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;41:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=413, @rc-code=0, @op-status=0, @exec-time=252
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2436, version=1.581.28)
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_stop_0 (41) confirmed on vmi243500 (rc=0)
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_2_DEV_ASCS_stop_0 locally on vmi243500 | action 39
Jan 26 05:17:31 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_2_DEV_ASCS_monitor_20000
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=39:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_2_DEV_ASCS_stop_0
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.28
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:stop call_id:415
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: Cancelled | call=360 key=fs_2_DEV_ASCS_monitor_20000 confirmed=true
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2437)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.28 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.29 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_stop_0, @operation=stop, @transition-key=39:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;39:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580012251, @last-rc-change=1580012251, @exe
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2437, version=1.581.29)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.29
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:stop call_id:415 pid:28114 exit-code:0 exec-time:176ms queue-time:0ms
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=415 key=fs_2_DEV_ASCS_stop_0 confirmed=true cib-update=2438
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2438)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.29 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.30 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;39:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=415, @rc-code=0, @op-status=0, @exec-time=176
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2438, version=1.581.30)
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_stop_0 (39) confirmed on vmi243500 (rc=0)
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_ASCS00_stop_0 locally on vmi243500 | action 9
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.30
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation rsc_DEV_ASCS00_monitor_120000
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_ASCS00_stop_0
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:stop call_id:417
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: Cancelled | call=357 key=rsc_DEV_ASCS00_monitor_120000 confirmed=true
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2439)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.30 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.31 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_stop_0, @operation=stop, @transition-key=9:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;9:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580012251, @last-rc-change=1580012251, @ex
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.31
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2439, version=1.581.31)
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:stop call_id:417 pid:28190 exit-code:0 exec-time:246ms queue-time:0ms
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=417 key=rsc_DEV_ASCS00_stop_0 confirmed=true cib-update=2440
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2440)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.31 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.32 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;9:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=417, @rc-code=0, @op-status=0, @exec-time=246
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2440, version=1.581.32)
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_stop_0 (9) confirmed on vmi243500 (rc=0)
Jan 26 05:17:31 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_ASCS00_start_0 locally on vmi243500 | action 38
Jan 26 05:17:31 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=38:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_ASCS00_start_0
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.32
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:31 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:start call_id:418
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2441)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.32 2
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.33 (null)
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_start_0, @operation=start, @transition-key=38:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;38:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:17:31 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2441, version=1.581.33)
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.33
Jan 26 05:17:31 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:17:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:32 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:33 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:17:36 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 19df7c058ae8b217562fa480e1299dd8 for 1.581.33 (0x55b8bb70abe0 0)
Jan 26 05:18:12 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:start call_id:418 pid:28263 exit-code:0 exec-time:40839ms queue-time:0ms
Jan 26 05:18:12 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=418 key=rsc_DEV_ASCS00_start_0 confirmed=true cib-update=2442
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2442)
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.33 2
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.34 (null)
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;38:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=418, @rc-code=0, @op-status=0, @exec-time=40839
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2442, version=1.581.34)
Jan 26 05:18:12 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_start_0 (38) confirmed on vmi243500 (rc=0)
Jan 26 05:18:12 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ASCS00_monitor_120000 locally on vmi243500 | action 8
Jan 26 05:18:12 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=8:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_ASCS00_monitor_120000
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2443)
Jan 26 05:18:12 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_2_DEV_ASCS_start_0 locally on vmi243500 | action 40
Jan 26 05:18:12 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=40:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_2_DEV_ASCS_start_0
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.34 2
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.35 (null)
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-key=8:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;8:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580012292, @exec-time=0
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2443, version=1.581.35)
Jan 26 05:18:12 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:start call_id:420
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2444)
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.35 2
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.36 (null)
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_start_0, @operation=start, @transition-key=40:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;40:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580012292, @last-rc-change=1580012292, @e
Jan 26 05:18:12 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2444, version=1.581.36)
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.34
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.35
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.36
Jan 26 05:18:12 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=419 key=rsc_DEV_ASCS00_monitor_120000 confirmed=false cib-update=2445
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2445)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.36 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.37 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-magic=0:0;8:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=419, @rc-code=0, @op-status=0, @exec-time=283
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_monitor_120000 (8) confirmed on vmi243500 (rc=0)
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.37
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2445, version=1.581.37)
Jan 26 05:18:13 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:start call_id:420 pid:29809 exit-code:0 exec-time:438ms queue-time:0ms
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=420 key=fs_2_DEV_ASCS_start_0 confirmed=true cib-update=2446
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2446)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.37 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.38 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;40:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=420, @rc-code=0, @op-status=0, @exec-time=438
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2446, version=1.581.38)
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.38
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_start_0 (40) confirmed on vmi243500 (rc=0)
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_2_DEV_ASCS_monitor_20000 locally on vmi243500 | action 3
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=3:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_2_DEV_ASCS_monitor_20000
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_3_DEV_ASCS_start_0 locally on vmi243500 | action 42
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=42:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_3_DEV_ASCS_start_0
Jan 26 05:18:13 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:start call_id:422
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2447)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2448)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.38 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.39 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-key=3:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;3:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580012293, @exec-time=0
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.39
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2447, version=1.581.39)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.39 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.40 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=40
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_start_0, @operation=start, @transition-key=42:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;42:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580012293, @last-rc-change=1580012293, @e
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2448, version=1.581.40)
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.40
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=421 key=fs_2_DEV_ASCS_monitor_20000 confirmed=false cib-update=2449
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2449)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.40 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.41 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=41
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;3:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=421, @rc-code=0, @op-status=0, @exec-time=79
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2449, version=1.581.41)
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_monitor_20000 (3) confirmed on vmi243500 (rc=0)
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.41
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:start call_id:422 pid:30045 exit-code:0 exec-time:163ms queue-time:0ms
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=422 key=fs_3_DEV_ASCS_start_0 confirmed=true cib-update=2450
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2450)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.41 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.42 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=42
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;42:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=422, @rc-code=0, @op-status=0, @exec-time=163
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.42
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_start_0 (42) confirmed on vmi243500 (rc=0)
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_3_DEV_ASCS_monitor_20000 locally on vmi243500 | action 10
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_3_DEV_ASCS_monitor_20000
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2450, version=1.581.42)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2451)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.42 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.43 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=43
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-key=10:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;10:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580012293, @exec-time=0
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2451, version=1.581.43)
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.43
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=423 key=fs_3_DEV_ASCS_monitor_20000 confirmed=false cib-update=2452
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2452)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.43 2
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.44 (null)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;10:1619:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=423, @rc-code=0, @op-status=0, @exec-time=77
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_monitor_20000 (10) confirmed on vmi243500 (rc=0)
Jan 26 05:18:13 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2452, version=1.581.44)
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1619 (Complete=15, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-512.bz2): Complete
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.44
Jan 26 05:18:13 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:18:13 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:18:13 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:14 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:15 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:16 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:18:18 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 0a4d6a4e97d656e50d8c7d73d5336914 for 1.581.44 (0x55b8bb70abe0 0)
Jan 26 05:30:54 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/2453)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: 1580011394 -> (null) from vmi243500
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 185 with 2 changes for last-failure-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: INFINITY -> (null) from vmi243500
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 186 with 2 changes for fail-count-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.44 2
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.45 7b3810e3136ad6efa51467045e082767
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/2453, version=1.581.44)
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: delete_resource:	Removing resource rsc_DEV_CI for 4beb0593-ffc5-470f-b2a4-dcbc544f8575 (hacluster) on vmi243500
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/185)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/186)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/2454)
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: notify_deleted:	Notifying 4beb0593-ffc5-470f-b2a4-dcbc544f8575 on vmi243500 that rsc_DEV_CI was deleted
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.44 2
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.45 (null)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0']
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/185, version=1.581.45)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.45 2
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.46 (null)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0']
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/186, version=1.581.46)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.46 2
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.581.47 (null)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Jan 26 05:30:55 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: delete lrm_resource[@id='rsc_DEV_CI']
Jan 26 05:30:55 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.581.47
Jan 26 05:30:55 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 185 for last-failure-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 185 for last-failure-rsc_DEV_CI#start_0[vmi243500]=(null): OK (0)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 185 for last-failure-rsc_DEV_CI#start_0[vmi243493]=1579785934: OK (0)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 186 for fail-count-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 186 for fail-count-rsc_DEV_CI#start_0[vmi243500]=(null): OK (0)
Jan 26 05:30:55 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 186 for fail-count-rsc_DEV_CI#start_0[vmi243493]=INFINITY: OK (0)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/2454, version=1.581.47)
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1619 aborted by deletion of nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0']: Transient attribute change | cib=1.581.45 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0'] complete=true
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1619 aborted by deletion of nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0']: Transient attribute change | cib=1.581.46 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0'] complete=true
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1619 aborted by deletion of lrm_resource[@id='rsc_DEV_CI']: Resource state removal | cib=1.581.47 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI'] complete=true
Jan 26 05:30:55 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/2456)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.581.47 2
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.0 (null)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=582, @num_updates=0
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/crm_config/cluster_property_set[@id='cib-bootstrap-options']/nvpair[@id='cib-bootstrap-options-last-lrm-refresh']:  @value=1580013055
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/2456, version=1.582.0)
Jan 26 05:30:55 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:30:55 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:30:55 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:30:55 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:30:55 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:30:55 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1619 aborted by cib-bootstrap-options-last-lrm-refresh doing modify last-lrm-refresh=1580013055: Configuration change | cib=1.582.0 source=te_update_diff_v2:500 path=/cib/configuration/crm_config/cluster_property_set[@id='cib-bootstrap-options']/nvpair[@id='cib-bootstrap-options-last-lrm-refresh'] complete=true
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             (              vmi243500 )  
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:30:55 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:30:55 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1620, saving inputs in /var/lib/pacemaker/pengine/pe-input-513.bz2
Jan 26 05:30:55 [1594] vmi243500       crmd:     info: handle_response:	pe_calc calculation pe_calc-dc-1580013055-2100 is obsolete
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-83.raw
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.582.0 of the CIB to disk (digest: 7dba4892f5ff0d9b6d4578cf66b06a8e)
Jan 26 05:30:55 [1589] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.vWimWr (digest: /var/lib/pacemaker/cib/cib.HiDjkV)
Jan 26 05:30:56 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jan 26 05:30:56 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:30:56 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:30:56 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:30:56 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:30:56 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:30:56 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             (              vmi243500 )  
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:30:56 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:30:56 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:30:56 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1621, saving inputs in /var/lib/pacemaker/pengine/pe-input-514.bz2
Jan 26 05:30:56 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1621 (ref=pe_calc-dc-1580013056-2101) derived from /var/lib/pacemaker/pengine/pe-input-514.bz2
Jan 26 05:30:56 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_CI_monitor_0 locally on vmi243500 | action 21
Jan 26 05:30:56 [1591] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (17 active resources)
Jan 26 05:30:56 [1591] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (18 active resources)
Jan 26 05:30:56 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:1621:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_monitor_0
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2463)
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.0 2
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.1 (null)
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="21:1621:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="-1:193;21:1621:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:30:56 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:30:56 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.1
Jan 26 05:30:56 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:56 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2463, version=1.582.1)
Jan 26 05:30:57 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:30:57 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=428 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=2464
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2464)
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.1 2
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.2 (null)
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;21:1621:7:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=428, @rc-code=7, @op-status=0, @exec-time=1062, @queue-time=1
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.2
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:57 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_monitor_0 (21) confirmed on vmi243500 (rc=7)
Jan 26 05:30:57 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_CI_start_0 locally on vmi243500 | action 52
Jan 26 05:30:57 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_start_0
Jan 26 05:30:57 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:429
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2464, version=1.582.2)
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2465)
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.2 2
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.3 (null)
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @transition-key=52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013057, @last-rc-change=1580013057, @exec-time=
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.3
Jan 26 05:30:57 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:30:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2465, version=1.582.3)
Jan 26 05:30:57 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:30:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:30:59 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:31:00 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:31:00 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:31:01 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:31:02 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:31:02 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 64e8096c697b3d77cff4642a9c695284 for 1.582.3 (0x55b8bb66deb0 0)
Jan 26 05:31:37 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:32:04 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:32:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 26 05:32:17 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:32:47 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 187 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/187)
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.3 2
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.4 (null)
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 05:32:47 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/187, version=1.582.4)
Jan 26 05:32:47 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1621 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.582.4 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jan 26 05:32:47 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 187 for #health-cpu: OK (0)
Jan 26 05:32:47 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 187 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 05:32:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:49 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:51 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:52 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:32:52 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 71fcbd1ca74e06ea88e30b57845f54ed for 1.582.4 (0x55b8bb66deb0 0)
Jan 26 05:32:57 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:33:23 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:33:37 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:33:57 [1591] vmi243500       lrmd:  warning: child_timeout_callback:	rsc_DEV_CI_start_0 process (PID 23282) timed out
Jan 26 05:33:57 [1591] vmi243500       lrmd:  warning: operation_finished:	rsc_DEV_CI_start_0:23282 - timed out after 180000ms
Jan 26 05:33:57 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:429 pid:23282 exit-code:1 exec-time:180009ms queue-time:1ms
Jan 26 05:33:57 [1594] vmi243500       crmd:    error: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: Timed Out | call=429 key=rsc_DEV_CI_start_0 timeout=180000ms
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2466)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.4 2
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.5 (null)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=2:1;52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=429, @rc-code=1, @op-status=2, @exec-time=180009, @queue-time=1
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="2:1;52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_node="vmi243500" ca
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2466, version=1.582.5)
Jan 26 05:33:57 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 52 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1621 aborted by operation rsc_DEV_CI_start_0 'modify' on vmi243500: Event failed | magic=2:1;52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.582.5 source=match_graph_event:299 complete=false
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (52) confirmed on vmi243500 (rc=1)
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1580013237)
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1621.52) rsc_DEV_CI_start_0.429=unknown error: failed
Jan 26 05:33:57 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 52 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1621 aborted by operation rsc_DEV_CI_start_0 'create' on vmi243500: Event failed | magic=2:1;52:1621:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.582.5 source=match_graph_event:299 complete=false
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (52) confirmed on vmi243500 (rc=1)
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1580013237)
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.5
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1621.52) rsc_DEV_CI_start_0.429=unknown error: failed
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:33:57 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1621 (Complete=3, Pending=0, Fired=0, Skipped=0, Incomplete=2, Source=/var/lib/pacemaker/pengine/pe-input-514.bz2): Complete
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: (null) -> INFINITY from vmi243500
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 188 with 2 changes for fail-count-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: (null) -> 1580013237 from vmi243500
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 189 with 2 changes for last-failure-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/188)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/189)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.5 2
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.6 (null)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/188, version=1.582.6)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 188 for fail-count-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 188 for fail-count-rsc_DEV_CI#start_0[vmi243500]=INFINITY: OK (0)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 188 for fail-count-rsc_DEV_CI#start_0[vmi243493]=INFINITY: OK (0)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.6 2
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.7 (null)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1580013237"/>
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/189, version=1.582.7)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 189 for last-failure-rsc_DEV_CI#start_0: OK (0)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 189 for last-failure-rsc_DEV_CI#start_0[vmi243500]=1580013237: OK (0)
Jan 26 05:33:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 189 for last-failure-rsc_DEV_CI#start_0[vmi243493]=1579785934: OK (0)
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1621 aborted by status-771304931-fail-count-rsc_DEV_CI.start_0 doing create fail-count-rsc_DEV_CI#start_0=INFINITY: Transient attribute change | cib=1.582.6 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1621 aborted by status-771304931-last-failure-rsc_DEV_CI.start_0 doing create last-failure-rsc_DEV_CI#start_0=1580013237: Transient attribute change | cib=1.582.7 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_CI             (              vmi243500 )  
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1622, saving inputs in /var/lib/pacemaker/pengine/pe-input-515.bz2
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: handle_response:	pe_calc calculation pe_calc-dc-1580013237-2105 is obsolete
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:33:57 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       rsc_DEV_CI             (              vmi243500 )   due to node availability
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:33:57 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1623, saving inputs in /var/lib/pacemaker/pengine/pe-input-516.bz2
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:33:57 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1623 (ref=pe_calc-dc-1580013237-2106) derived from /var/lib/pacemaker/pengine/pe-input-516.bz2
Jan 26 05:33:57 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_CI_stop_0 locally on vmi243500 | action 15
Jan 26 05:33:57 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=15:1623:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_CI_stop_0
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2470)
Jan 26 05:33:57 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:stop call_id:430
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.7 2
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.8 (null)
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=15:1623:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;15:1623:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013237, @last-rc-change=1580013237, @exec-time=0,
Jan 26 05:33:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2470, version=1.582.8)
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.8
Jan 26 05:33:57 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:33:58 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:33:59 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:34:00 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:34:00 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:34:01 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:34:02 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jan 26 05:34:02 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 2644899403a553fbea2025fa0e98e809 for 1.582.8 (0x55b8bb66deb0 0)
Jan 26 05:34:03 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:34:06 [1594] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 11.120000
Jan 26 05:34:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0010 (was 0001)
Jan 26 05:34:17 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:34:33 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:stop call_id:430 pid:30090 exit-code:0 exec-time:35810ms queue-time:1ms
Jan 26 05:34:33 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=430 key=rsc_DEV_CI_stop_0 confirmed=true cib-update=2471
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2471)
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.8 2
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.9 (null)
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;15:1623:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=430, @rc-code=0, @op-status=0, @exec-time=35810, @queue-time=1
Jan 26 05:34:33 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_stop_0 (15) confirmed on vmi243500 (rc=0)
Jan 26 05:34:33 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1623 (Complete=4, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-516.bz2): Complete
Jan 26 05:34:33 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:34:33 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:34:33 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:34:33 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.9
Jan 26 05:34:33 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:34:33 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2471, version=1.582.9)
Jan 26 05:34:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:34 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:35 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:36 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:36 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0010)
Jan 26 05:34:37 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:38 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 20217fea168e7ef97d9f336c2b62b134 for 1.582.9 (0x55b8bb66deb0 0)
Jan 26 05:34:47 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 190 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/190)
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.9 2
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.10 (null)
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 05:34:47 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1623 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.582.10 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=true
Jan 26 05:34:47 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jan 26 05:34:47 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/190, version=1.582.10)
Jan 26 05:34:47 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 190 for #health-cpu: OK (0)
Jan 26 05:34:47 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 190 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:34:47 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:34:47 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:34:47 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:34:47 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1624, saving inputs in /var/lib/pacemaker/pengine/pe-input-517.bz2
Jan 26 05:34:47 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:34:47 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1624 (ref=pe_calc-dc-1580013287-2110) derived from /var/lib/pacemaker/pengine/pe-input-517.bz2
Jan 26 05:34:47 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1624 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-517.bz2): Complete
Jan 26 05:34:47 [1594] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:34:47 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:34:47 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:48 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:49 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:50 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:51 [1594] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jan 26 05:34:52 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: d31f767430a66bb9c5c7d5d4dbf1709a for 1.582.10 (0x55b8bb66deb0 0)
Jan 26 05:35:06 [1594] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 26 05:45:57 [1585] vmi243500 pacemakerd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:45:57 [1585] vmi243500 pacemakerd:   notice: pcmk_shutdown_worker:	Shutting down Pacemaker
Jan 26 05:45:57 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping crmd | sent signal 15 to process 1594
Jan 26 05:45:57 [1594] vmi243500       crmd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:45:57 [1594] vmi243500       crmd:   notice: crm_shutdown:	Shutting down cluster resource manager | limit=1200000ms
Jan 26 05:45:57 [1594] vmi243500       crmd:     info: do_log:	Input I_SHUTDOWN received in state S_IDLE from crm_shutdown
Jan 26 05:45:57 [1594] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_SHUTDOWN cause=C_SHUTDOWN origin=crm_shutdown
Jan 26 05:45:57 [1594] vmi243500       crmd:     info: do_shutdown_req:	Sending shutdown request to all peers (DC is vmi243500)
Jan 26 05:45:57 [1594] vmi243500       crmd:     info: crm_update_peer_expected:	handle_request: Node vmi243500[771304931] - expected state is now down (was member)
Jan 26 05:45:57 [1594] vmi243500       crmd:     info: handle_shutdown_request:	Creating shutdown request for vmi243500 (state=S_POLICY_ENGINE)
Jan 26 05:45:57 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting shutdown[vmi243500]: (null) -> 1580013957 from vmi243500
Jan 26 05:45:57 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 191 with 1 changes for shutdown, id=<n/a>, set=(null)
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/191)
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.10 2
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.11 (null)
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-shutdown" name="shutdown" value="1580013957"/>
Jan 26 05:45:57 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/191, version=1.582.11)
Jan 26 05:45:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 191 for shutdown: OK (0)
Jan 26 05:45:57 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 191 for shutdown[vmi243500]=1580013957: OK (0)
Jan 26 05:45:57 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1624 aborted by status-771304931-shutdown doing create shutdown=1580013957: Transient attribute change | cib=1.582.11 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is shutting down
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:0: Rolling back scores from fs_DEV_sapmnt:0
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:0 cannot run anywhere
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:0 cannot run anywhere
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_CPU on vmi243493
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: stage6:	Scheduling Node vmi243500 for shutdown
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogNodeActions:	 * Shutdown vmi243500
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_database        ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       vip_DEV_database       ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       rsc_DEV_database       ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_ASCS            ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       vip_DEV_ASCS           ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       rsc_DEV_ASCS00         ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_2_DEV_ASCS          ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_3_DEV_ASCS          ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_CI              ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       vip_DEV_CI             ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       global_rsc_DEV_CPU     ( vmi243500 -> vmi243493 )  
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       global_rsc_DEV_NIC     (              vmi243500 )   due to node availability
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       dlm_DEV:0              (              vmi243500 )   due to node availability
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       fs_DEV_sapmnt:0        (              vmi243500 )   due to node availability
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:45:58 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:45:58 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1625, saving inputs in /var/lib/pacemaker/pengine/pe-input-518.bz2
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1625 (ref=pe_calc-dc-1580013957-2113) derived from /var/lib/pacemaker/pengine/pe-input-518.bz2
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation vip_DEV_CI_stop_0 locally on vmi243500 | action 58
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_CI_monitor_10000
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=58:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_CI_stop_0
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2474)
Jan 26 05:45:58 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:stop call_id:432
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation global_rsc_DEV_CPU_stop_0 locally on vmi243500 | action 73
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation global_rsc_DEV_CPU_monitor_10000
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: services_action_cancel:	Terminating in-flight op global_rsc_DEV_CPU_monitor_10000 (pid 22270) early because it was cancelled
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: operation_finished:	global_rsc_DEV_CPU_monitor_10000:22270 - terminated with signal 9
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation global_rsc_DEV_CPU_monitor_10000
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.11 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.12 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_stop_0, @operation=stop, @transition-key=58:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;58:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013958, @last-rc-change=1580013958, @exec-time=0,
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2474, version=1.582.12)
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=73:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=global_rsc_DEV_CPU_stop_0
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.12
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2475)
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:45:58 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:stop call_id:434
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.12 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.13 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_stop_0, @operation=stop, @crm-debug-origin=do_update_resource, @transition-key=73:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;73:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2475, version=1.582.13)
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation global_rsc_DEV_NIC_stop_0 locally on vmi243500 | action 76
Jan 26 05:45:58 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation global_rsc_DEV_NIC_monitor_10000
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=76:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=global_rsc_DEV_NIC_stop_0
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2476)
Jan 26 05:45:58 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:stop call_id:436
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.13
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.13 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.14 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_stop_0, @operation=stop, @transition-key=76:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;76:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013958, @last-rc-change=1
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2476, version=1.582.14)
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: Cancelled | call=400 key=vip_DEV_CI_monitor_10000 confirmed=true
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: Cancelled | call=82 key=global_rsc_DEV_CPU_monitor_10000 confirmed=true
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: Cancelled | call=177 key=global_rsc_DEV_NIC_monitor_10000 confirmed=true
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.14
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:45:58 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: 1 -> (null) from vmi243500
Jan 26 05:45:58 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 192 with 1 changes for ethmonitor-eth0, id=<n/a>, set=(null)
Jan 26 05:45:58 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:stop call_id:436 pid:22429 exit-code:0 exec-time:175ms queue-time:1ms
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/192)
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=436 key=global_rsc_DEV_NIC_stop_0 confirmed=true cib-update=2477
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2477)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.14 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.15 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-ethmonitor-eth0']
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/192, version=1.582.15)
Jan 26 05:45:58 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 192 for ethmonitor-eth0: OK (0)
Jan 26 05:45:58 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 192 for ethmonitor-eth0[vmi243500]=(null): OK (0)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.15 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.16 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;76:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=436, @rc-code=0, @op-status=0, @exec-time=175, @queue-time=1
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2477, version=1.582.16)
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.16
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1625 aborted by deletion of nvpair[@id='status-771304931-ethmonitor-eth0']: Transient attribute change | cib=1.582.15 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-ethmonitor-eth0'] complete=false
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_stop_0 (76) confirmed on vmi243500 (rc=0)
Jan 26 05:45:58 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:stop call_id:432 pid:22426 exit-code:0 exec-time:253ms queue-time:0ms
Jan 26 05:45:58 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_CI on vmi243500: 0 (ok) | call=432 key=vip_DEV_CI_stop_0 confirmed=true cib-update=2478
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2478)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.16 2
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.17 (null)
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;58:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=432, @rc-code=0, @op-status=0, @exec-time=253
Jan 26 05:45:58 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2478, version=1.582.17)
Jan 26 05:45:58 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_stop_0 (58) confirmed on vmi243500 (rc=0)
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.17
Jan 26 05:45:58 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:stop call_id:434 pid:22428 exit-code:0 exec-time:3328ms queue-time:0ms
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=434 key=global_rsc_DEV_CPU_stop_0 confirmed=true cib-update=2479
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2479)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.17 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.18 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;73:1625:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=434, @rc-code=0, @op-status=0, @exec-time=3328
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_stop_0 (73) confirmed on vmi243500 (rc=0)
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1625 (Complete=4, Pending=0, Fired=0, Skipped=2, Incomplete=49, Source=/var/lib/pacemaker/pengine/pe-input-518.bz2): Stopped
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.18
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2479, version=1.582.18)
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is shutting down
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 vmi243500 ]
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:0: Rolling back scores from fs_DEV_sapmnt:0
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:0 cannot run anywhere
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:0 cannot run anywhere
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_CPU on vmi243493
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: stage6:	Scheduling Node vmi243500 for shutdown
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogNodeActions:	 * Shutdown vmi243500
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_database        ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       vip_DEV_database       ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       rsc_DEV_database       ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_ASCS            ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       vip_DEV_ASCS           ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       rsc_DEV_ASCS00         ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_2_DEV_ASCS          ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_3_DEV_ASCS          ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Move       fs_DEV_CI              ( vmi243500 -> vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             (              vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     (              vmi243493 )  
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Stopped)
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       dlm_DEV:0              (              vmi243500 )   due to node availability
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: LogAction:	 * Stop       fs_DEV_sapmnt:0        (              vmi243500 )   due to node availability
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Started vmi243493)
Jan 26 05:46:01 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Started vmi243493)
Jan 26 05:46:01 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1626, saving inputs in /var/lib/pacemaker/pengine/pe-input-519.bz2
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1626 (ref=pe_calc-dc-1580013961-2117) derived from /var/lib/pacemaker/pengine/pe-input-519.bz2
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_CI_stop_0 locally on vmi243500 | action 52
Jan 26 05:46:01 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_CI_monitor_20000
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=52:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_CI_stop_0
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:stop call_id:438
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2481)
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation global_rsc_DEV_CPU_start_0 on vmi243493 | action 69
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: Cancelled | call=398 key=fs_DEV_CI_monitor_20000 confirmed=true
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.18 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.19 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_stop_0, @operation=stop, @transition-key=52:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;52:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013961, @last-rc-change=1580013961, @exec-time=0
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2481, version=1.582.19)
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.19
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.19 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.20 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_start_0, @operation=start, @transition-key=69:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;69:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013953, @last-rc-change=1
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/267, version=1.582.20)
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.20
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.20 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.21 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;69:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=215, @rc-code=0, @op-status=0, @exec-time=22
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/268, version=1.582.21)
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.21
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_start_0 (69) confirmed on vmi243493 (rc=0)
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_CPU_monitor_10000 on vmi243493 | action 70
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.21 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.22 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']:  <lrm_rsc_op id="global_rsc_DEV_CPU_monitor_10000" operation_key="global_rsc_DEV_CPU_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="70:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="-1:193;70:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_CPU']
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/269, version=1.582.22)
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.22
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:stop call_id:438 pid:22666 exit-code:0 exec-time:381ms queue-time:0ms
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_CI on vmi243500: 0 (ok) | call=438 key=fs_DEV_CI_stop_0 confirmed=true cib-update=2482
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2482)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.22 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.23 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;52:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=438, @rc-code=0, @op-status=0, @exec-time=381
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2482, version=1.582.23)
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.23
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_stop_0 (52) confirmed on vmi243500 (rc=0)
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_3_DEV_ASCS_stop_0 locally on vmi243500 | action 45
Jan 26 05:46:01 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_3_DEV_ASCS_monitor_20000
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=45:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_3_DEV_ASCS_stop_0
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:stop call_id:440
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: Cancelled | call=423 key=fs_3_DEV_ASCS_monitor_20000 confirmed=true
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2483)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.23 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.24 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_stop_0, @operation=stop, @transition-key=45:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;45:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013961, @last-rc-change=1580013961, @exe
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.24
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2483, version=1.582.24)
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:stop call_id:440 pid:22739 exit-code:0 exec-time:139ms queue-time:0ms
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=440 key=fs_3_DEV_ASCS_stop_0 confirmed=true cib-update=2484
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2484)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.24 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.25 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;45:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=440, @rc-code=0, @op-status=0, @exec-time=139
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.25
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_stop_0 (45) confirmed on vmi243500 (rc=0)
Jan 26 05:46:01 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_2_DEV_ASCS_stop_0 locally on vmi243500 | action 42
Jan 26 05:46:01 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_2_DEV_ASCS_monitor_20000
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=42:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_2_DEV_ASCS_stop_0
Jan 26 05:46:01 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:stop call_id:442
Jan 26 05:46:01 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: Cancelled | call=421 key=fs_2_DEV_ASCS_monitor_20000 confirmed=true
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2484, version=1.582.25)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2485)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.25 2
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.26 (null)
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_stop_0, @operation=stop, @transition-key=42:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;42:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013961, @last-rc-change=1580013961, @exe
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.26
Jan 26 05:46:01 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:01 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2485, version=1.582.26)
Jan 26 05:46:02 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:stop call_id:442 pid:22812 exit-code:0 exec-time:129ms queue-time:0ms
Jan 26 05:46:02 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=442 key=fs_2_DEV_ASCS_stop_0 confirmed=true cib-update=2486
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2486)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.26 2
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.27 (null)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;42:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=442, @rc-code=0, @op-status=0, @exec-time=129
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_stop_0 (42) confirmed on vmi243500 (rc=0)
Jan 26 05:46:02 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_ASCS00_stop_0 locally on vmi243500 | action 39
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.27
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:02 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation rsc_DEV_ASCS00_monitor_120000
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=39:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_ASCS00_stop_0
Jan 26 05:46:02 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:stop call_id:444
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: Cancelled | call=419 key=rsc_DEV_ASCS00_monitor_120000 confirmed=true
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2486, version=1.582.27)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2487)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.27 2
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.28 (null)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_stop_0, @operation=stop, @transition-key=39:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;39:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013962, @last-rc-change=1580013962, @
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2487, version=1.582.28)
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.28
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:02 [1591] vmi243500       lrmd:   notice: operation_finished:	rsc_DEV_ASCS00_stop_0:22885:stderr [ cleanipc: Command not found. ]
Jan 26 05:46:02 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:stop call_id:444 pid:22885 exit-code:0 exec-time:839ms queue-time:0ms
Jan 26 05:46:02 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=444 key=rsc_DEV_ASCS00_stop_0 confirmed=true cib-update=2488
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2488)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.28 2
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.29 (null)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;39:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=444, @rc-code=0, @op-status=0, @exec-time=839
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_stop_0 (39) confirmed on vmi243500 (rc=0)
Jan 26 05:46:02 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation vip_DEV_ASCS_stop_0 locally on vmi243500 | action 36
Jan 26 05:46:02 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_ASCS_monitor_10000
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.29
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=36:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_ASCS_stop_0
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:02 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_ASCS action:stop call_id:446
Jan 26 05:46:02 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_ASCS on vmi243500: Cancelled | call=355 key=vip_DEV_ASCS_monitor_10000 confirmed=true
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2488, version=1.582.29)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2489)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.29 2
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.30 (null)
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @operation_key=vip_DEV_ASCS_stop_0, @operation=stop, @transition-key=36:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;36:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013962, @last-rc-change=1580013962, @exec-t
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.30
Jan 26 05:46:02 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:02 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2489, version=1.582.30)
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_ASCS action:stop call_id:446 pid:23193 exit-code:0 exec-time:101ms queue-time:0ms
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=446 key=vip_DEV_ASCS_stop_0 confirmed=true cib-update=2490
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2490)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.30 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.31 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:0;36:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=446, @rc-code=0, @op-status=0, @exec-time=101
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2490, version=1.582.31)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.31
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_stop_0 (36) confirmed on vmi243500 (rc=0)
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_ASCS_stop_0 locally on vmi243500 | action 33
Jan 26 05:46:03 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_ASCS_monitor_20000
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=33:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_ASCS_stop_0
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2491)
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_ASCS action:stop call_id:448
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_ASCS on vmi243500: Cancelled | call=353 key=fs_DEV_ASCS_monitor_20000 confirmed=true
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.31 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.32 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @operation_key=fs_DEV_ASCS_stop_0, @operation=stop, @transition-key=33:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;33:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013963, @last-rc-change=1580013963, @exec-time
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.32
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2491, version=1.582.32)
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_ASCS action:stop call_id:448 pid:23243 exit-code:0 exec-time:327ms queue-time:0ms
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=448 key=fs_DEV_ASCS_stop_0 confirmed=true cib-update=2492
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2492)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.32 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.33 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:0;33:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=448, @rc-code=0, @op-status=0, @exec-time=327
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_stop_0 (33) confirmed on vmi243500 (rc=0)
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_ASCS_start_0 on vmi243493 | action 34
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2492, version=1.582.33)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.33
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_sapmnt_stop_0 locally on vmi243500 | action 72
Jan 26 05:46:03 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_sapmnt_monitor_20000
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=72:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_sapmnt_stop_0
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2493)
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:stop call_id:450
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.33 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.34 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_stop_0, @operation=stop, @crm-debug-origin=do_update_resource, @transition-key=72:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;72:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=158001
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: Cancelled | call=85 key=fs_DEV_sapmnt_monitor_20000 confirmed=true
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.34
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2493, version=1.582.34)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.34 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.35 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @operation_key=fs_DEV_ASCS_start_0, @operation=start, @transition-key=34:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;34:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013955, @last-rc-change=1580013955, @exec-time
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.35
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/270, version=1.582.35)
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:stop call_id:450 pid:23316 exit-code:0 exec-time:137ms queue-time:0ms
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=450 key=fs_DEV_sapmnt_stop_0 confirmed=true cib-update=2494
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2494)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.35 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.36 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;72:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=450, @rc-code=0, @op-status=0, @exec-time=137
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_sapmnt_stop_0 (72) confirmed on vmi243500 (rc=0)
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation dlm_DEV_stop_0 locally on vmi243500 | action 71
Jan 26 05:46:03 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation dlm_DEV_monitor_60000
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=71:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=dlm_DEV_stop_0
Jan 26 05:46:03 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:stop call_id:452
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2494, version=1.582.36)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2495)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.36
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.36 2
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: Cancelled | call=83 key=dlm_DEV_monitor_60000 confirmed=true
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.37 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_stop_0, @operation=stop, @crm-debug-origin=do_update_resource, @transition-key=71:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;71:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013963, @last-rc-cha
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2495, version=1.582.37)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.37
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.37 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.38 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:0;34:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=217, @rc-code=0, @op-status=0, @exec-time=186
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/271, version=1.582.38)
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_start_0 (34) confirmed on vmi243493 (rc=0)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.38
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_ASCS_monitor_20000 on vmi243493 | action 35
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_ASCS_start_0 on vmi243493 | action 37
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.38 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.39 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']:  @transition-key=35:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;35:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013955, @exec-time=0
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/272, version=1.582.39)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.39
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.39 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.40 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=40
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @operation_key=vip_DEV_ASCS_start_0, @operation=start, @transition-key=37:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;37:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013955, @last-rc-change=1580013955, @exec-t
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/273, version=1.582.40)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.40
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.40 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.41 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=41
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;35:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=218, @rc-code=0, @op-status=0, @exec-time=70
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_monitor_20000 (35) confirmed on vmi243493 (rc=0)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.41
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/274, version=1.582.41)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.41 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.42 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=42
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:0;37:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=219, @rc-code=0, @op-status=0, @exec-time=115
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_start_0 (37) confirmed on vmi243493 (rc=0)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.42
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_ASCS_monitor_10000 on vmi243493 | action 38
Jan 26 05:46:03 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_ASCS00_start_0 on vmi243493 | action 40
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/275, version=1.582.42)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.42 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.43 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=43
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']:  @transition-key=38:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;38:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013955, @exec-time=0
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/276, version=1.582.43)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.43 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.44 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_start_0, @operation=start, @transition-key=40:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;40:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013955, @last-rc-change=1580013955, @
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/277, version=1.582.44)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.43
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.44
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.44 2
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.45 (null)
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']:  @transition-magic=0:0;38:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=220, @rc-code=0, @op-status=0, @exec-time=59
Jan 26 05:46:03 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_monitor_10000 (38) confirmed on vmi243493 (rc=0)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.45
Jan 26 05:46:03 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/278, version=1.582.45)
Jan 26 05:46:03 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:04 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243493]: (null) -> green from vmi243493
Jan 26 05:46:04 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.45 2
Jan 26 05:46:04 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.46 (null)
Jan 26 05:46:04 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Jan 26 05:46:04 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-magic=0:0;70:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=216, @rc-code=0, @op-status=0, @exec-time=3246
Jan 26 05:46:04 [1594] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_monitor_10000 (70) confirmed on vmi243493 (rc=0)
Jan 26 05:46:04 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Jan 26 05:46:04 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.46
Jan 26 05:46:04 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/279, version=1.582.46)
Jan 26 05:46:04 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:05 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:stop call_id:452 pid:23367 exit-code:0 exec-time:2094ms queue-time:0ms
Jan 26 05:46:05 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for dlm_DEV on vmi243500: 0 (ok) | call=452 key=dlm_DEV_stop_0 confirmed=true cib-update=2496
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2496)
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.46 2
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.47 (null)
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;71:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=452, @rc-code=0, @op-status=0, @exec-time=2094
Jan 26 05:46:05 [1594] vmi243500       crmd:     info: match_graph_event:	Action dlm_DEV_stop_0 (71) confirmed on vmi243500 (rc=0)
Jan 26 05:46:05 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_database_stop_0 locally on vmi243500 | action 26
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.47
Jan 26 05:46:05 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation rsc_DEV_database_monitor_120000
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:05 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=rsc_DEV_database_stop_0
Jan 26 05:46:05 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:stop call_id:454
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2496, version=1.582.47)
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2497)
Jan 26 05:46:05 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: Cancelled | call=411 key=rsc_DEV_database_monitor_120000 confirmed=true
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.47 2
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.48 (null)
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=48
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_stop_0, @operation=stop, @transition-key=26:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;26:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013965, @last-rc-change=1580013
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.48
Jan 26 05:46:05 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2497, version=1.582.48)
Jan 26 05:46:05 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:10 [1589] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: f5b5ee1c25d1ec10cc2b8286b7aeb2ed for 1.582.48 (0x55b8bb66deb0 0)
Jan 26 05:46:34 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:stop call_id:454 pid:23386 exit-code:0 exec-time:28920ms queue-time:0ms
Jan 26 05:46:34 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_database on vmi243500: 0 (ok) | call=454 key=rsc_DEV_database_stop_0 confirmed=true cib-update=2498
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2498)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.48 2
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.49 (null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=49
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;26:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=454, @rc-code=0, @op-status=0, @exec-time=28920
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_stop_0 (26) confirmed on vmi243500 (rc=0)
Jan 26 05:46:34 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation vip_DEV_database_stop_0 locally on vmi243500 | action 23
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.49
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:34 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_database_monitor_10000
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=vip_DEV_database_stop_0
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2498, version=1.582.49)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2499)
Jan 26 05:46:34 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:stop call_id:456
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: Cancelled | call=394 key=vip_DEV_database_monitor_10000 confirmed=true
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.49 2
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.50 (null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=50
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_stop_0, @operation=stop, @transition-key=23:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;23:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013994, @last-rc-change=1580013
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2499, version=1.582.50)
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.50
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:34 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:stop call_id:456 pid:24008 exit-code:0 exec-time:112ms queue-time:0ms
Jan 26 05:46:34 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_database on vmi243500: 0 (ok) | call=456 key=vip_DEV_database_stop_0 confirmed=true cib-update=2500
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2500)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.50 2
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.51 (null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=51
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;23:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=456, @rc-code=0, @op-status=0, @exec-time=112
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_stop_0 (23) confirmed on vmi243500 (rc=0)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2500, version=1.582.51)
Jan 26 05:46:34 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation fs_DEV_database_stop_0 locally on vmi243500 | action 20
Jan 26 05:46:34 [1591] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_database_monitor_20000
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.51
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=20:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 op=fs_DEV_database_stop_0
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:34 [1591] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:stop call_id:458
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2501)
Jan 26 05:46:34 [1594] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: Cancelled | call=392 key=fs_DEV_database_monitor_20000 confirmed=true
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.51 2
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.52 (null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=52
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_stop_0, @operation=stop, @transition-key=20:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;20:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013994, @last-rc-change=1580013994
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2501, version=1.582.52)
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.52
Jan 26 05:46:34 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:34 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 193 with 2 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/193)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.52 2
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.53 (null)
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=53
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']:  <nvpair id="status-96317541-.health-cpu" name="#health-cpu" value="green"/>
Jan 26 05:46:34 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/193, version=1.582.53)
Jan 26 05:46:34 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 193 for #health-cpu: OK (0)
Jan 26 05:46:34 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1626 aborted by status-96317541-.health-cpu doing create #health-cpu=green: Transient attribute change | cib=1.582.53 source=abort_unless_down:330 path=/cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541'] complete=false
Jan 26 05:46:34 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 193 for #health-cpu[vmi243493]=green: OK (0)
Jan 26 05:46:34 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 193 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:46:36 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.53 2
Jan 26 05:46:36 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.54 (null)
Jan 26 05:46:36 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=54
Jan 26 05:46:36 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;40:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=221, @rc-code=0, @op-status=0, @exec-time=32717
Jan 26 05:46:36 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/280, version=1.582.54)
Jan 26 05:46:36 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_start_0 (40) confirmed on vmi243493 (rc=0)
Jan 26 05:46:36 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:46:36 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.54
Jan 26 05:46:36 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:24058:stderr [ umount: /sapdb: target is busy. ]
Jan 26 05:46:38 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:24058:stderr [ ocf-exit-reason:Couldn't unmount /sapdb; trying cleanup with TERM ]
Jan 26 05:46:38 [1591] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_database_stop_0:24058:stderr [ /usr/lib/ocf/resource.d/heartbeat/Filesystem: line 497: kill: (15848) - No such process ]
Jan 26 05:46:38 [1591] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:stop call_id:458 pid:24058 exit-code:0 exec-time:3970ms queue-time:0ms
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_database on vmi243500: 0 (ok) | call=458 key=fs_DEV_database_stop_0 confirmed=true cib-update=2502
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2502)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.54 2
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.55 (null)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=55
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;20:1626:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=458, @rc-code=0, @op-status=0, @exec-time=3970
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2502, version=1.582.55)
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_stop_0 (20) confirmed on vmi243500 (rc=0)
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.55
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1626 (Complete=31, Pending=0, Fired=0, Skipped=4, Incomplete=19, Source=/var/lib/pacemaker/pengine/pe-input-519.bz2): Stopped
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is shutting down
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243493 is active
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: determine_online_status:	Node vmi243493 is online
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_database on vmi243500: not running (7)
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for rsc_DEV_ASCS00 on vmi243500: not running (7)
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op monitor for fs_3_DEV_ASCS on vmi243500: not running (7)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource fs_DEV_CI active on vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: determine_op_status:	Operation monitor found resource rsc_DEV_ERS10 active on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243493: not running (7)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: short_print:	     Started: [ vmi243493 ]
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243500 ]
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243493 after 1000000 failures (max=1000000)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_database has failed 1 times on vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_database can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_ASCS00 has failed 1 times on vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: check_migration_threshold:	rsc_DEV_ASCS00 can fail 999999 more times on vmi243500 before being forced off
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: pe_get_failcount:	fs_3_DEV_ASCS has failed 3 times on vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: check_migration_threshold:	fs_3_DEV_ASCS can fail 999997 more times on vmi243500 before being forced off
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243493
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: stage6:	Scheduling Node vmi243500 for shutdown
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogNodeActions:	 * Shutdown vmi243500
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             (              vmi243493 )  
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Stopped)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243493)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jan 26 05:46:38 [1593] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jan 26 05:46:38 [1593] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 1627, saving inputs in /var/lib/pacemaker/pengine/pe-input-520.bz2
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1627 (ref=pe_calc-dc-1580013998-2136) derived from /var/lib/pacemaker/pengine/pe-input-520.bz2
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_database_start_0 on vmi243493 | action 12
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ASCS00_monitor_120000 on vmi243493 | action 28
Jan 26 05:46:38 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_2_DEV_ASCS_start_0 on vmi243493 | action 29
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: te_crm_command:	Executing crm-event (72): do_shutdown on vmi243500
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: te_crm_command:	crm-event (72) is a local shutdown
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.55 2
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.56 (null)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=56
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_start_0, @operation=start, @transition-key=12:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;12:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013990, @last-rc-change=1580013990
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.56
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/281, version=1.582.56)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.56 2
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.57 (null)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=57
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-key=28:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;28:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013990, @exec-time=0
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.57
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/282, version=1.582.57)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.57 2
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.58 (null)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=58
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_start_0, @operation=start, @transition-key=29:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;29:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013990, @last-rc-change=1580013990, @exe
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/283, version=1.582.58)
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.58
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.58 2
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.59 (null)
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=59
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-magic=0:0;28:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=223, @rc-code=0, @op-status=0, @exec-time=204
Jan 26 05:46:38 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/284, version=1.582.59)
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.59
Jan 26 05:46:38 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:38 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_monitor_120000 (28) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.59 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.60 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=60
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;29:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=224, @rc-code=0, @op-status=0, @exec-time=810
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/285, version=1.582.60)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.60
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_start_0 (29) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_2_DEV_ASCS_monitor_20000 on vmi243493 | action 30
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_3_DEV_ASCS_start_0 on vmi243493 | action 31
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.60 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.61 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=61
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-key=30:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;30:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013991, @exec-time=0, @queue-time=0
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.61
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/286, version=1.582.61)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.61 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.62 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=62
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_start_0, @operation=start, @transition-key=31:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;31:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013991, @last-rc-change=1580013991, @exe
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/287, version=1.582.62)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.62
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.62 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.63 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=63
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;12:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=222, @rc-code=0, @op-status=0, @exec-time=905
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_start_0 (12) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/288, version=1.582.63)
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_database_monitor_20000 on vmi243493 | action 13
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_database_start_0 on vmi243493 | action 14
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.63
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.63 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.64 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=64
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_database']:  <lrm_rsc_op id="fs_DEV_database_monitor_20000" operation_key="fs_DEV_database_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="13:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="-1:193;13:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason=""
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/289, version=1.582.64)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_database']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.64
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.64 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.65 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=65
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;30:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=225, @rc-code=0, @op-status=0, @exec-time=83
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_monitor_20000 (30) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/290, version=1.582.65)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.65 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.66 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=66
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_start_0, @operation=start, @transition-key=14:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;14:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013991, @last-rc-change=1580013
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/291, version=1.582.66)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.65
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.66
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.66 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.67 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=67
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-magic=0:0;13:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=227, @rc-code=0, @op-status=0, @exec-time=101
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/292, version=1.582.67)
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_monitor_20000 (13) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.67
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.67 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.68 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=68
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;14:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=228, @rc-code=0, @op-status=0, @exec-time=153, @queue-time=1
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_start_0 (14) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_database_monitor_10000 on vmi243493 | action 15
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_database_start_0 on vmi243493 | action 16
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.68
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/293, version=1.582.68)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.68 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.69 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=69
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_database']:  <lrm_rsc_op id="vip_DEV_database_monitor_10000" operation_key="vip_DEV_database_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="-1:193;15:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/294, version=1.582.69)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.69 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.70 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=70
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @transition-key=16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013991, @last-rc-change=1580013
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_database']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.69
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/295, version=1.582.70)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.70
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.70 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.71 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=71
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-magic=0:0;15:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=229, @rc-code=0, @op-status=0, @exec-time=63
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/296, version=1.582.71)
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_monitor_10000 (15) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.71
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.71 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.72 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=72
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;31:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=226, @rc-code=0, @op-status=0, @exec-time=329
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/297, version=1.582.72)
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_start_0 (31) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_3_DEV_ASCS_monitor_20000 on vmi243493 | action 32
Jan 26 05:46:39 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_CI_start_0 on vmi243493 | action 37
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.72 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.73 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=73
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-key=32:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;32:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013992, @exec-time=0
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/298, version=1.582.73)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.73 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.74 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=74
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @transition-key=37:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;37:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013992, @last-rc-change=1580013992, @exec-time=0
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.72
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/299, version=1.582.74)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.73
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.74
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.74 2
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.75 (null)
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=75
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;32:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=231, @rc-code=0, @op-status=0, @exec-time=59
Jan 26 05:46:39 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/300, version=1.582.75)
Jan 26 05:46:39 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_monitor_20000 (32) confirmed on vmi243493 (rc=0)
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.75
Jan 26 05:46:39 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.75 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.76 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=76
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;37:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=232, @rc-code=0, @op-status=0, @exec-time=206
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/301, version=1.582.76)
Jan 26 05:46:40 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_start_0 (37) confirmed on vmi243493 (rc=0)
Jan 26 05:46:40 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_CI_monitor_20000 on vmi243493 | action 38
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.76
Jan 26 05:46:40 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_CI_start_0 on vmi243493 | action 39
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.76 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.77 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=77
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-key=38:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;38:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013992, @exec-time=0
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/302, version=1.582.77)
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.77
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.77 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.78 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=78
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @transition-key=39:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;39:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580013992, @last-rc-change=1580013992, @exec-time=0
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/303, version=1.582.78)
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.78
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.78 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.79 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=79
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;38:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=233, @rc-code=0, @op-status=0, @exec-time=65
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/304, version=1.582.79)
Jan 26 05:46:40 [1594] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_monitor_20000 (38) confirmed on vmi243493 (rc=0)
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.79
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.79 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.80 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=80
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;39:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=234, @rc-code=0, @op-status=0, @exec-time=111
Jan 26 05:46:40 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_start_0 (39) confirmed on vmi243493 (rc=0)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/305, version=1.582.80)
Jan 26 05:46:40 [1594] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_CI_monitor_10000 on vmi243493 | action 40
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.80
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.80 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.81 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=81
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-key=40:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @transition-magic=-1:193;40:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1580013992, @exec-time=0
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.81
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/306, version=1.582.81)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.81 2
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.82 (null)
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=82
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;40:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=235, @rc-code=0, @op-status=0, @exec-time=80
Jan 26 05:46:40 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/307, version=1.582.82)
Jan 26 05:46:40 [1594] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_monitor_10000 (40) confirmed on vmi243493 (rc=0)
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.82
Jan 26 05:46:40 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.82 2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.83 (null)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=83
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:1;16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048, @call-id=230, @rc-code=1, @op-status=0, @exec-time=2523
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_database']:  <lrm_rsc_op id="rsc_DEV_database_last_failure_0" operation_key="rsc_DEV_database_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" transition-magic="0:1;16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048" exit-reason="" on_nod
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/308, version=1.582.83)
Jan 26 05:46:42 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 16 (rsc_DEV_database_start_0) on vmi243493 failed (target: 0 vs. rc: 1): Error
Jan 26 05:46:42 [1594] vmi243500       crmd:   notice: abort_transition_graph:	Transition 1627 aborted by operation rsc_DEV_database_start_0 'modify' on vmi243493: Event failed | magic=0:1;16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.582.83 source=match_graph_event:299 complete=false
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_start_0 (16) confirmed on vmi243493 (rc=1)
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_database on vmi243493 after failed start: rc=1 (update=INFINITY, time=1580014002)
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.83
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1627.16) rsc_DEV_database_start_0.230=unknown error: failed
Jan 26 05:46:42 [1594] vmi243500       crmd:  warning: status_from_rc:	Action 16 (rsc_DEV_database_start_0) on vmi243493 failed (target: 0 vs. rc: 1): Error
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: abort_transition_graph:	Transition 1627 aborted by operation rsc_DEV_database_start_0 'create' on vmi243493: Event failed | magic=0:1;16:1627:0:2987ea60-f77d-4a68-a9ae-82ed6dd18048 cib=1.582.83 source=match_graph_event:299 complete=false
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_start_0 (16) confirmed on vmi243493 (rc=1)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_database on vmi243493 after failed start: rc=1 (update=INFINITY, time=1580014002)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: process_graph_event:	Detected action (1627.16) rsc_DEV_database_start_0.230=unknown error: failed
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:46:42 [1594] vmi243500       crmd:   notice: run_graph:	Transition 1627 (Complete=19, Pending=0, Fired=0, Skipped=0, Incomplete=2, Source=/var/lib/pacemaker/pengine/pe-input-520.bz2): Complete
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_database#start_0[vmi243493]: (null) -> INFINITY from vmi243500
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_log:	Input I_STOP received in state S_TRANSITION_ENGINE from notify_crmd
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_STOPPING | input=I_STOP cause=C_FSA_INTERNAL origin=notify_crmd
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_dc_release:	DC role released
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 194 with 2 changes for fail-count-rsc_DEV_database#start_0, id=<n/a>, set=(null)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_database#start_0[vmi243493]: (null) -> 1580014002 from vmi243500
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: write_attribute:	Sent update 195 with 2 changes for last-failure-rsc_DEV_database#start_0, id=<n/a>, set=(null)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/2504)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/194)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/195)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: pe_ipc_destroy:	Connection to the Policy Engine released
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_te_control:	Transitioner is now inactive
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_shutdown:	Disconnecting STONITH...
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.83 2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.84 (null)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=84
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_dc_release, @expected=down
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/2504, version=1.582.84)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: tengine_stonith_connection_destroy:	Fencing daemon disconnected
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_lrm_control:	Disconnecting from the LRM
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: lrmd_api_disconnect:	Disconnecting IPC LRM connection to local
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: lrmd_ipc_connection_destroy:	IPC connection destroyed
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: lrm_connection_destroy:	LRM Connection disconnected
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: lrmd_api_disconnect:	Disconnecting IPC LRM connection to local
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.84 2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.85 (null)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=85
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']:  <nvpair id="status-96317541-fail-count-rsc_DEV_database.start_0" name="fail-count-rsc_DEV_database#start_0" value="INFINITY"/>
Jan 26 05:46:42 [1594] vmi243500       crmd:   notice: do_lrm_control:	Disconnected from the LRM
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/194, version=1.582.85)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 194 for fail-count-rsc_DEV_database#start_0: OK (0)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 194 for fail-count-rsc_DEV_database#start_0[vmi243493]=INFINITY: OK (0)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 194 for fail-count-rsc_DEV_database#start_0[vmi243500]=(null): OK (0)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.85 2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.86 (null)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=86
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']:  <nvpair id="status-96317541-last-failure-rsc_DEV_database.start_0" name="last-failure-rsc_DEV_database#start_0" value="1580014002"/>
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/195, version=1.582.86)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 195 for last-failure-rsc_DEV_database#start_0: OK (0)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 195 for last-failure-rsc_DEV_database#start_0[vmi243493]=1580014002: OK (0)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_callback:	Update 195 for last-failure-rsc_DEV_database#start_0[vmi243500]=(null): OK (0)
Jan 26 05:46:42 [1594] vmi243500       crmd:   notice: terminate_cs_connection:	Disconnected from Corosync
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_ha_control:	Disconnected from the cluster
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_cib_control:	Disconnecting CIB
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.86 2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.87 36580d96a36e9d2c257caface2d3ef53
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=87
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes: OK (rc=0, origin=vmi243493/crmd/309, version=1.582.87)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_cib_connection_destroy:	Connection to the CIB terminated...
Jan 26 05:46:42 [1594] vmi243500       crmd:   notice: do_cib_control:	Disconnected from the CIB
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_exit:	Performing A_EXIT_0 - gracefully exiting the CRMd
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: do_exit:	[crmd] stopped (0)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_exit:	Dropping I_RELEASE_SUCCESS: [ state=S_STOPPING cause=C_FSA_INTERNAL origin=do_dc_release ]
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_exit:	Dropping I_TERMINATE: [ state=S_STOPPING cause=C_FSA_INTERNAL origin=do_stop ]
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_cs_destroy:	Corosync connection closed
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_cs_destroy:	Corosync connection closed
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crmd_init:	crmd[1594] exiting with status 0 (OK)
Jan 26 05:46:42 [1594] vmi243500       crmd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	crmd[1594] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping pengine | sent signal 15 to process 1593
Jan 26 05:46:42 [1593] vmi243500    pengine:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:46:42 [1593] vmi243500    pengine:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1593] vmi243500    pengine:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	pengine[1593] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping attrd | sent signal 15 to process 1592
Jan 26 05:46:42 [1592] vmi243500      attrd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: main:	Shutting down attribute manager
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: attrd_cib_destroy_cb:	Connection disconnection complete
Jan 26 05:46:42 [1592] vmi243500      attrd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243493/crmd/311, version=1.582.87)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	attrd[1592] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping lrmd | sent signal 15 to process 1591
Jan 26 05:46:42 [1591] vmi243500       lrmd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:46:42 [1591] vmi243500       lrmd:     info: lrmd_exit:	Terminating with 0 clients
Jan 26 05:46:42 [1591] vmi243500       lrmd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1591] vmi243500       lrmd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/313, version=1.582.87)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/315, version=1.582.87)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	lrmd[1591] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping stonith-ng | sent signal 15 to process 1590
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: stonith_shutdown:	Terminating with 0 clients
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: cib_connection_destroy:	Connection to the CIB closed.
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/317, version=1.582.87)
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: main:	Done
Jan 26 05:46:42 [1590] vmi243500 stonith-ng:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	stonith-ng[1590] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: stop_child:	Stopping cib | sent signal 15 to process 1589
Jan 26 05:46:42 [1589] vmi243500        cib:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_shutdown:	All clients disconnected (0)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: initiate_exit:	Sending disconnect notification to 2 peers...
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_shutdown:	Disconnected 1 clients
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_shutdown:	All clients disconnected (0)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: initiate_exit:	Sending disconnect notification to 2 peers...
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_shutdown_req:	Peer vmi243500 is requesting to shut down
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243493: 36580d96a36e9d2c257caface2d3ef53
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_replace:	Replaced 1.582.87 with 1.582.87 from vmi243493
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	cib_perform_op: Local-only Change: 1.582.87
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @cib-last-written=Sun Jan 26 05:30:47 2020
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_replace_notify:	Local-only Replace: 1.582.87 from vmi243493
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243493/crmd/321, version=1.582.87)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/322, version=1.582.87)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_shutdown_req:	Peer vmi243500 is requesting to shut down
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_process_shutdown_req:	Peer vmi243500 has acknowledged our shutdown request
Jan 26 05:46:42 [1589] vmi243500        cib:     info: terminate_cib:	cib_process_shutdown_req: Exiting from mainloop...
Jan 26 05:46:42 [1589] vmi243500        cib:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jan 26 05:46:42 [1589] vmi243500        cib:   notice: terminate_cs_connection:	Disconnected from Corosync
Jan 26 05:46:42 [1589] vmi243500        cib:     info: crm_get_peer:	Created entry 6afac23f-4cac-454a-9e8f-2594c589191f/0x55b8bb97e6d0 for node vmi243500/0 (1 total)
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cib_peer_update_callback:	No more peers
Jan 26 05:46:42 [1589] vmi243500        cib:     info: terminate_cib:	cib_peer_update_callback: Exiting from mainloop...
Jan 26 05:46:42 [1589] vmi243500        cib:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jan 26 05:46:42 [1589] vmi243500        cib:     info: cluster_disconnect_cpg:	No CPG connection
Jan 26 05:46:42 [1589] vmi243500        cib:   notice: terminate_cs_connection:	Disconnected from Corosync
Jan 26 05:46:42 [1589] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1589] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1589] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1589] vmi243500        cib:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: pcmk_child_exit:	cib[1589] exited with status 0 (OK)
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:   notice: pcmk_shutdown_worker:	Shutdown complete
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jan 26 05:46:42 [1585] vmi243500 pacemakerd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: get_cluster_type:	Detected an active 'corosync' cluster
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: mcp_read_config:	Reading configure for stack: corosync
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:   notice: main:	Starting Pacemaker 1.1.18+20180430.b12c320f5-lp150.1.4 | build=b12c320f5 features: generated-manpages agent-manpages ncurses libqb-logging libqb-ipc lha-fencing systemd nagios  corosync-native atomic-attrd acls cibsecrets
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: main:	Maximum core file size is: 18446744073709551615
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: qb_ipcs_us_publish:	server name: pacemakerd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry ac35b56c-fd41-4b4d-ae0f-1b09c10bb9c9/0x55b1a24930d0 for node (null)/771304931 (1 total)
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:   notice: cluster_connect_quorum:	Quorum acquired
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process cib
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1654 for process cib
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1655 for process stonith-ng
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1656 for process lrmd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process attrd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1657 for process attrd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process pengine
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1658 for process pengine
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process crmd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: start_child:	Forked child 1659 for process crmd
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: main:	Starting mainloop
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Quorum retained | membership=944 members=2
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry 8be9f6c4-7687-46f3-93b0-b678f12fd46e/0x55b1a2795460 for node (null)/96317541 (2 total)
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jan 26 05:47:21 [1654] vmi243500        cib:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:21 [1654] vmi243500        cib:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jan 26 05:47:21 [1654] vmi243500        cib:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jan 26 05:47:21 [1654] vmi243500        cib:     info: retrieveCib:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.xml (digest: /var/lib/pacemaker/cib/cib.xml.sig)
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:21 [1644] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Jan 26 05:47:22 [1654] vmi243500        cib:     info: validate_with_relaxng:	Creating RNG parser context
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 joined group pacemakerd (counter=0.0)
Jan 26 05:47:22 [1644] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=0.0)
Jan 26 05:47:22 [1656] vmi243500       lrmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:22 [1656] vmi243500       lrmd:     info: qb_ipcs_us_publish:	server name: lrmd
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:22 [1656] vmi243500       lrmd:     info: main:	Starting
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: main:	Starting up
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jan 26 05:47:22 [1657] vmi243500      attrd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jan 26 05:47:22 [1659] vmi243500       crmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:22 [1659] vmi243500       crmd:     info: main:	CRM Git Version: 1.1.18+20180430.b12c320f5-lp150.1.4 (b12c320f5)
Jan 26 05:47:22 [1659] vmi243500       crmd:     info: do_log:	Input I_STARTUP received in state S_STARTING from crmd_init
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jan 26 05:47:22 [1658] vmi243500    pengine:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1657] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: crm_get_peer:	Created entry 432353cf-b9e5-420b-9252-0aaa45565125/0x563c3550e260 for node (null)/771304931 (1 total)
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jan 26 05:47:22 [1657] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: init_cs_connection_once:	Connection to 'corosync': established
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1657] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jan 26 05:47:22 [1654] vmi243500        cib:     info: startCib:	CIB Initialization completed successfully
Jan 26 05:47:22 [1654] vmi243500        cib:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry 4200238e-44d5-437a-91d7-fdf606616d18/0x558006ff1180 for node (null)/771304931 (1 total)
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:22 [1658] vmi243500    pengine:     info: qb_ipcs_us_publish:	server name: pengine
Jan 26 05:47:22 [1658] vmi243500    pengine:     info: main:	Starting pengine
Jan 26 05:47:22 [1657] vmi243500      attrd:     info: main:	Cluster connection active
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: init_cs_connection_once:	Connection to 'corosync': established
Jan 26 05:47:22 [1654] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1654] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jan 26 05:47:22 [1654] vmi243500        cib:     info: crm_get_peer:	Created entry 8b5f9482-727c-4800-9507-2e4244880aea/0x5597ab776270 for node (null)/771304931 (1 total)
Jan 26 05:47:22 [1654] vmi243500        cib:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jan 26 05:47:22 [1654] vmi243500        cib:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jan 26 05:47:22 [1654] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:22 [1654] vmi243500        cib:     info: init_cs_connection_once:	Connection to 'corosync': established
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:22 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jan 26 05:47:22 [1654] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:22 [1654] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:22 [1654] vmi243500        cib:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jan 26 05:47:22 [1654] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_ro
Jan 26 05:47:22 [1654] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_rw
Jan 26 05:47:22 [1654] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_shm
Jan 26 05:47:22 [1654] vmi243500        cib:     info: cib_init:	Starting cib mainloop
Jan 26 05:47:22 [1654] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 joined group cib (counter=0.0)
Jan 26 05:47:22 [1654] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=0.0)
Jan 26 05:47:22 [1654] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-84.raw
Jan 26 05:47:22 [1654] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.582.0 of the CIB to disk (digest: 493c380dd5f7d04b3ec9e174e5596b96)
Jan 26 05:47:22 [1654] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.JuGyRg (digest: /var/lib/pacemaker/cib/cib.kTqrES)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_get_peer:	Created entry 5e4da4b4-7547-4ead-93d0-904b9d78c859/0x55a54df97430 for node (null)/771304931 (1 total)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: init_cs_connection_once:	Connection to 'corosync': established
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now in unknown state
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: attrd_erase_attrs:	Clearing transient attributes from CIB | xpath=//node_state[@uname='vmi243500']/transient_attributes
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: attrd_client_update:	Starting an election to determine the writer
Jan 26 05:47:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes to all (origin=local/attrd/2)
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: cluster_connect_quorum:	Quorum acquired
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:23 [1657] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: main:	CIB connection active
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: qb_ipcs_us_publish:	server name: attrd
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: main:	Accepting attribute updates
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 joined group attrd (counter=0.0)
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=0.0)
Jan 26 05:47:23 [1654] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:23 [1654] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243500]: (null) -> 2 from vmi243500
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: write_or_elect_attribute:	Starting an election to determine who will write out #attrd-protocol
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: setup_cib:	Watching for stonith topology changes
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: qb_ipcs_us_publish:	server name: stonith-ng
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: main:	Starting stonith-ng mainloop
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 joined group stonith-ng (counter=0.0)
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=0.0)
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: init_cib_cache_cb:	Updating device list from the cib: init
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: election_complete:	Election election-attrd complete
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: write_attribute:	Processed 1 private change for #attrd-protocol, id=<n/a>, set=(null)
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.0
Jan 26 05:47:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes: OK (rc=0, origin=vmi243500/attrd/2, version=1.582.0)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: do_ha_control:	Connected to the cluster
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: lrmd_ipc_connect:	Connecting to lrmd
Jan 26 05:47:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/2)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: do_lrm_control:	LRM connection established
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: do_started:	Delaying start, no membership data (0000000000100000)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: pcmk_quorum_notification:	Quorum retained | membership=944 members=2
Jan 26 05:47:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/2, version=1.582.0)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_get_peer:	Created entry 59377ad3-c82d-4a92-af6a-e7d499250f11/0x55a54e098d60 for node (null)/96317541 (2 total)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now member (was in unknown state)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: do_started:	Delaying start, Config not read (0000000000000040)
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: qb_ipcs_us_publish:	server name: crmd
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: do_started:	The local CRM is operational
Jan 26 05:47:23 [1659] vmi243500       crmd:     info: do_log:	Input I_PENDING received in state S_STARTING from do_started
Jan 26 05:47:23 [1659] vmi243500       crmd:   notice: do_state_transition:	State transition S_STARTING -> S_PENDING | input=I_PENDING cause=C_FSA_INTERNAL origin=do_started
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 joined group pacemakerd (counter=1.0)
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 still member of group pacemakerd (peer=(null), counter=1.0)
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=1.1)
Jan 26 05:47:23 [1644] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 joined group attrd (counter=1.0)
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1657] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: crm_get_peer:	Created entry f57485e2-4a20-4db7-bf17-a1b3c241bd1b/0x563c35614960 for node (null)/96317541 (2 total)
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 still member of group attrd (peer=(null), counter=1.0)
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jan 26 05:47:23 [1657] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:23 [1657] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=1.1)
Jan 26 05:47:23 [1654] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 joined group cib (counter=1.0)
Jan 26 05:47:23 [1654] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:23 [1654] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:23 [1654] vmi243500        cib:     info: crm_get_peer:	Created entry 7b837587-52f0-4885-b90d-c367a0b3402f/0x5597ab800cc0 for node (null)/96317541 (2 total)
Jan 26 05:47:23 [1654] vmi243500        cib:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jan 26 05:47:23 [1654] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 still member of group cib (peer=(null), counter=1.0)
Jan 26 05:47:23 [1654] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jan 26 05:47:23 [1654] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:23 [1654] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=1.1)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: stonith_device_register:	Added 'stonith-sbd' to the device list (1 active devices)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 joined group stonith-ng (counter=1.0)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry 04b2fbad-abb2-4905-8787-96276de541f4/0x5580071a9e60 for node (null)/96317541 (2 total)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 still member of group stonith-ng (peer=(null), counter=1.0)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=1.1)
Jan 26 05:47:24 [1655] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jan 26 05:47:24 [1659] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 joined group crmd (counter=0.0)
Jan 26 05:47:24 [1659] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=0.0)
Jan 26 05:47:25 [1657] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jan 26 05:47:25 [1654] vmi243500        cib:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jan 26 05:47:25 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243493]: (null) -> 2 from vmi243493
Jan 26 05:47:25 [1657] vmi243500      attrd:     info: write_attribute:	Processed 2 private changes for #attrd-protocol, id=<n/a>, set=(null)
Jan 26 05:47:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243493/attrd/2, version=1.582.0)
Jan 26 05:47:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/2, version=1.582.0)
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 joined group crmd (counter=1.0)
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jan 26 05:47:25 [1659] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 still member of group crmd (peer=(null), counter=1.0)
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=1.1)
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jan 26 05:47:25 [1659] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243493 is now member
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: crm_timer_popped:	Election Trigger (I_DC_TIMEOUT) just popped (20000ms)
Jan 26 05:47:44 [1659] vmi243500       crmd:  warning: do_log:	Input I_DC_TIMEOUT received in state S_PENDING from crm_timer_popped
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_state_transition:	State transition S_PENDING -> S_ELECTION | input=I_DC_TIMEOUT cause=C_TIMER_POPPED origin=crm_timer_popped
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: election_count_vote:	Election 1 (owner: 96317541) lost: vote from vmi243493 (Uptime)
Jan 26 05:47:44 [1659] vmi243500       crmd:   notice: do_state_transition:	State transition S_ELECTION -> S_PENDING | input=I_PENDING cause=C_FSA_INTERNAL origin=do_election_count_vote
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_dc_release:	DC role released
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_te_control:	Transitioner is now inactive
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_log:	Input I_RELEASE_SUCCESS received in state S_PENDING from do_dc_release
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243493/crmd/6, version=1.582.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/8, version=1.582.0)
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: update_dc:	Set DC to vmi243493 (3.1.0)
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: crm_update_peer_expected:	update_dc: Node vmi243493[96317541] - expected state is now member (was (null))
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: election_count_vote:	Election 2 (owner: 96317541) lost: vote from vmi243493 (Uptime)
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: update_dc:	Unset DC. Was vmi243493
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_log:	Input I_PENDING received in state S_PENDING from do_election_count_vote
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: update_dc:	Set DC to vmi243493 (3.1.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/10, version=1.582.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243493/crmd/12, version=1.582.0)
Jan 26 05:47:44 [1659] vmi243500       crmd:     info: do_log:	Input I_NOT_DC received in state S_PENDING from do_cl_join_finalize_respond
Jan 26 05:47:44 [1659] vmi243500       crmd:   notice: do_state_transition:	State transition S_PENDING -> S_NOT_DC | input=I_NOT_DC cause=C_HA_MESSAGE origin=do_cl_join_finalize_respond
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243493: 41c8c56a6af90dd3167247aa19361885
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_replace:	Replaced 1.582.0 with 1.582.0 from vmi243493
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	cib_perform_op: Local-only Change: 1.582.0
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @cib-last-written=Sun Jan 26 05:46:34 2020
Jan 26 05:47:44 [1655] vmi243500 stonith-ng:   notice: xml_patch_version_check:	Versions did not change in patch 1.582.0
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_replace_notify:	Local-only Replace: 1.582.0 from vmi243493
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243493/crmd/16, version=1.582.0)
Jan 26 05:47:44 [1657] vmi243500      attrd:   notice: attrd_cib_replaced_cb:	Updating all attributes after cib_refresh_notify event
Jan 26 05:47:44 [1657] vmi243500      attrd:     info: write_attribute:	Processed 2 private changes for #attrd-protocol, id=<n/a>, set=(null)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/17, version=1.582.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/18, version=1.582.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243493/crmd/19, version=1.582.0)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.0 2
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.1 (null)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="96317541" uname="vmi243493" in_ccm="true" crmd="online" crm-debug-origin="do_lrm_query_internal"/>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                 <lrm id="96317541">
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                   <lrm_resources/>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                 </lrm>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++               </node_state>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/20, version=1.582.1)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/lrm: OK (rc=0, origin=vmi243493/crmd/21, version=1.582.1)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.1 2
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.2 (null)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="771304931" uname="vmi243500" in_ccm="true" crmd="online" crm-debug-origin="do_lrm_query_internal"/>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                 <lrm id="771304931">
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                   <lrm_resources/>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++                 </lrm>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	++               </node_state>
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/22, version=1.582.2)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/25, version=1.582.2)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.2 2
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.3 (null)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_state_transition, @join=member, @expected=member
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_state_transition, @join=member, @expected=member
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/26, version=1.582.3)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.3 2
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.4 (null)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4, @dc-uuid=96317541
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243493/crmd/27, version=1.582.4)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-85.raw
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.582.0 of the CIB to disk (digest: ce3a175038fda1076a727c850edc44f6)
Jan 26 05:47:44 [1654] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.DPCBe0 (digest: /var/lib/pacemaker/cib/cib.hLH3Bs)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'stonith-sbd' not found (0 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'stonith-sbd' to the rsc list (1 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=20:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=stonith-sbd_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/8)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.4 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.5 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_update_resource
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="2:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;2:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/30, version=1.582.5)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_database' not found (1 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_database' to the rsc list (2 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.5 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.6 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_update_resource
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="20:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;20:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_database_monitor_0
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.5
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/8, version=1.582.6)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.6
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed Filesystem_meta-data_0 process 1783 exited with rc=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/9)
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for stonith-sbd on vmi243500: 7 (not running) | call=5 key=stonith-sbd_monitor_0 confirmed=true cib-update=10
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/10)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.6 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.7 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="21:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;21:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" o
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/9, version=1.582.7)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.7
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.7 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.8 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:7;20:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=5, @rc-code=7, @op-status=0, @exec-time=2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/10, version=1.582.8)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.8
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_database' not found (2 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_database' to the rsc list (3 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_database_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.8 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.9 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="3:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;3:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-st
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/31, version=1.582.9)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.9
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.9 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.10 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="4:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;4:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/32, version=1.582.10)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.10
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed IPaddr2_meta-data_0 process 1792 exited with rc=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/11)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_database' not found (3 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_database' to the rsc list (4 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.10 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.11 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="22:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;22:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193"
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_database_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/11, version=1.582.11)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.11
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.11 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.12 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="5:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;5:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/33, version=1.582.12)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.12
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.12 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.13 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;6:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/34, version=1.582.13)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.13
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.13 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.14 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="7:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;7:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/35, version=1.582.14)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.14
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed SAPDatabase_meta-data_0 process 1814 exited with rc=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/12)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.14 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.15 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="23:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;23:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193"
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_ASCS' not found (4 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_ASCS' to the rsc list (5 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=24:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_ASCS_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/12, version=1.582.15)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.15
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/13)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.15 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.16 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="24:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;24:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/13, version=1.582.16)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.16
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ASCS' not found (5 active resources)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ASCS' to the rsc list (6 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=25:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_ASCS_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/14)
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_database on vmi243500: 7 (not running) | call=9 key=fs_DEV_database_monitor_0 confirmed=true cib-update=15
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ASCS00' not found (6 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ASCS00' to the rsc list (7 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_ASCS00_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.16 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.17 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="25:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;25:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-stat
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/14, version=1.582.17)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.17
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/15)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.17 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.18 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:7;21:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=9, @rc-code=7, @op-status=0, @exec-time=108
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/15, version=1.582.18)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.18
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.18 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.19 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="8:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;8:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-stat
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/36, version=1.582.19)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.19 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.20 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;9:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/37, version=1.582.20)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.19
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.20 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.21 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:7;2:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=5, @rc-code=7, @op-status=0, @exec-time=2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/38, version=1.582.21)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.21 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.22 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:7;3:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=9, @rc-code=7, @op-status=0, @exec-time=58
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/39, version=1.582.22)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.22 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.23 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:7;4:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=13, @rc-code=7, @op-status=0, @exec-time=55
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/40, version=1.582.23)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.20
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.23 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.24 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:7;6:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=21, @rc-code=7, @op-status=0, @exec-time=64
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/41, version=1.582.24)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.21
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.24 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.25 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:7;5:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=17, @rc-code=7, @op-status=0, @exec-time=78
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/42, version=1.582.25)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.22
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.25 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.26 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @operation_key=stonith-sbd_start_0, @operation=start, @transition-key=38:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;38:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/43, version=1.582.26)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.23
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.24
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.25
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.26
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.26 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.27 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="10:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;10:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-stat
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/44, version=1.582.27)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.27
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.27 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.28 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;11:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1" 
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/45, version=1.582.28)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.28 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.29 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="12:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;12:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/46, version=1.582.29)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.28
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.29
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.29 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.30 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:7;7:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=25, @rc-code=7, @op-status=0, @exec-time=93
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/47, version=1.582.30)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.30 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.31 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="13:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;13:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/48, version=1.582.31)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.30
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.31
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.31 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.32 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="14:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;14:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/49, version=1.582.32)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.32
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed SAPInstance_meta-data_0 process 1870 exited with rc=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/16)
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_database on vmi243500: 7 (not running) | call=13 key=vip_DEV_database_monitor_0 confirmed=true cib-update=17
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.32 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.33 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="26:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;26:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/16, version=1.582.33)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/17)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.33 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.34 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:7;22:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=13, @rc-code=7, @op-status=0, @exec-time=114
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/17, version=1.582.34)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.33
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.34
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_2_DEV_ASCS' not found (7 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_2_DEV_ASCS' to the rsc list (8 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=27:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_2_DEV_ASCS_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/18)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.34 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.35 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="27:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;27:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/18, version=1.582.35)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_3_DEV_ASCS' not found (8 active resources)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.35
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_3_DEV_ASCS' to the rsc list (9 active resources)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=28:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_3_DEV_ASCS_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/19)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=40:0:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_database_start_0
Jan 26 05:47:45 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:start call_id:38
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_CI' not found (9 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_CI' to the rsc list (10 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=29:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_CI_monitor_0
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ASCS on vmi243500: 7 (not running) | call=25 key=vip_DEV_ASCS_monitor_0 confirmed=true cib-update=22
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_ASCS on vmi243500: 7 (not running) | call=21 key=fs_DEV_ASCS_monitor_0 confirmed=true cib-update=23
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.35 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.36 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="28:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;28:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.36
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/19, version=1.582.36)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/20)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/21)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/22)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/23)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.36 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.37 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_start_0, @operation=start, @transition-key=40:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;40:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.37
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/20, version=1.582.37)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.37 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.38 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="29:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;29:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.38
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/21, version=1.582.38)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.38 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.39 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:7;25:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=25, @rc-code=7, @op-status=0, @exec-time=116
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/22, version=1.582.39)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.39 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.40 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=40
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:7;24:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=21, @rc-code=7, @op-status=0, @exec-time=134
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.39
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/23, version=1.582.40)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.40 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.41 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=41
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:7;8:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=29, @rc-code=7, @op-status=0, @exec-time=139
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/50, version=1.582.41)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.40
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_database on vmi243500: 7 (not running) | call=17 key=rsc_DEV_database_monitor_0 confirmed=true cib-update=24
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_CI' not found (10 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/24)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_CI' to the rsc list (11 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=30:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_CI_monitor_0
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.41
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.41 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.42 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=42
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;15:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-stat
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/51, version=1.582.42)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (11 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.42 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.43 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=43
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:7;9:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=33, @rc-code=7, @op-status=0, @exec-time=145
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (12 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/52, version=1.582.43)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=31:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_CI_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.43 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.44 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:7;23:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=17, @rc-code=7, @op-status=0, @exec-time=175, @queue-time=1
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/24, version=1.582.44)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/25)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/26)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.44 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.45 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="30:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;30:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/25, version=1.582.45)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.45 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.46 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="31:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;31:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/26, version=1.582.46)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ERS' not found (12 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ERS' to the rsc list (13 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=32:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_ERS_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/27)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.42
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.43
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.44
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.45
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.46
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.46 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.47 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="32:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;32:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/27, version=1.582.47)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.47
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.47 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.48 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=48
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="16:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;16:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="19
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/53, version=1.582.48)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.48
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.48 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.49 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=49
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:7;11:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=42, @rc-code=7, @op-status=0, @exec-time=148
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/54, version=1.582.49)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.49 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.50 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=50
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:7;14:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=54, @rc-code=7, @op-status=0, @exec-time=131
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/55, version=1.582.50)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.49
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.50 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.51 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=51
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:7;10:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=38, @rc-code=7, @op-status=0, @exec-time=173
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/56, version=1.582.51)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.51 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.52 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=52
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:7;12:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=46, @rc-code=7, @op-status=0, @exec-time=167
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/57, version=1.582.52)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.50
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.51
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ASCS00 on vmi243500: 7 (not running) | call=29 key=rsc_DEV_ASCS00_monitor_0 confirmed=true cib-update=28
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/28)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.52
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.52 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.53 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=53
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;13:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=50, @rc-code=7, @op-status=0, @exec-time=176
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_3_DEV_ASCS on vmi243500: 7 (not running) | call=37 key=fs_3_DEV_ASCS_monitor_0 confirmed=true cib-update=29
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/58, version=1.582.53)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.53 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.54 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=54
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:7;26:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=29, @rc-code=7, @op-status=0, @exec-time=156
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.53
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/28, version=1.582.54)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/29)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.54
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.54 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.55 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=55
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:7;28:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=37, @rc-code=7, @op-status=0, @exec-time=139
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_2_DEV_ASCS on vmi243500: 7 (not running) | call=33 key=fs_2_DEV_ASCS_monitor_0 confirmed=true cib-update=30
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_CI on vmi243500: 7 (not running) | call=42 key=fs_DEV_CI_monitor_0 confirmed=true cib-update=31
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/29, version=1.582.55)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/30)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/31)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.55
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.55 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.56 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=56
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:7;27:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=33, @rc-code=7, @op-status=0, @exec-time=156
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/30, version=1.582.56)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.56
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.56 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.57 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=57
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:7;29:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=42, @rc-code=7, @op-status=0, @exec-time=146
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/31, version=1.582.57)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.57
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ERS on vmi243500: 7 (not running) | call=54 key=vip_DEV_ERS_monitor_0 confirmed=true cib-update=32
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/32)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.57 2
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=50 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=33
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.58 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=58
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:7;32:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=54, @rc-code=7, @op-status=0, @exec-time=104
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/32, version=1.582.58)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/33)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.58
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.58 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.59 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=59
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;17:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="19
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/59, version=1.582.59)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.59
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.59 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.60 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=60
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;31:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=50, @rc-code=7, @op-status=0, @exec-time=118
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/33, version=1.582.60)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.60
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_CI on vmi243500: 7 (not running) | call=46 key=vip_DEV_CI_monitor_0 confirmed=true cib-update=34
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/34)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.60 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.61 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=61
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:7;30:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=46, @rc-code=7, @op-status=0, @exec-time=140
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/34, version=1.582.61)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.61
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.61 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.62 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=62
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="18:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;18:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-status="-1" inte
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/60, version=1.582.62)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.62 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.63 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=63
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources:  <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="19:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;19:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="-1" rc-code="193" op-stat
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                            </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/61, version=1.582.63)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.62
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ERS10' not found (13 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ERS10' to the rsc list (14 active resources)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.63 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.64 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=64
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:7;16:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=62, @rc-code=7, @op-status=0, @exec-time=44
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=33:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_ERS10_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/62, version=1.582.64)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.64 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.65 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=65
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @operation_key=vip_DEV_ERS_start_0, @operation=start, @transition-key=74:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;74:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/63, version=1.582.65)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/35)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_CPU' not found (14 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_CPU' to the rsc list (15 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=34:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_CPU_monitor_0
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.63
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.64
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.65 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.66 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=66
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="33:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;33:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/35, version=1.582.66)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.65
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.66
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.66 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.67 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=67
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:7;17:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=66, @rc-code=7, @op-status=0, @exec-time=52
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/64, version=1.582.67)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.67
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed HealthCPU_meta-data_0 process 2359 exited with rc=0
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_NIC' not found (15 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_NIC' to the rsc list (16 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=35:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_NIC_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/36)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.67 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.68 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=68
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="34:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;34:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/36, version=1.582.68)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.68
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.68 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.69 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=69
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:7;18:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=71, @rc-code=7, @op-status=0, @exec-time=63
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/65, version=1.582.69)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.69
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed ethmonitor_meta-data_0 process 2375 exited with rc=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/37)
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_CPU on vmi243500: 7 (not running) | call=62 key=global_rsc_DEV_CPU_monitor_0 confirmed=true cib-update=38
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV' not found (16 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV:1' not found (16 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'dlm_DEV' to the rsc list (17 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=36:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=dlm_DEV_monitor_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.69 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.70 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=70
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="35:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;35:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/37, version=1.582.70)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/38)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.70
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.70 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.71 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=71
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:7;34:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=62, @rc-code=7, @op-status=0, @exec-time=23
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/38, version=1.582.71)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.71 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.72 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=72
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:7;19:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=76, @rc-code=7, @op-status=0, @exec-time=88
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/66, version=1.582.72)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.71
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: action_synced_wait:	Managed controld_meta-data_0 process 2409 exited with rc=0
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.72
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/39)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt' not found (17 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt:1' not found (17 active resources)
Jan 26 05:47:45 [1656] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_sapmnt' to the rsc list (18 active resources)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=37:0:7:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_sapmnt_monitor_0
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=82:0:0:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_CPU_start_0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.72 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.73 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=73
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="36:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;36:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1" in
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:start call_id:77
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/39, version=1.582.73)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/40)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/41)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.73
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.73 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.74 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=74
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat"/>
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="37:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;37:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.74
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/40, version=1.582.74)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.74 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.75 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=75
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_start_0, @operation=start, @transition-key=82:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;82:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/41, version=1.582.75)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.75
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_NIC on vmi243500: 7 (not running) | call=66 key=global_rsc_DEV_NIC_monitor_0 confirmed=true cib-update=42
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/42)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.75 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.76 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=76
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:7;35:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=66, @rc-code=7, @op-status=0, @exec-time=56
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/42, version=1.582.76)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.76
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ERS10 on vmi243500: 7 (not running) | call=58 key=rsc_DEV_ERS10_monitor_0 confirmed=true cib-update=43
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/43)
Jan 26 05:47:45 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=84:0:0:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_NIC_start_0
Jan 26 05:47:45 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:start call_id:78
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.76 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.77 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=77
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:7;33:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=58, @rc-code=7, @op-status=0, @exec-time=128
Jan 26 05:47:45 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:start call_id:77 pid:2445 exit-code:0 exec-time:36ms queue-time:0ms
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/43, version=1.582.77)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/44)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.77
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:45 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=77 key=global_rsc_DEV_CPU_start_0 confirmed=true cib-update=45
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.77 2
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.78 (null)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=78
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:0;74:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=77, @rc-code=0, @op-status=0, @exec-time=136
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/67, version=1.582.78)
Jan 26 05:47:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/45)
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.78
Jan 26 05:47:45 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.78 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.79 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=79
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']:  <lrm_rsc_op id="vip_DEV_ERS_monitor_10000" operation_key="vip_DEV_ERS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="75:0:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;75:0:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi24349
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/68, version=1.582.79)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.79 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.80 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=80
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_start_0, @operation=start, @transition-key=84:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;84:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ERS']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.79
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/44, version=1.582.80)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.80 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.81 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=81
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;82:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=77, @rc-code=0, @op-status=0, @exec-time=36
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/45, version=1.582.81)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.81 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.82 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=82
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:0;15:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=58, @rc-code=0, @op-status=0, @exec-time=313
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']:  <lrm_rsc_op id="rsc_DEV_ERS10_last_failure_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="0:0;15:0:7:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi24349
Jan 26 05:47:46 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for dlm_DEV on vmi243500: 7 (not running) | call=71 key=dlm_DEV_monitor_0 confirmed=true cib-update=46
Jan 26 05:47:46 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=83:0:0:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_CPU_monitor_10000
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/69, version=1.582.82)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/46)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/47)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.80
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.82 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.83 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=83
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:7;36:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=71, @rc-code=7, @op-status=0, @exec-time=71
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/46, version=1.582.83)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.83 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.84 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=84
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']:  <lrm_rsc_op id="global_rsc_DEV_CPU_monitor_10000" operation_key="global_rsc_DEV_CPU_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="83:0:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;83:0:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reas
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.81
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/47, version=1.582.84)
Jan 26 05:47:46 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_sapmnt on vmi243500: 7 (not running) | call=76 key=fs_DEV_sapmnt_monitor_0 confirmed=true cib-update=48
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/48)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.84 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.85 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=85
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:7;37:0:7:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=76, @rc-code=7, @op-status=0, @exec-time=94
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/48, version=1.582.85)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.82
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:start call_id:38 pid:2011 exit-code:0 exec-time:402ms queue-time:0ms
Jan 26 05:47:46 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_database on vmi243500: 0 (ok) | call=38 key=fs_DEV_database_start_0 confirmed=true cib-update=49
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/49)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.83
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_CPU']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.84
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.85 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.86 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=86
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;40:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=38, @rc-code=0, @op-status=0, @exec-time=402
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/49, version=1.582.86)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.85
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.86 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.87 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=87
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']:  @transition-magic=0:0;75:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=78, @rc-code=0, @op-status=0, @exec-time=66
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/70, version=1.582.87)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.86
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.87
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:46 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: (null) -> 1 from vmi243500
Jan 26 05:47:46 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 4 with 1 changes for ethmonitor-eth0, id=<n/a>, set=(null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/4)
Jan 26 05:47:46 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:start call_id:78 pid:2493 exit-code:0 exec-time:196ms queue-time:0ms
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.87 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.88 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=88
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <transient_attributes id="771304931"/>
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++                                             <instance_attributes id="status-771304931">
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++                                               <nvpair id="status-771304931-ethmonitor-eth0" name="ethmonitor-eth0" value="1"/>
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++                                             </instance_attributes>
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	++                                           </transient_attributes>
Jan 26 05:47:46 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=78 key=global_rsc_DEV_NIC_start_0 confirmed=true cib-update=50
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/4, version=1.582.88)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/50)
Jan 26 05:47:46 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for ethmonitor-eth0: OK (0)
Jan 26 05:47:46 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for ethmonitor-eth0[vmi243500]=1: OK (0)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.88 2
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.89 (null)
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=89
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;84:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=78, @rc-code=0, @op-status=0, @exec-time=196
Jan 26 05:47:46 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/50, version=1.582.89)
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.89
Jan 26 05:47:46 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:47 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.89 2
Jan 26 05:47:47 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.90 (null)
Jan 26 05:47:47 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=90
Jan 26 05:47:47 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:0;38:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=34, @rc-code=0, @op-status=0, @exec-time=1715, @queue-time=1
Jan 26 05:47:47 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/71, version=1.582.90)
Jan 26 05:47:47 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jan 26 05:47:47 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.90
Jan 26 05:47:47 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: (null) -> green from vmi243500
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=79 key=global_rsc_DEV_CPU_monitor_10000 confirmed=false cib-update=51
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/51)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.90 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.91 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=91
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-magic=0:0;83:0:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=79, @rc-code=0, @op-status=0, @exec-time=3233
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/51, version=1.582.91)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.91
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:1:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_database_monitor_20000
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.91 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.92 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=92
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']:  <lrm_rsc_op id="stonith-sbd_monitor_3600000" operation_key="stonith-sbd_monitor_3600000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;6:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/73, version=1.582.92)
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:1:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_database_start_0
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='stonith-sbd']
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.92 2
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.92
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.93 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=93
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']:  <lrm_rsc_op id="rsc_DEV_ERS10_monitor_120000" operation_key="rsc_DEV_ERS10_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="46:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;46:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:start call_id:81
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/74, version=1.582.93)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/52)
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=55:1:0:d961127d-613a-42b7-8bde-7de1f289d35c op=global_rsc_DEV_NIC_monitor_10000
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/53)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.93 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.94 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=94
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']:  <lrm_rsc_op id="fs_DEV_database_monitor_20000" operation_key="fs_DEV_database_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;9:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_no
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/52, version=1.582.94)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ERS10']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.93
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.94 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.95 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=95
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_start_0, @operation=start, @transition-key=10:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;10:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014069, @last-rc-change=1580014069,
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/53, version=1.582.95)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/54)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_database']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.94
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.95 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.96 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=96
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']:  <lrm_rsc_op id="global_rsc_DEV_NIC_monitor_10000" operation_key="global_rsc_DEV_NIC_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="55:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;55:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reas
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/54, version=1.582.96)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.95
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_NIC']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.96
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: 0 (ok) | call=80 key=fs_DEV_database_monitor_20000 confirmed=false cib-update=55
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/55)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.96 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.97 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=97
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-magic=0:0;9:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=80, @rc-code=0, @op-status=0, @exec-time=79
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/55, version=1.582.97)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.97
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:start call_id:81 pid:2703 exit-code:0 exec-time:125ms queue-time:0ms
Jan 26 05:47:49 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_database on vmi243500: 0 (ok) | call=81 key=vip_DEV_database_start_0 confirmed=true cib-update=56
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/56)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.97 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.98 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=98
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;10:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=81, @rc-code=0, @op-status=0, @exec-time=125
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/56, version=1.582.98)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.98
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=11:1:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_database_monitor_10000
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=12:1:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_database_start_0
Jan 26 05:47:49 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:start call_id:84
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/57)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/58)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.98 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.99 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=99
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']:  <lrm_rsc_op id="vip_DEV_database_monitor_10000" operation_key="vip_DEV_database_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;11:1:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" 
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/57, version=1.582.99)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.99 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.100 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=100
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @transition-key=12:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;12:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014069, @last-rc-change=1580014069,
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/58, version=1.582.100)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_database']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.99
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.100
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=82 key=global_rsc_DEV_NIC_monitor_10000 confirmed=false cib-update=59
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/59)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.100 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.101 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=101
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']:  @transition-magic=0:0;55:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=82, @rc-code=0, @op-status=0, @exec-time=174
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/59, version=1.582.101)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.101
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: 0 (ok) | call=83 key=vip_DEV_database_monitor_10000 confirmed=false cib-update=60
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/60)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.101 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.102 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=102
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-magic=0:0;11:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=83, @rc-code=0, @op-status=0, @exec-time=72
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/60, version=1.582.102)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.102
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.102 2
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.103 (null)
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=103
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']:  @transition-magic=0:0;46:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=80, @rc-code=0, @op-status=0, @exec-time=287
Jan 26 05:47:49 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/75, version=1.582.103)
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.103
Jan 26 05:47:49 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:50 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.103 2
Jan 26 05:47:50 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.104 (null)
Jan 26 05:47:50 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=104
Jan 26 05:47:50 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_monitor_3600000']:  @transition-magic=0:0;6:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=79, @rc-code=0, @op-status=0, @exec-time=1588
Jan 26 05:47:50 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/76, version=1.582.104)
Jan 26 05:47:50 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_monitor_3600000']
Jan 26 05:47:50 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.104
Jan 26 05:47:50 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:47:53 [1659] vmi243500       crmd:     info: crm_procfs_pid_of:	Found cib active as process 1654
Jan 26 05:47:53 [1659] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was ffffffff)
Jan 26 05:47:55 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 0572c40855b9bd0c40d92089c289fb97 for 1.582.104 (0x5597ab76f2b0 0)
Jan 26 05:48:19 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 5 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/5)
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.104 2
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.105 (null)
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=105
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-.health-cpu" name="#health-cpu" value="green"/>
Jan 26 05:48:19 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/5, version=1.582.105)
Jan 26 05:48:19 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 5 for #health-cpu: OK (0)
Jan 26 05:48:19 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 5 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:48:24 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: b82a4057899b4ee6a7cf8f4d47732945 for 1.582.105 (0x5597ab76f2b0 0)
Jan 26 05:48:55 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:49:08 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:49:38 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 6 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:49:38 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/6)
Jan 26 05:49:38 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/6, version=1.582.105)
Jan 26 05:49:38 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 6 for #health-cpu: OK (0)
Jan 26 05:49:38 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 6 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:49:43 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: b82a4057899b4ee6a7cf8f4d47732945 for 1.582.105 (0x5597ab76f2b0 0)
Jan 26 05:52:22 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:start call_id:84 pid:2846 exit-code:0 exec-time:273543ms queue-time:0ms
Jan 26 05:52:22 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_database on vmi243500: 0 (ok) | call=84 key=rsc_DEV_database_start_0 confirmed=true cib-update=61
Jan 26 05:52:22 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/61)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.105 2
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.106 (null)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=106
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;12:1:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=84, @rc-code=0, @op-status=0, @exec-time=273543
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/61, version=1.582.106)
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.106
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:23 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=17:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_database_monitor_120000
Jan 26 05:52:23 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=66:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=dlm_DEV_start_0
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.106 2
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.107 (null)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=107
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @transition-key=58:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;58:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014341, @last-rc-change=1580014341, @exec-time=0
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/78, version=1.582.107)
Jan 26 05:52:23 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:start call_id:86
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/62)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/63)
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.107
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.107 2
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.108 (null)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=108
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']:  <lrm_rsc_op id="rsc_DEV_database_monitor_120000" operation_key="rsc_DEV_database_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;17:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/62, version=1.582.108)
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_database']
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.108
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.108 2
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.109 (null)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=109
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @transition-key=66:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;66:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014343, @last-rc-change=1580014343, @exec-time=0
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/63, version=1.582.109)
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.109
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:23 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 0 (ok) | call=85 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=64
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/64)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.109 2
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.110 (null)
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=110
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-magic=0:0;17:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=85, @rc-code=0, @op-status=0, @exec-time=105
Jan 26 05:52:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/64, version=1.582.110)
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.110
Jan 26 05:52:23 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.110 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.111 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=111
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;58:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=81, @rc-code=0, @op-status=0, @exec-time=1132
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/79, version=1.582.111)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.111
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.111 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.112 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=112
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']:  <lrm_rsc_op id="dlm_DEV_monitor_60000" operation_key="dlm_DEV_monitor_60000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="59:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;59:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243493" call-id="
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/80, version=1.582.112)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='dlm_DEV']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.112
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.112 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.113 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=113
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @transition-key=60:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;60:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014342, @last-rc-change=1580014342, @exec-time
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/81, version=1.582.113)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.113
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.113 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.114 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=114
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;59:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=82, @rc-code=0, @op-status=0, @exec-time=36
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/82, version=1.582.114)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.114
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:start call_id:86 pid:7722 exit-code:0 exec-time:1197ms queue-time:0ms
Jan 26 05:52:24 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for dlm_DEV on vmi243500: 0 (ok) | call=86 key=dlm_DEV_start_0 confirmed=true cib-update=65
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/65)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.114 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.115 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=115
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;66:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=86, @rc-code=0, @op-status=0, @exec-time=1197
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.115
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/65, version=1.582.115)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=67:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=dlm_DEV_monitor_60000
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/66)
Jan 26 05:52:24 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=68:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_sapmnt_start_0
Jan 26 05:52:24 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:start call_id:88
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.115 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.116 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=116
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']:  <lrm_rsc_op id="dlm_DEV_monitor_60000" operation_key="dlm_DEV_monitor_60000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="67:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;67:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" call-id
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/66, version=1.582.116)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/67)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='dlm_DEV']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.116
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.116 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.117 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=117
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @transition-key=68:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;68:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014344, @last-rc-change=1580014344, @exec-ti
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/67, version=1.582.117)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.117
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: 0 (ok) | call=87 key=dlm_DEV_monitor_60000 confirmed=false cib-update=68
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/68)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.117 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.118 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=118
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;67:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=87, @rc-code=0, @op-status=0, @exec-time=62
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/68, version=1.582.118)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.118
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.118 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.119 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=119
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;60:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=83, @rc-code=0, @op-status=0, @exec-time=406
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/83, version=1.582.119)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.119
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.119 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.120 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=120
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']:  <lrm_rsc_op id="fs_DEV_sapmnt_monitor_20000" operation_key="fs_DEV_sapmnt_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="61:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;61:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vm
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/84, version=1.582.120)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_sapmnt']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.120
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.120 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.121 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=121
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;61:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=84, @rc-code=0, @op-status=0, @exec-time=63
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/85, version=1.582.121)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.121
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:start call_id:88 pid:7839 exit-code:0 exec-time:692ms queue-time:0ms
Jan 26 05:52:24 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=88 key=fs_DEV_sapmnt_start_0 confirmed=true cib-update=69
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/69)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.121 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.122 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=122
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;68:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=88, @rc-code=0, @op-status=0, @exec-time=692
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/69, version=1.582.122)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.122
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=69:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_sapmnt_monitor_20000
Jan 26 05:52:24 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_ASCS_start_0
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/70)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/71)
Jan 26 05:52:24 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_ASCS action:start call_id:90
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.122 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.123 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=123
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']:  <lrm_rsc_op id="fs_DEV_sapmnt_monitor_20000" operation_key="fs_DEV_sapmnt_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="69:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;69:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/70, version=1.582.123)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.123 2
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.124 (null)
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=124
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @operation_key=fs_DEV_ASCS_start_0, @operation=start, @transition-key=22:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;22:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014344, @last-rc-change=1580014344, @exec-time=0
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_sapmnt']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.123
Jan 26 05:52:24 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/71, version=1.582.124)
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.124
Jan 26 05:52:24 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=89 key=fs_DEV_sapmnt_monitor_20000 confirmed=false cib-update=72
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/72)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.124 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.125 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=125
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;69:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=89, @rc-code=0, @op-status=0, @exec-time=74
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/72, version=1.582.125)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.125
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_ASCS action:start call_id:90 pid:7988 exit-code:0 exec-time:264ms queue-time:0ms
Jan 26 05:52:25 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=90 key=fs_DEV_ASCS_start_0 confirmed=true cib-update=73
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/73)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.125 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.126 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=126
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:0;22:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=90, @rc-code=0, @op-status=0, @exec-time=264
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.126
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/73, version=1.582.126)
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_ASCS_monitor_20000
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/74)
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=24:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_ASCS_start_0
Jan 26 05:52:25 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_ASCS action:start call_id:92
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.126 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.127 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=127
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']:  <lrm_rsc_op id="fs_DEV_ASCS_monitor_20000" operation_key="fs_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="23:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;23:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/74, version=1.582.127)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/75)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_ASCS']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.127
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.127 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.128 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=128
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @operation_key=vip_DEV_ASCS_start_0, @operation=start, @transition-key=24:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;24:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014345, @last-rc-change=1580014345, @exec-time=
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/75, version=1.582.128)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.128
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=91 key=fs_DEV_ASCS_monitor_20000 confirmed=false cib-update=76
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/76)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.128 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.129 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=129
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;23:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=91, @rc-code=0, @op-status=0, @exec-time=71
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/76, version=1.582.129)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.129
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_ASCS action:start call_id:92 pid:8101 exit-code:0 exec-time:108ms queue-time:0ms
Jan 26 05:52:25 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=92 key=vip_DEV_ASCS_start_0 confirmed=true cib-update=77
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/77)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.129 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.130 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=130
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:0;24:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=92, @rc-code=0, @op-status=0, @exec-time=108
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/77, version=1.582.130)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.130
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=25:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_ASCS_monitor_10000
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_ASCS00_start_0
Jan 26 05:52:25 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:start call_id:94
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/78)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/79)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.130 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.131 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=131
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']:  <lrm_rsc_op id="vip_DEV_ASCS_monitor_10000" operation_key="vip_DEV_ASCS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="25:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;25:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/78, version=1.582.131)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.131 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.132 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=132
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_start_0, @operation=start, @transition-key=26:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;26:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014345, @last-rc-change=1580014345, @exec
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/79, version=1.582.132)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ASCS']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.131
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.132
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:25 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=93 key=vip_DEV_ASCS_monitor_10000 confirmed=false cib-update=80
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/80)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.132 2
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.133 (null)
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=133
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']:  @transition-magic=0:0;25:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=93, @rc-code=0, @op-status=0, @exec-time=68
Jan 26 05:52:25 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/80, version=1.582.133)
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.133
Jan 26 05:52:25 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:52:30 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 3ee2401caceb7b250263263c4b656e6b for 1.582.133 (0x5597ab76f2b0 0)
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:start call_id:94 pid:8213 exit-code:0 exec-time:48861ms queue-time:0ms
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/81)
Jan 26 05:53:14 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=94 key=rsc_DEV_ASCS00_start_0 confirmed=true cib-update=81
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.133 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.134 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=134
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;26:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=94, @rc-code=0, @op-status=0, @exec-time=48861
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/81, version=1.582.134)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.134
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=27:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_ASCS00_monitor_120000
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=28:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_2_DEV_ASCS_start_0
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/82)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/83)
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:start call_id:96
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.134 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.135 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=135
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']:  <lrm_rsc_op id="rsc_DEV_ASCS00_monitor_120000" operation_key="rsc_DEV_ASCS00_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="27:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;27:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_n
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/82, version=1.582.135)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.135 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.136 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=136
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_start_0, @operation=start, @transition-key=28:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;28:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014394, @last-rc-change=1580014394, @exec-ti
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/83, version=1.582.136)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ASCS00']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.135
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.136
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:start call_id:96 pid:9827 exit-code:0 exec-time:349ms queue-time:7ms
Jan 26 05:53:14 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=96 key=fs_2_DEV_ASCS_start_0 confirmed=true cib-update=84
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/84)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.136 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.137 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=137
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;28:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=96, @rc-code=0, @op-status=0, @exec-time=349, @queue-time=7
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=29:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_2_DEV_ASCS_monitor_20000
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=30:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_3_DEV_ASCS_start_0
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:start call_id:98
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.137
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/84, version=1.582.137)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/85)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/86)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.137 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.138 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=138
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']:  <lrm_rsc_op id="fs_2_DEV_ASCS_monitor_20000" operation_key="fs_2_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="29:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;29:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_2_DEV_ASCS']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.138
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/85, version=1.582.138)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.138 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.139 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=139
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_start_0, @operation=start, @transition-key=30:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;30:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014394, @last-rc-change=1580014394, @exec-ti
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/86, version=1.582.139)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.139
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=97 key=fs_2_DEV_ASCS_monitor_20000 confirmed=false cib-update=87
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/87)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.139 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.140 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=140
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;29:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=97, @rc-code=0, @op-status=0, @exec-time=235
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/87, version=1.582.140)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.140
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=95 key=rsc_DEV_ASCS00_monitor_120000 confirmed=false cib-update=88
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/88)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.140 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.141 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=141
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-magic=0:0;27:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=95, @rc-code=0, @op-status=0, @exec-time=643
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/88, version=1.582.141)
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.141
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:start call_id:98 pid:9948 exit-code:0 exec-time:338ms queue-time:0ms
Jan 26 05:53:14 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=98 key=fs_3_DEV_ASCS_start_0 confirmed=true cib-update=89
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/89)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.141 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.142 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=142
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;30:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=98, @rc-code=0, @op-status=0, @exec-time=338
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.142
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/89, version=1.582.142)
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=31:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_3_DEV_ASCS_monitor_20000
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/90)
Jan 26 05:53:14 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=36:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_CI_start_0
Jan 26 05:53:14 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:start call_id:100
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/91)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.142 2
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.143 (null)
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=143
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']:  <lrm_rsc_op id="fs_3_DEV_ASCS_monitor_20000" operation_key="fs_3_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="31:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;31:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_3_DEV_ASCS']
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.143
Jan 26 05:53:14 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/90, version=1.582.143)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.143 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.144 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=144
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @transition-key=36:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;36:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014394, @last-rc-change=1580014394, @exec-time=0
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/91, version=1.582.144)
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.144
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=99 key=fs_3_DEV_ASCS_monitor_20000 confirmed=false cib-update=92
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/92)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.144 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.145 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=145
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;31:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=99, @rc-code=0, @op-status=0, @exec-time=113
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.145
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/92, version=1.582.145)
Jan 26 05:53:15 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:start call_id:100 pid:10123 exit-code:0 exec-time:228ms queue-time:0ms
Jan 26 05:53:15 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_CI on vmi243500: 0 (ok) | call=100 key=fs_DEV_CI_start_0 confirmed=true cib-update=93
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/93)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.145 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.146 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=146
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;36:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=100, @rc-code=0, @op-status=0, @exec-time=228
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.146
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/93, version=1.582.146)
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=37:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=fs_DEV_CI_monitor_20000
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/94)
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=38:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_CI_start_0
Jan 26 05:53:15 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:start call_id:102
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.146 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.147 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=147
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']:  <lrm_rsc_op id="fs_DEV_CI_monitor_20000" operation_key="fs_DEV_CI_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="37:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;37:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500" c
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_CI']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.147
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/94, version=1.582.147)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/95)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.147 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.148 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=148
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @transition-key=38:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;38:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014395, @last-rc-change=1580014395, @exec-time=0
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.148
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/95, version=1.582.148)
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: 0 (ok) | call=101 key=fs_DEV_CI_monitor_20000 confirmed=false cib-update=96
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/96)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.148 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.149 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=149
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;37:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=101, @rc-code=0, @op-status=0, @exec-time=126
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.149
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/96, version=1.582.149)
Jan 26 05:53:15 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:start call_id:102 pid:10233 exit-code:0 exec-time:208ms queue-time:0ms
Jan 26 05:53:15 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_CI on vmi243500: 0 (ok) | call=102 key=vip_DEV_CI_start_0 confirmed=true cib-update=97
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/97)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.149 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.150 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=150
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;38:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=102, @rc-code=0, @op-status=0, @exec-time=208
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=39:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=vip_DEV_CI_monitor_10000
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.150
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=40:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_CI_start_0
Jan 26 05:53:15 [1656] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:104
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/97, version=1.582.150)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/98)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/99)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.150 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.151 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=151
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']:  <lrm_rsc_op id="vip_DEV_CI_monitor_10000" operation_key="vip_DEV_CI_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="39:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;39:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi243500
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_CI']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.151
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/98, version=1.582.151)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.151 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.152 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=152
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @transition-key=40:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @transition-magic=-1:193;40:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1580014395, @last-rc-change=1580014395, @exec-time=0
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.152
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/99, version=1.582.152)
Jan 26 05:53:15 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: 0 (ok) | call=103 key=vip_DEV_CI_monitor_10000 confirmed=false cib-update=100
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/100)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.152 2
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.153 (null)
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=153
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;39:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=103, @rc-code=0, @op-status=0, @exec-time=126, @queue-time=1
Jan 26 05:53:15 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/100, version=1.582.153)
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.153
Jan 26 05:53:15 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:53:20 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 9a64a9106f247e5c00bcd22bcfd4eae0 for 1.582.153 (0x5597ab76f2b0 0)
Jan 26 05:54:00 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:54:13 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:54:40 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:54:53 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 05:55:23 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 7 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 05:55:23 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/7)
Jan 26 05:55:23 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/7, version=1.582.153)
Jan 26 05:55:23 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 7 for #health-cpu: OK (0)
Jan 26 05:55:23 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 7 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 05:55:28 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 9a64a9106f247e5c00bcd22bcfd4eae0 for 1.582.153 (0x5597ab76f2b0 0)
Jan 26 05:55:35 [1656] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:104 pid:10379 exit-code:0 exec-time:139881ms queue-time:0ms
Jan 26 05:55:35 [1659] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=104 key=rsc_DEV_CI_start_0 confirmed=true cib-update=101
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/101)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.153 2
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.154 (null)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=154
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;40:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=104, @rc-code=0, @op-status=0, @exec-time=139881
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/101, version=1.582.154)
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.154
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:55:35 [1659] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=41:2:0:d961127d-613a-42b7-8bde-7de1f289d35c op=rsc_DEV_CI_monitor_120000
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/102)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.154 2
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.155 (null)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=155
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_monitor_120000" operation_key="rsc_DEV_CI_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="41:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" transition-magic="-1:193;41:2:0:d961127d-613a-42b7-8bde-7de1f289d35c" exit-reason="" on_node="vmi2435
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/102, version=1.582.155)
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_CI']
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.155
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:55:35 [1659] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=105 key=rsc_DEV_CI_monitor_120000 confirmed=false cib-update=103
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/103)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.155 2
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.156 (null)
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=156
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_monitor_120000']:  @transition-magic=0:0;41:2:0:d961127d-613a-42b7-8bde-7de1f289d35c, @call-id=105, @rc-code=0, @op-status=0, @exec-time=328
Jan 26 05:55:35 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/103, version=1.582.156)
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_monitor_120000']
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.582.156
Jan 26 05:55:35 [1655] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jan 26 05:55:40 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: a7675c2e638cbcf28dc8107767b2e811 for 1.582.156 (0x5597ab76f2b0 0)
Jan 26 05:59:31 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 05:59:58 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 06:00:28 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 8 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 06:00:28 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/8)
Jan 26 06:00:28 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/8, version=1.582.156)
Jan 26 06:00:28 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 8 for #health-cpu: OK (0)
Jan 26 06:00:28 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 8 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 06:00:33 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: a7675c2e638cbcf28dc8107767b2e811 for 1.582.156 (0x5597ab76f2b0 0)
Jan 26 06:00:38 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 06:01:08 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 9 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/9)
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.156 2
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.157 (null)
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=157
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 26 06:01:08 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/9, version=1.582.157)
Jan 26 06:01:08 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 9 for #health-cpu: OK (0)
Jan 26 06:01:08 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 9 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 26 06:01:13 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: d7d7bd2f5210c9a1819cc98482b605c3 for 1.582.157 (0x5597ab76f2b0 0)
Jan 26 06:01:44 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 06:01:57 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 26 06:02:11 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 26 06:02:41 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 10 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/10)
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.157 2
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.158 (null)
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=158
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 26 06:02:41 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/10, version=1.582.158)
Jan 26 06:02:41 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 10 for #health-cpu: OK (0)
Jan 26 06:02:41 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 10 for #health-cpu[vmi243500]=green: OK (0)
Jan 26 06:02:46 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: b728229b986ff2f687cc631c9ab86142 for 1.582.158 (0x5597ab76f2b0 0)
Jan 27 04:03:01 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 27 04:03:15 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 27 04:03:45 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 11 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:03:45 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/11)
Jan 27 04:03:45 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/11, version=1.582.158)
Jan 27 04:03:45 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 11 for #health-cpu: OK (0)
Jan 27 04:03:45 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 11 for #health-cpu[vmi243500]=green: OK (0)
Jan 27 04:03:50 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: b728229b986ff2f687cc631c9ab86142 for 1.582.158 (0x5597ab76f2b0 0)
Jan 27 04:12:32 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 27 04:13:02 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 12 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/12)
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.158 2
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.159 (null)
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=159
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 27 04:13:02 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/12, version=1.582.159)
Jan 27 04:13:02 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 12 for #health-cpu: OK (0)
Jan 27 04:13:02 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 12 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 27 04:13:07 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 43235a258a89d7add9801483cc62e8b7 for 1.582.159 (0x5597ab76f2b0 0)
Jan 27 04:13:26 [1659] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 27 04:13:38 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 27 04:13:56 [1659] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 27 04:14:08 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 13 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/13)
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.159 2
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.160 (null)
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=160
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 27 04:14:08 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/13, version=1.582.160)
Jan 27 04:14:08 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 13 for #health-cpu: OK (0)
Jan 27 04:14:08 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 13 for #health-cpu[vmi243500]=green: OK (0)
Jan 27 04:14:13 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: fd1abd7fbc350da6315b2398b824165e for 1.582.160 (0x5597ab76f2b0 0)
Jan 27 04:14:31 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 27 04:14:44 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 27 04:15:14 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 14 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:15:14 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/14)
Jan 27 04:15:14 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/14, version=1.582.160)
Jan 27 04:15:14 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 14 for #health-cpu: OK (0)
Jan 27 04:15:14 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 14 for #health-cpu[vmi243500]=green: OK (0)
Jan 27 04:15:19 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: fd1abd7fbc350da6315b2398b824165e for 1.582.160 (0x5597ab76f2b0 0)
Jan 27 04:15:37 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 27 04:16:07 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 15 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/15)
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.160 2
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.161 (null)
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=161
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jan 27 04:16:07 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/15, version=1.582.161)
Jan 27 04:16:07 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 15 for #health-cpu: OK (0)
Jan 27 04:16:07 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 15 for #health-cpu[vmi243500]=yellow: OK (0)
Jan 27 04:16:12 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: e253cdab3e827b35b3a792206d98e292 for 1.582.161 (0x5597ab76f2b0 0)
Jan 27 04:16:26 [1659] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jan 27 04:16:57 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 27 04:17:26 [1659] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jan 27 04:17:27 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 16 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/16)
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.582.161 2
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.582.162 (null)
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=162
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jan 27 04:17:27 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/16, version=1.582.162)
Jan 27 04:17:27 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 16 for #health-cpu: OK (0)
Jan 27 04:17:27 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 16 for #health-cpu[vmi243500]=green: OK (0)
Jan 27 04:17:32 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 6c33308f1d0fc240eba6b4f0fd8b7ce9 for 1.582.162 (0x5597ab76f2b0 0)
Jan 27 04:18:30 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jan 27 04:18:43 [1657] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jan 27 04:19:13 [1657] vmi243500      attrd:     info: write_attribute:	Sent update 17 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jan 27 04:19:13 [1654] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/17)
Jan 27 04:19:13 [1654] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/17, version=1.582.162)
Jan 27 04:19:13 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 17 for #health-cpu: OK (0)
Jan 27 04:19:13 [1657] vmi243500      attrd:     info: attrd_cib_callback:	Update 17 for #health-cpu[vmi243500]=green: OK (0)
Jan 27 04:19:18 [1654] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 6c33308f1d0fc240eba6b4f0fd8b7ce9 for 1.582.162 (0x5597ab76f2b0 0)
