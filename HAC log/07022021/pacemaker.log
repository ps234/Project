Jun 21 00:11:51 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 00:11:51 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 00:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 00:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 00:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 00:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 00:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 42 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 00:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 42 (ref=pe_calc-dc-1592691112-70) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 42 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 00:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 00:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 00:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 00:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 00:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 00:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 00:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 00:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 00:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 43 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 00:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 43 (ref=pe_calc-dc-1592692012-71) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 43 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 00:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 00:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 00:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 00:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 00:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 00:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 00:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 00:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 00:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 44 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 00:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 44 (ref=pe_calc-dc-1592692912-72) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 44 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 00:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 00:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 00:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 00:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 00:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 00:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 00:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 00:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 00:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 45 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 00:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 45 (ref=pe_calc-dc-1592693812-73) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 00:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 45 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 00:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 00:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 01:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 01:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 01:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 01:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 01:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 01:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 01:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 46 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 01:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 46 (ref=pe_calc-dc-1592694712-74) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 46 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 01:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 01:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 01:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 01:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 01:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 01:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 01:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 01:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 01:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 47 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 01:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 47 (ref=pe_calc-dc-1592695612-75) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 47 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 01:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 01:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 01:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 01:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 01:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 01:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 01:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 01:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 01:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 48 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 01:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 48 (ref=pe_calc-dc-1592696512-76) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 48 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 01:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 01:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 01:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 01:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 01:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 01:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 01:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 01:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 01:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 49 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 01:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 49 (ref=pe_calc-dc-1592697412-77) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 01:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 49 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 01:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 01:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 02:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 02:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 02:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 02:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 02:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 02:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 02:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 50 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 02:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 50 (ref=pe_calc-dc-1592698312-78) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 50 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 02:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 02:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 02:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 02:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 02:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 02:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 02:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 02:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 02:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 51 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 02:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 51 (ref=pe_calc-dc-1592699212-79) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 51 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 02:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 02:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 02:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 02:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 02:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 02:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 02:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 02:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 02:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 52 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 02:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 52 (ref=pe_calc-dc-1592700112-80) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 52 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 02:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 02:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 02:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 02:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 02:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 02:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 02:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 02:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 02:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 53 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 02:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 53 (ref=pe_calc-dc-1592701012-81) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 02:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 53 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 02:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 02:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 03:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 03:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 03:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 03:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 03:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 03:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 03:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 54 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 03:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 54 (ref=pe_calc-dc-1592701912-82) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 54 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 03:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 03:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 03:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 03:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 03:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 03:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 03:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 03:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 03:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 55 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 03:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 55 (ref=pe_calc-dc-1592702812-83) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 55 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 03:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 03:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 03:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 03:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 03:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 03:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 03:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 03:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 03:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 56 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 03:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 56 (ref=pe_calc-dc-1592703712-84) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 56 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 03:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 03:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 03:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 03:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 03:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 03:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 03:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 03:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 03:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 57 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 03:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 57 (ref=pe_calc-dc-1592704612-85) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 03:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 57 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 03:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 03:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 04:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 04:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 04:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 04:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 04:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 04:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 04:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 58 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 04:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 58 (ref=pe_calc-dc-1592705512-86) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 58 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 04:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 04:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 04:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 04:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 04:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 04:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 04:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 04:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 04:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 59 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 04:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 59 (ref=pe_calc-dc-1592706412-87) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 59 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 04:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 04:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 04:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 04:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 04:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 04:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 04:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 04:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 04:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 60 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 04:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 60 (ref=pe_calc-dc-1592707312-88) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 60 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 04:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 04:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 04:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 04:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 04:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 04:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 04:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 04:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 04:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 61 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 04:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 61 (ref=pe_calc-dc-1592708212-89) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 04:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 61 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 04:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 04:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 05:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 05:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 05:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 05:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 05:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 05:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 05:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 62 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 05:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 62 (ref=pe_calc-dc-1592709112-90) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 62 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 05:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 05:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 05:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 05:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 05:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 05:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 05:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 05:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 05:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 63 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 05:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 63 (ref=pe_calc-dc-1592710012-91) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 63 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 05:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 05:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 05:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 05:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 05:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 05:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 05:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 05:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 05:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 64 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 05:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 64 (ref=pe_calc-dc-1592710912-92) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 64 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 05:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 05:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 05:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 05:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 05:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 05:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 05:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 05:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 05:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 65 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 05:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 65 (ref=pe_calc-dc-1592711812-93) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 05:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 65 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 05:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 05:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 06:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 06:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 06:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 06:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 06:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 06:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 06:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 66 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 06:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 66 (ref=pe_calc-dc-1592712712-94) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 66 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 06:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 06:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 06:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 06:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 06:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 06:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 06:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 06:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 06:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 67 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 06:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 67 (ref=pe_calc-dc-1592713612-95) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 67 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 06:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 06:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 06:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 06:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 06:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 06:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 06:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 06:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 06:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 68 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 06:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 68 (ref=pe_calc-dc-1592714512-96) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 68 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 06:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 06:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 06:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 06:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 06:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 06:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 06:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 06:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 06:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 69 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 06:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 69 (ref=pe_calc-dc-1592715412-97) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 06:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 69 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 06:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 06:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 07:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 07:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 07:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 07:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 07:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 07:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 07:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 70 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 07:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 70 (ref=pe_calc-dc-1592716312-98) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 70 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 07:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 07:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 07:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 07:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 07:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 07:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 07:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 07:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 07:26:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 71 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 07:26:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 71 (ref=pe_calc-dc-1592717212-99) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:26:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 71 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 07:26:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 07:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 07:41:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 07:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 07:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 07:41:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 07:41:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 07:41:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 07:41:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 72 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:41:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 07:41:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 72 (ref=pe_calc-dc-1592718112-100) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:41:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 72 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 07:41:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 07:41:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 07:56:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 07:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 07:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 07:56:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 07:56:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 07:56:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 07:56:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 73 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:56:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 07:56:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 73 (ref=pe_calc-dc-1592719012-101) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 07:56:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 73 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 07:56:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 07:56:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 08:11:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 08:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 08:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 08:11:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 08:11:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 08:11:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 08:11:52 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 74 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:11:52 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 08:11:52 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 74 (ref=pe_calc-dc-1592719912-102) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:11:52 [1647] vmi243500       crmd:   notice: run_graph:	Transition 74 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 08:11:52 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 08:11:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 08:26:52 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 08:26:52 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 08:26:52 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 08:26:52 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 08:26:52 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 08:26:52 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 08:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 75 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 08:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 75 (ref=pe_calc-dc-1592720812-103) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 75 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 08:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 08:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 08:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 08:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 08:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 08:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 08:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 08:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 08:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 76 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 08:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 76 (ref=pe_calc-dc-1592721713-104) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 76 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 08:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 08:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 08:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 08:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 08:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 08:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 08:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 08:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 08:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 77 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 08:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 77 (ref=pe_calc-dc-1592722613-105) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 08:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 77 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 08:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 08:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 09:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 09:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 09:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 09:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 09:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 09:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 09:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 78 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 09:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 78 (ref=pe_calc-dc-1592723513-106) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 78 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 09:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 09:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 09:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 09:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 09:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 09:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 09:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 09:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 09:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 79 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 09:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 79 (ref=pe_calc-dc-1592724413-107) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 79 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 09:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 09:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 09:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 09:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 09:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 09:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 09:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 09:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 09:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 80 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 09:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 80 (ref=pe_calc-dc-1592725313-108) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 80 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 09:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 09:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 09:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 09:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 09:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 09:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 09:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 09:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 09:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 81 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 09:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 81 (ref=pe_calc-dc-1592726213-109) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 09:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 81 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 09:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 09:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 10:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 10:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 10:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 10:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 10:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 10:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 10:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 82 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 10:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 82 (ref=pe_calc-dc-1592727113-110) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 82 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 10:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 10:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 10:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 10:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 10:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 10:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 10:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 10:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 10:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 83 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 10:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 83 (ref=pe_calc-dc-1592728013-111) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 83 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 10:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 10:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 10:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 10:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 10:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 10:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 10:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 10:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 10:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 84 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 10:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 84 (ref=pe_calc-dc-1592728913-112) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 84 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 10:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 10:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 10:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 10:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 10:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 10:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 10:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 10:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 10:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 85 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 10:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 85 (ref=pe_calc-dc-1592729813-113) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 10:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 85 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 10:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 10:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 11:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 11:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 11:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 11:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 11:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 11:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 11:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 86 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 11:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 86 (ref=pe_calc-dc-1592730713-114) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 86 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 11:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 11:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 11:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 11:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 11:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 11:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 11:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 11:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 11:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 87 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 11:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 87 (ref=pe_calc-dc-1592731613-115) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 87 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 11:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 11:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 11:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 11:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 11:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 11:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 11:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 11:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 11:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 88 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 11:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 88 (ref=pe_calc-dc-1592732513-116) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 88 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 11:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 11:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 11:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 11:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 11:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 11:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 11:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 11:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 11:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 89 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 11:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 89 (ref=pe_calc-dc-1592733413-117) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 11:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 89 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 11:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 11:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 12:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 12:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 12:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 12:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 12:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 12:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 12:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 90 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 12:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 90 (ref=pe_calc-dc-1592734313-118) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 90 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 12:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 12:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 12:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 12:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 12:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 12:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 12:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 12:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 12:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 91 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 12:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 91 (ref=pe_calc-dc-1592735213-119) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 91 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 12:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 12:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 12:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 12:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 12:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 12:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 12:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 12:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 12:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 92 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 12:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 92 (ref=pe_calc-dc-1592736113-120) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 92 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 12:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 12:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 12:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 12:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 12:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 12:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 12:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 12:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 12:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 93 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 12:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 93 (ref=pe_calc-dc-1592737013-121) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 12:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 93 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 12:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 12:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 13:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 13:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 13:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 13:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 13:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 13:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 13:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 13:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 94 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 94 (ref=pe_calc-dc-1592737913-122) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 94 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 13:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 13:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 13:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 13:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 13:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 13:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 13:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 13:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 13:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 95 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 13:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 95 (ref=pe_calc-dc-1592738813-123) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 95 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 13:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 13:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 13:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 13:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 13:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 13:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 13:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 13:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 13:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 96 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 13:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 96 (ref=pe_calc-dc-1592739713-124) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 96 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 13:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 13:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 13:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 13:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 13:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 13:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 13:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 13:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 13:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 97 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 13:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 97 (ref=pe_calc-dc-1592740613-125) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 13:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 97 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 13:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 13:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 14:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 14:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 14:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 14:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 14:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 14:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 14:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 98 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 14:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 98 (ref=pe_calc-dc-1592741513-126) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 98 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 14:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 14:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 14:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 14:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 14:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 14:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 14:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 14:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 14:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 99 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 14:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 99 (ref=pe_calc-dc-1592742413-127) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 99 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 14:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 14:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 14:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 14:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 14:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 14:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 14:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 14:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 14:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 100 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 14:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 100 (ref=pe_calc-dc-1592743313-128) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 100 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 14:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 14:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 14:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 14:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 14:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 14:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 14:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 14:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 14:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 101 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 14:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 101 (ref=pe_calc-dc-1592744213-129) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 14:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 101 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 14:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 14:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 15:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 15:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 15:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 15:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 15:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 15:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 15:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 102 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 15:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 102 (ref=pe_calc-dc-1592745113-130) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 102 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 15:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 15:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 15:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 15:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 15:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 15:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 15:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 15:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 15:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 103 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 15:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 103 (ref=pe_calc-dc-1592746013-131) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 103 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 15:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 15:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 15:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 15:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 15:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 15:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 15:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 15:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 15:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 104 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 15:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 104 (ref=pe_calc-dc-1592746913-132) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 104 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 15:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 15:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 15:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 15:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 15:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 15:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 15:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 15:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 15:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 105 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 15:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 105 (ref=pe_calc-dc-1592747813-133) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 15:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 105 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 15:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 15:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 16:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 16:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 16:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 16:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 16:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 16:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 16:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 106 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 16:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 106 (ref=pe_calc-dc-1592748713-134) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 106 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 16:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 16:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 16:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 16:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 16:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 16:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 16:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 16:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 16:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 107 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 16:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 107 (ref=pe_calc-dc-1592749613-135) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 107 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 16:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 16:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 16:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 16:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 16:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 16:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 16:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 16:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 16:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 108 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 16:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 108 (ref=pe_calc-dc-1592750513-136) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 108 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 16:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 16:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 16:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 16:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 16:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 16:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 16:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 16:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 16:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 109 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 16:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 109 (ref=pe_calc-dc-1592751413-137) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 16:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 109 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 16:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 16:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 17:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 17:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 17:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 17:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 17:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 17:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 17:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 110 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 17:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 110 (ref=pe_calc-dc-1592752313-138) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 110 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 17:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 17:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 17:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 17:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 17:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 17:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 17:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 17:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 17:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 111 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 17:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 111 (ref=pe_calc-dc-1592753213-139) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 111 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 17:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 17:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 17:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 17:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 17:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 17:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 17:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 17:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 17:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 112 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 17:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 112 (ref=pe_calc-dc-1592754113-140) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 112 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 17:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 17:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 17:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 17:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 17:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 17:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 17:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 17:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 17:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 113 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 17:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 113 (ref=pe_calc-dc-1592755013-141) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 17:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 113 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 17:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 17:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 18:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 18:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 18:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 18:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 18:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 18:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 18:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 114 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 18:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 114 (ref=pe_calc-dc-1592755913-142) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 114 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 18:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 18:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 18:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 18:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 18:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 18:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 18:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 18:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 18:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 115 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 18:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 115 (ref=pe_calc-dc-1592756813-143) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 115 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 18:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 18:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 18:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 18:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 18:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 18:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 18:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 18:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 18:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 116 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 18:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 116 (ref=pe_calc-dc-1592757713-144) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 116 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 18:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 18:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 18:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 18:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 18:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 18:56:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 18:56:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 18:56:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 18:56:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 117 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 18:56:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 117 (ref=pe_calc-dc-1592758613-145) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 18:56:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 117 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 18:56:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 18:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 19:11:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 19:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 19:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 19:11:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 19:11:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 19:11:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 19:11:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 118 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:11:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 19:11:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 118 (ref=pe_calc-dc-1592759513-146) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:11:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 118 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 19:11:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 19:11:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 19:26:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 19:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 19:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 19:26:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 19:26:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 19:26:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 19:26:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 119 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:26:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 19:26:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 119 (ref=pe_calc-dc-1592760413-147) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:26:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 119 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 19:26:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 19:26:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 19:41:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 19:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 19:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 19:41:53 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 19:41:53 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 19:41:53 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 19:41:53 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 120 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:41:53 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 19:41:53 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 120 (ref=pe_calc-dc-1592761313-148) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:41:53 [1647] vmi243500       crmd:   notice: run_graph:	Transition 120 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 19:41:53 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 19:41:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 19:56:53 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 19:56:53 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 19:56:53 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 19:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 19:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 19:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 19:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 121 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 19:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 121 (ref=pe_calc-dc-1592762213-149) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 19:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 121 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 19:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 19:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 20:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 20:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 20:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 20:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 20:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 20:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 20:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 122 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 20:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 122 (ref=pe_calc-dc-1592763114-150) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 122 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 20:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 20:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 20:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 20:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 20:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 20:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 20:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 20:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 20:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 123 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 20:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 123 (ref=pe_calc-dc-1592764014-151) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 123 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 20:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 20:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 20:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 20:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 20:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 20:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 20:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 20:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 20:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 124 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 20:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 124 (ref=pe_calc-dc-1592764914-152) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 124 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 20:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 20:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 20:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 20:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 20:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 20:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 20:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 20:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 20:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 125 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 20:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 125 (ref=pe_calc-dc-1592765814-153) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 20:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 125 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 20:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 20:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 21:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 21:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 21:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 21:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 21:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 21:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 21:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 126 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 21:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 126 (ref=pe_calc-dc-1592766714-154) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 126 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 21:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 21:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 21:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 21:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 21:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 21:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 21:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 21:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 21:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 127 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 21:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 127 (ref=pe_calc-dc-1592767614-155) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 127 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 21:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 21:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 21:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 21:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 21:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 21:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 21:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 21:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 21:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 128 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 21:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 128 (ref=pe_calc-dc-1592768514-156) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 128 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 21:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 21:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 21:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 21:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 21:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 21:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 21:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 21:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 21:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 129 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 21:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 129 (ref=pe_calc-dc-1592769414-157) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 21:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 129 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 21:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 21:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 22:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 22:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 22:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 22:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 22:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 22:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 22:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 130 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 22:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 130 (ref=pe_calc-dc-1592770314-158) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 130 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 22:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 22:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 22:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 22:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 22:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 22:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 22:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 22:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 22:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 131 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 22:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 131 (ref=pe_calc-dc-1592771214-159) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 131 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 22:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 22:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 22:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 22:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 22:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 22:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 22:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 22:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 22:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 132 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 22:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 132 (ref=pe_calc-dc-1592772114-160) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 132 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 22:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 22:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 22:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 22:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 22:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 22:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 22:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 22:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 22:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 133 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 22:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 133 (ref=pe_calc-dc-1592773014-161) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 22:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 133 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 22:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 22:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 23:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 23:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 23:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 23:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 23:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 23:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 23:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 134 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 23:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 134 (ref=pe_calc-dc-1592773914-162) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 134 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 23:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 23:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 23:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 23:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 23:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 23:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 23:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 23:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 23:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 135 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 23:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 135 (ref=pe_calc-dc-1592774814-163) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 135 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 23:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 23:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 23:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 23:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 23:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 23:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 23:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 23:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 23:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 136 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 23:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 136 (ref=pe_calc-dc-1592775714-164) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 136 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 23:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 23:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 21 23:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 21 23:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 21 23:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 21 23:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 21 23:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 21 23:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 21 23:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 137 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 21 23:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 137 (ref=pe_calc-dc-1592776614-165) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 21 23:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 137 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 21 23:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 21 23:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 00:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 00:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 00:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 00:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 00:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 00:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 00:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 138 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 00:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 138 (ref=pe_calc-dc-1592777514-166) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 138 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 00:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 00:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 00:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 00:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 00:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 00:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 00:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 00:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 00:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 139 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 00:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 139 (ref=pe_calc-dc-1592778414-167) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 139 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 00:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 00:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 00:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 00:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 00:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 00:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 00:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 00:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 00:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 140 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 00:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 140 (ref=pe_calc-dc-1592779314-168) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 140 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 00:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 00:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 00:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 00:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 00:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 00:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 00:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 00:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 00:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 141 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 00:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 141 (ref=pe_calc-dc-1592780214-169) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 00:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 141 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 00:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 00:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 01:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 01:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 01:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 01:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 01:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 01:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 01:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 142 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 01:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 142 (ref=pe_calc-dc-1592781114-170) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 142 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 01:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 01:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 01:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 01:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 01:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 01:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 01:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 01:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 01:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 143 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 01:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 143 (ref=pe_calc-dc-1592782014-171) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 143 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 01:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 01:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 01:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 01:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 01:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 01:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 01:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 01:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 01:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 144 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 01:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 144 (ref=pe_calc-dc-1592782914-172) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 144 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 01:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 01:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 01:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 01:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 01:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 01:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 01:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 01:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 01:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 145 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 01:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 145 (ref=pe_calc-dc-1592783814-173) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 01:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 145 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 01:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 01:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 02:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 02:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 02:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 02:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 02:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 02:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 02:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 146 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 02:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 146 (ref=pe_calc-dc-1592784714-174) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 146 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 02:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 02:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 02:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 02:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 02:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 02:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 02:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 02:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 02:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 147 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 02:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 147 (ref=pe_calc-dc-1592785614-175) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 147 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 02:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 02:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 02:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 02:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 02:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 02:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 02:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 02:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 02:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 148 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 02:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 148 (ref=pe_calc-dc-1592786514-176) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 148 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 02:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 02:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 02:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 02:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 02:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 02:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 02:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 02:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 02:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 149 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 02:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 149 (ref=pe_calc-dc-1592787414-177) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 02:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 149 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 02:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 02:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 03:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 03:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 03:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 03:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 03:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 03:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 03:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 150 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 03:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 150 (ref=pe_calc-dc-1592788314-178) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 150 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 03:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 03:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 03:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 03:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 03:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 03:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 03:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 03:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 03:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 151 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 03:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 151 (ref=pe_calc-dc-1592789214-179) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 151 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 03:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 03:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 03:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 03:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 03:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 03:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 03:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 03:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 03:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 152 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 03:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 152 (ref=pe_calc-dc-1592790114-180) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 152 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 03:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 03:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 03:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 03:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 03:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 03:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 03:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 03:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 03:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 153 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 03:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 153 (ref=pe_calc-dc-1592791014-181) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 03:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 153 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 03:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 03:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 04:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 04:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 04:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 04:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 04:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 04:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 04:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 154 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 04:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 154 (ref=pe_calc-dc-1592791914-182) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 154 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 04:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 04:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 04:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 04:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 04:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 04:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 04:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 04:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 04:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 155 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 04:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 155 (ref=pe_calc-dc-1592792814-183) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 155 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 04:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 04:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 04:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 04:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 04:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 04:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 04:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 04:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 04:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 156 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 04:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 156 (ref=pe_calc-dc-1592793714-184) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 156 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 04:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 04:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 04:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 04:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 04:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 04:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 04:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 04:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 04:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 157 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 04:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 157 (ref=pe_calc-dc-1592794614-185) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 04:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 157 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 04:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 04:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 05:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 05:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 05:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 05:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 05:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 05:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 05:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 158 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 05:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 158 (ref=pe_calc-dc-1592795514-186) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 158 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 05:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 05:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 05:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 05:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 05:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 05:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 05:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 05:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 05:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 159 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 05:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 159 (ref=pe_calc-dc-1592796414-187) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 159 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 05:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 05:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 05:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 05:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 05:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 05:41:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 05:41:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 05:41:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 05:41:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 160 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 05:41:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 160 (ref=pe_calc-dc-1592797314-188) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:41:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 160 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 05:41:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 05:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 05:56:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 05:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 05:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 05:56:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 05:56:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 05:56:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 05:56:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 161 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:56:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 05:56:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 161 (ref=pe_calc-dc-1592798214-189) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 05:56:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 161 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 05:56:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 05:56:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 06:11:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 06:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 06:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 06:11:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 06:11:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 06:11:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 06:11:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 162 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:11:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 06:11:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 162 (ref=pe_calc-dc-1592799114-190) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:11:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 162 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 06:11:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 06:11:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 06:26:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 06:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 06:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 06:26:54 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 06:26:54 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 06:26:54 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 06:26:54 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 163 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:26:54 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 06:26:54 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 163 (ref=pe_calc-dc-1592800014-191) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:26:54 [1647] vmi243500       crmd:   notice: run_graph:	Transition 163 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 06:26:54 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 06:26:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 06:41:54 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 06:41:54 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 06:41:54 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 06:41:55 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 06:41:55 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 06:41:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 06:41:55 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 164 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:41:55 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 06:41:55 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 164 (ref=pe_calc-dc-1592800915-192) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:41:55 [1647] vmi243500       crmd:   notice: run_graph:	Transition 164 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 06:41:55 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 06:41:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 06:56:55 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 06:56:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 06:56:55 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 06:56:55 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 06:56:55 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 06:56:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 06:56:55 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 165 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:56:55 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 06:56:55 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 165 (ref=pe_calc-dc-1592801815-193) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 06:56:55 [1647] vmi243500       crmd:   notice: run_graph:	Transition 165 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 06:56:55 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 06:56:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:11:55 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 07:11:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 07:11:55 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:11:55 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:11:55 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:11:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:11:55 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 166 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:11:55 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:11:55 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 166 (ref=pe_calc-dc-1592802715-194) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:11:55 [1647] vmi243500       crmd:   notice: run_graph:	Transition 166 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 07:11:55 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:11:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:26:55 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 07:26:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 07:26:55 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:26:55 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:26:55 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:26:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:26:55 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 167 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:26:55 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:26:55 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 167 (ref=pe_calc-dc-1592803615-195) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:26:55 [1647] vmi243500       crmd:   notice: run_graph:	Transition 167 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 07:26:55 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:26:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:41:55 [1647] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 07:41:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 07:41:55 [1647] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:41:55 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:41:55 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:41:55 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:41:55 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 168 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:41:55 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:41:55 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 168 (ref=pe_calc-dc-1592804515-196) derived from /var/lib/pacemaker/pengine/pe-warn-133.bz2
Jun 22 07:41:55 [1647] vmi243500       crmd:   notice: run_graph:	Transition 168 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-133.bz2): Complete
Jun 22 07:41:55 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:41:55 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:49:56 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:50:51 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:50:54 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:28 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:28 [1643] vmi243500 stonith-ng:   notice: handle_request:	Received manual confirmation that vmi243493 is fenced
Jun 22 07:51:28 [1643] vmi243500 stonith-ng:   notice: initiate_remote_stonith_op:	Initiating manual confirmation for vmi243493: 1e83ccf2-1463-4a18-8b58-902bd0be2527
Jun 22 07:51:28 [1643] vmi243500 stonith-ng:   notice: stonith_manual_ack:	Injecting manual confirmation that vmi243493 is safely off/down
Jun 22 07:51:28 [1643] vmi243500 stonith-ng:   notice: remote_op_done:	Operation off of vmi243493 by a human for stonith_admin.16816@vmi243500.1e83ccf2: OK
Jun 22 07:51:28 [1647] vmi243500       crmd:   notice: tengine_stonith_notify:	Peer vmi243493 was terminated (off) by a human on behalf of stonith_admin.16816: OK | initiator=vmi243500 ref=1e83ccf2-1463-4a18-8b58-902bd0be2527
Jun 22 07:51:29 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:49 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crm_attribute/4)
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.588.39 2
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.0 a6525f8cbe2b320006cbe2959958b191
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=589, @num_updates=0
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/nodes/node[@id='96317541']/instance_attributes[@id='nodes-96317541']/nvpair[@id='nodes-96317541-maintenance']:  @value=on
Jun 22 07:51:50 [1647] vmi243500       crmd:     info: abort_transition_graph:	Transition 168 aborted by nodes-96317541-maintenance doing modify maintenance=on: Configuration change | cib=1.589.0 source=te_update_diff_v2:500 path=/cib/configuration/nodes/node[@id='96317541']/instance_attributes[@id='nodes-96317541']/nvpair[@id='nodes-96317541-maintenance'] complete=true
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crm_attribute/4, version=1.589.0)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:51:50 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:51:50 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:51:50 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:51:50 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 169 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-134.bz2
Jun 22 07:51:50 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 169 (ref=pe_calc-dc-1592805110-197) derived from /var/lib/pacemaker/pengine/pe-warn-134.bz2
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: run_graph:	Transition 169 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-134.bz2): Complete
Jun 22 07:51:50 [1647] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-20.raw
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: 73ee61564691e15ed9ec0bc562ee1dca)
Jun 22 07:51:50 [1642] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.3Sig1W (digest: /var/lib/pacemaker/cib/cib.wQOoxv)
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:50 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:51 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:51 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:52 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:52 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:55 [1642] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: a6525f8cbe2b320006cbe2959958b191 for 1.589.0 (0x55eadf19f710 0)
Jun 22 07:51:56 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:51:56 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:52:07 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:52:10 [1647] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: pcmk_shutdown_worker:	Shutting down Pacemaker
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping crmd | sent signal 15 to process 1647
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: crm_shutdown:	Shutting down cluster resource manager | limit=1200000ms
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_log:	Input I_SHUTDOWN received in state S_IDLE from crm_shutdown
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_SHUTDOWN cause=C_SHUTDOWN origin=crm_shutdown
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_shutdown_req:	Sending shutdown request to all peers (DC is vmi243500)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crm_update_peer_expected:	handle_request: Node vmi243500[771304931] - expected state is now down (was member)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: handle_shutdown_request:	Creating shutdown request for vmi243500 (state=S_POLICY_ENGINE)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: update_attrd_helper:	Connecting to attribute manager ... 5 retries remaining
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: attrd_peer_update:	Setting shutdown[vmi243500]: (null) -> 1592805205 from vmi243500
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: write_attribute:	Sent update 4 with 1 changes for shutdown, id=<n/a>, set=(null)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/4)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.0 2
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.1 (null)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <transient_attributes id="771304931"/>
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	++                                             <instance_attributes id="status-771304931">
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	++                                               <nvpair id="status-771304931-shutdown" name="shutdown" value="1592805205"/>
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	++                                             </instance_attributes>
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	++                                           </transient_attributes>
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/4, version=1.589.1)
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for shutdown: OK (0)
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for shutdown[vmi243500]=1592805205: OK (0)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: abort_transition_graph:	Transition 169 aborted by transient_attributes.771304931 'create': Transient attribute change | cib=1.589.1 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931'] complete=true
Jun 22 07:53:25 [1646] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:53:25 [1646] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is shutting down
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource stonith-sbd cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_database: Rolling back scores from vip_DEV_database
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_database cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_database: Rolling back scores from rsc_DEV_database
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource vip_DEV_database cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_database cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_ASCS: Rolling back scores from vip_DEV_ASCS
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_ASCS cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_ASCS: Rolling back scores from rsc_DEV_ASCS00
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource vip_DEV_ASCS cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	rsc_DEV_ASCS00: Rolling back scores from fs_2_DEV_ASCS
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_ASCS00 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	fs_2_DEV_ASCS: Rolling back scores from fs_3_DEV_ASCS
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_2_DEV_ASCS cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	fs_3_DEV_ASCS: Rolling back scores from vip_DEV_ERS
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_3_DEV_ASCS cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from vip_DEV_CI
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_CI cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource vip_DEV_CI cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	vip_DEV_ERS: Rolling back scores from grp_DEV_ascs
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_ERS: Rolling back scores from rsc_DEV_ERS10
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource vip_DEV_ERS cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_ERS10 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_CPU cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:0: Rolling back scores from fs_DEV_sapmnt:0
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:0 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:0 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:53:25 [1646] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:53:25 [1646] vmi243500    pengine:   notice: stage6:	Scheduling Node vmi243500 for shutdown
Jun 22 07:53:25 [1646] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:53:25 [1646] vmi243500    pengine:   notice: LogNodeActions:	 * Shutdown vmi243500
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:53:25 [1646] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 170 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-135.bz2
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 170 (ref=pe_calc-dc-1592805205-199) derived from /var/lib/pacemaker/pengine/pe-warn-135.bz2
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: te_crm_command:	Executing crm-event (31): do_shutdown on vmi243500
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: te_crm_command:	crm-event (31) is a local shutdown
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: run_graph:	Transition 170 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-135.bz2): Complete
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_log:	Input I_STOP received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_STOPPING | input=I_STOP cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_dc_release:	DC role released
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: pe_ipc_destroy:	Connection to the Policy Engine released
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_te_control:	Transitioner is now inactive
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_shutdown:	Disconnecting STONITH...
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: tengine_stonith_connection_destroy:	Fencing daemon disconnected
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_lrm_control:	Disconnecting from the LRM
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: lrmd_api_disconnect:	Disconnecting IPC LRM connection to local
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: lrmd_ipc_connection_destroy:	IPC connection destroyed
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: lrm_connection_destroy:	LRM Connection disconnected
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: lrmd_api_disconnect:	Disconnecting IPC LRM connection to local
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: do_lrm_control:	Disconnected from the LRM
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/233)
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: terminate_cs_connection:	Disconnected from Corosync
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_ha_control:	Disconnected from the cluster
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_cib_control:	Disconnecting CIB
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_process_readwrite:	We are now in R/O mode
Jun 22 07:53:25 [1642] vmi243500        cib:  warning: qb_ipcs_event_sendv:	new_event_notification (1642-1647-11): Broken pipe (32)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_cib_connection_destroy:	Connection to the CIB terminated...
Jun 22 07:53:25 [1642] vmi243500        cib:  warning: do_local_notify:	A-Sync reply to crmd failed: No message of desired type
Jun 22 07:53:25 [1647] vmi243500       crmd:   notice: do_cib_control:	Disconnected from the CIB
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_exit:	Performing A_EXIT_0 - gracefully exiting the CRMd
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: do_exit:	[crmd] stopped (0)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_exit:	Dropping I_RELEASE_SUCCESS: [ state=S_STOPPING cause=C_FSA_INTERNAL origin=do_dc_release ]
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_exit:	Dropping I_TERMINATE: [ state=S_STOPPING cause=C_FSA_INTERNAL origin=do_stop ]
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_cs_destroy:	Corosync connection closed
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_cs_destroy:	Corosync connection closed
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crmd_init:	crmd[1647] exiting with status 0 (OK)
Jun 22 07:53:25 [1647] vmi243500       crmd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.1 2
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.2 (null)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_dc_release, @expected=down
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/233, version=1.589.2)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	crmd[1647] exited with status 0 (OK)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping pengine | sent signal 15 to process 1646
Jun 22 07:53:25 [1646] vmi243500    pengine:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1646] vmi243500    pengine:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	pengine[1646] exited with status 0 (OK)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping attrd | sent signal 15 to process 1645
Jun 22 07:53:25 [1645] vmi243500      attrd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: main:	Shutting down attribute manager
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: attrd_cib_destroy_cb:	Connection disconnection complete
Jun 22 07:53:25 [1645] vmi243500      attrd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	attrd[1645] exited with status 0 (OK)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping lrmd | sent signal 15 to process 1644
Jun 22 07:53:25 [1644] vmi243500       lrmd:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1644] vmi243500       lrmd:     info: lrmd_exit:	Terminating with 0 clients
Jun 22 07:53:25 [1644] vmi243500       lrmd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1644] vmi243500       lrmd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	lrmd[1644] exited with status 0 (OK)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping stonith-ng | sent signal 15 to process 1643
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:     info: stonith_shutdown:	Terminating with 0 clients
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:     info: cib_connection_destroy:	Connection to the CIB closed.
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:     info: main:	Done
Jun 22 07:53:25 [1643] vmi243500 stonith-ng:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	stonith-ng[1643] exited with status 0 (OK)
Jun 22 07:53:25 [1634] vmi243500 pacemakerd:   notice: stop_child:	Stopping cib | sent signal 15 to process 1642
Jun 22 07:53:25 [1642] vmi243500        cib:   notice: crm_signal_dispatch:	Caught 'Terminated' signal | 15 (invoking handler)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_shutdown:	All clients disconnected (0)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: terminate_cib:	initiate_exit: Exiting from mainloop...
Jun 22 07:53:25 [1642] vmi243500        cib:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jun 22 07:53:25 [1642] vmi243500        cib:   notice: terminate_cs_connection:	Disconnected from Corosync
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_shutdown:	Disconnected 1 clients
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cib_shutdown:	All clients disconnected (0)
Jun 22 07:53:25 [1642] vmi243500        cib:     info: terminate_cib:	initiate_exit: Exiting from mainloop...
Jun 22 07:53:25 [1642] vmi243500        cib:     info: crm_cluster_disconnect:	Disconnecting from cluster infrastructure: corosync
Jun 22 07:53:25 [1642] vmi243500        cib:     info: cluster_disconnect_cpg:	No CPG connection
Jun 22 07:53:25 [1642] vmi243500        cib:   notice: terminate_cs_connection:	Disconnected from Corosync
Jun 22 07:53:25 [1642] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1642] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1642] vmi243500        cib:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:25 [1642] vmi243500        cib:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:53:26 [1634] vmi243500 pacemakerd:     info: pcmk_child_exit:	cib[1642] exited with status 0 (OK)
Jun 22 07:53:26 [1634] vmi243500 pacemakerd:   notice: pcmk_shutdown_worker:	Shutdown complete
Jun 22 07:53:26 [1634] vmi243500 pacemakerd:     info: qb_ipcs_us_withdraw:	withdrawing server sockets
Jun 22 07:53:26 [1634] vmi243500 pacemakerd:     info: crm_xml_cleanup:	Cleaning up memory from libxml2
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: get_cluster_type:	Detected an active 'corosync' cluster
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: mcp_read_config:	Reading configure for stack: corosync
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:   notice: main:	Starting Pacemaker 1.1.18+20180430.b12c320f5-lp150.1.4 | build=b12c320f5 features: generated-manpages agent-manpages ncurses libqb-logging libqb-ipc lha-fencing systemd nagios  corosync-native atomic-attrd acls cibsecrets
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: main:	Maximum core file size is: 18446744073709551615
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: qb_ipcs_us_publish:	server name: pacemakerd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry 49907f33-4656-4425-9c09-5bae8cb0ac01/0x55e8371e90d0 for node (null)/771304931 (1 total)
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:  warning: cluster_connect_quorum:	Quorum lost
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process cib
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1614 for process cib
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1615 for process stonith-ng
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1616 for process lrmd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process attrd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1617 for process attrd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process pengine
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1618 for process pengine
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process crmd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: start_child:	Forked child 1619 for process crmd
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: main:	Starting mainloop
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Quorum still lost | membership=1156 members=1
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 joined group pacemakerd (counter=0.0)
Jun 22 07:54:07 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=0.0)
Jun 22 07:54:08 [1614] vmi243500        cib:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: main:	Starting up
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jun 22 07:54:08 [1617] vmi243500      attrd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jun 22 07:54:08 [1614] vmi243500        cib:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jun 22 07:54:08 [1614] vmi243500        cib:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jun 22 07:54:08 [1616] vmi243500       lrmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1616] vmi243500       lrmd:     info: qb_ipcs_us_publish:	server name: lrmd
Jun 22 07:54:08 [1616] vmi243500       lrmd:     info: main:	Starting
Jun 22 07:54:08 [1614] vmi243500        cib:     info: retrieveCib:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.xml (digest: /var/lib/pacemaker/cib/cib.xml.sig)
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jun 22 07:54:08 [1614] vmi243500        cib:     info: validate_with_relaxng:	Creating RNG parser context
Jun 22 07:54:08 [1618] vmi243500    pengine:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1618] vmi243500    pengine:     info: qb_ipcs_us_publish:	server name: pengine
Jun 22 07:54:08 [1618] vmi243500    pengine:     info: main:	Starting pengine
Jun 22 07:54:08 [1619] vmi243500       crmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Jun 22 07:54:08 [1619] vmi243500       crmd:     info: main:	CRM Git Version: 1.1.18+20180430.b12c320f5-lp150.1.4 (b12c320f5)
Jun 22 07:54:08 [1619] vmi243500       crmd:     info: do_log:	Input I_STARTUP received in state S_STARTING from crmd_init
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1617] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: crm_get_peer:	Created entry 036156d1-8d82-4a76-a10d-efcdb121fa7f/0x5600ce8fb260 for node (null)/771304931 (1 total)
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jun 22 07:54:08 [1617] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: init_cs_connection_once:	Connection to 'corosync': established
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry e66b57fa-9ab7-4b9d-aad6-f65e7eec5d31/0x56134223f180 for node (null)/771304931 (1 total)
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1617] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: init_cs_connection_once:	Connection to 'corosync': established
Jun 22 07:54:08 [1617] vmi243500      attrd:     info: main:	Cluster connection active
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:08 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jun 22 07:54:08 [1614] vmi243500        cib:     info: startCib:	CIB Initialization completed successfully
Jun 22 07:54:08 [1614] vmi243500        cib:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jun 22 07:54:08 [1614] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1614] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jun 22 07:54:08 [1614] vmi243500        cib:     info: crm_get_peer:	Created entry f0dd90b1-8da0-4694-84b8-015dcd713064/0x55a430343050 for node (null)/771304931 (1 total)
Jun 22 07:54:08 [1614] vmi243500        cib:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jun 22 07:54:08 [1614] vmi243500        cib:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jun 22 07:54:08 [1614] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Jun 22 07:54:08 [1614] vmi243500        cib:     info: init_cs_connection_once:	Connection to 'corosync': established
Jun 22 07:54:08 [1614] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:08 [1614] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:08 [1614] vmi243500        cib:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jun 22 07:54:08 [1614] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_ro
Jun 22 07:54:08 [1614] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_rw
Jun 22 07:54:08 [1614] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_shm
Jun 22 07:54:08 [1614] vmi243500        cib:     info: cib_init:	Starting cib mainloop
Jun 22 07:54:08 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 joined group cib (counter=0.0)
Jun 22 07:54:08 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=0.0)
Jun 22 07:54:08 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-21.raw
Jun 22 07:54:08 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: 7fc94f9bc98a9deab57eb4aa773eb5df)
Jun 22 07:54:08 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.mDxEwC (digest: /var/lib/pacemaker/cib/cib.HFgDEu)
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: crm_get_peer:	Created entry cbe81adb-c4a4-4c6b-a1bd-576cf88d3ebf/0x559ba2f56430 for node (null)/771304931 (1 total)
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: init_cs_connection_once:	Connection to 'corosync': established
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now in unknown state
Jun 22 07:54:09 [1619] vmi243500       crmd:  warning: cluster_connect_quorum:	Quorum lost
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: do_ha_control:	Connected to the cluster
Jun 22 07:54:09 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/2)
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: lrmd_ipc_connect:	Connecting to lrmd
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: do_lrm_control:	LRM connection established
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: do_started:	Delaying start, no membership data (0000000000100000)
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: pcmk_quorum_notification:	Quorum still lost | membership=1156 members=1
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now member (was in unknown state)
Jun 22 07:54:09 [1614] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:09 [1614] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: do_started:	Delaying start, Config not read (0000000000000040)
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: qb_ipcs_us_publish:	server name: crmd
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: do_started:	The local CRM is operational
Jun 22 07:54:09 [1619] vmi243500       crmd:     info: do_log:	Input I_PENDING received in state S_STARTING from do_started
Jun 22 07:54:09 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_STARTING -> S_PENDING | input=I_PENDING cause=C_FSA_INTERNAL origin=do_started
Jun 22 07:54:09 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/2, version=1.589.0)
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: attrd_erase_attrs:	Clearing transient attributes from CIB | xpath=//node_state[@uname='vmi243500']/transient_attributes
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: attrd_client_update:	Starting an election to determine the writer
Jun 22 07:54:09 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes to all (origin=local/attrd/2)
Jun 22 07:54:09 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes: OK (rc=0, origin=vmi243500/attrd/2, version=1.589.0)
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Jun 22 07:54:09 [1617] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: main:	CIB connection active
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: qb_ipcs_us_publish:	server name: attrd
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: main:	Accepting attribute updates
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 joined group attrd (counter=0.0)
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=0.0)
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243500]: (null) -> 2 from vmi243500
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: write_or_elect_attribute:	Starting an election to determine who will write out #attrd-protocol
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: election_complete:	Election election-attrd complete
Jun 22 07:54:09 [1617] vmi243500      attrd:     info: write_attribute:	Processed 1 private change for #attrd-protocol, id=<n/a>, set=(null)
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: setup_cib:	Watching for stonith topology changes
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: qb_ipcs_us_publish:	server name: stonith-ng
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: main:	Starting stonith-ng mainloop
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 joined group stonith-ng (counter=0.0)
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=0.0)
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: init_cib_cache_cb:	Updating device list from the cib: init
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.0
Jun 22 07:54:09 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:10 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 joined group crmd (counter=0.0)
Jun 22 07:54:10 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=0.0)
Jun 22 07:54:10 [1615] vmi243500 stonith-ng:     info: stonith_device_register:	Added 'stonith-sbd' to the device list (1 active devices)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_timer_popped:	Election Trigger (I_DC_TIMEOUT) just popped (20000ms)
Jun 22 07:54:30 [1619] vmi243500       crmd:  warning: do_log:	Input I_DC_TIMEOUT received in state S_PENDING from crm_timer_popped
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_PENDING -> S_ELECTION | input=I_DC_TIMEOUT cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: election_complete:	Election election-0 complete
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: election_timeout_popped:	Election failed: Declaring ourselves the winner
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_log:	Input I_ELECTION_DC received in state S_ELECTION from election_timeout_popped
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_ELECTION -> S_INTEGRATION | input=I_ELECTION_DC cause=C_TIMER_POPPED origin=election_timeout_popped
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_te_control:	Registering TE UUID: b58f891c-6e09-4d3a-be21-ca68613900d7
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: set_graph_functions:	Setting custom graph functions
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_pid_active:	Could not read from /proc/1589/exe: Permission denied (13)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_dc_takeover:	Taking over DC status for this partition
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_readwrite:	We are now in R/W mode
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_master operation for section 'all': OK (rc=0, origin=local/crmd/5, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section cib to all (origin=local/crmd/6)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243500/crmd/6, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/8)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/8, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/10)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: join_make_offer:	Making join offers based on membership 1156
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: join_make_offer:	join-1: Sending offer to vmi243500
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-1 phase none -> welcomed
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_dc_join_offer_all:	join-1: Waiting on 1 outstanding join acks
Jun 22 07:54:30 [1619] vmi243500       crmd:  warning: do_log:	Input I_ELECTION_DC received in state S_INTEGRATION from do_election_check
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	initialize_join: Node vmi243500[771304931] - join-2 phase welcomed -> none
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243500
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase none -> welcomed
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_dc_join_offer_all:	join-2: Waiting on 1 outstanding join acks
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: update_dc:	Set DC to vmi243500 (3.1.0)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_expected:	update_dc: Node vmi243500[771304931] - expected state is now member (was (null))
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/10, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/12)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243500[771304931] - join-2 phase welcomed -> integrated
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_INTEGRATION -> S_FINALIZE_JOIN | input=I_INTEGRATED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243500=integrated
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_dc_join_finalize:	join-2: Syncing our CIB to the rest of the cluster
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/12, version=1.589.0)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	finalize_join_for: Node vmi243500[771304931] - join-2 phase integrated -> finalized
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_ack: Node vmi243500[771304931] - join-2 phase finalized -> confirmed
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_dc_join_ack:	join-2: Updating node state to member for vmi243500
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243500 | xpath=//node_state[@uname='vmi243500']/lrm
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243500: e432897816ff0f49023a83f62596925e
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_replace:	Replaced 1.589.0 with 1.589.0 from vmi243500
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243500/crmd/16, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/17)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/lrm to all (origin=local/crmd/18)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/19)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/17, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/lrm: OK (rc=0, origin=vmi243500/crmd/18, version=1.589.0)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-22.raw
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.0 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.1 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="771304931" uname="vmi243500" in_ccm="true" crmd="online" crm-debug-origin="do_lrm_query_internal"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                 <lrm id="771304931">
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                   <lrm_resources/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                 </lrm>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++               </node_state>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/19, version=1.589.1)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_FINALIZE_JOIN -> S_POLICY_ENGINE | input=I_FINALIZED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: crm_update_quorum:	Updating quorum status to false (call=23)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition -1 aborted: Quorum lost | source=crm_update_quorum:450 complete=true
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition -1 aborted: Peer Cancelled | source=do_te_invoke:131 complete=true
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/21)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: 51c044627a6f703657027a405a19b82a)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/22)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section cib to all (origin=local/crmd/23)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.LdpOSe (digest: /var/lib/pacemaker/cib/cib.8tZKmX)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/21, version=1.589.1)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.1 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.2 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_state_transition, @join=member, @expected=member
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/22, version=1.589.2)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.2 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.3 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3, @dc-uuid=771304931
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243500/crmd/23, version=1.589.3)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1618] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 07:54:30 [1618] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database    ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database    ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00      ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI           ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI          ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS         ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10       ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 07:54:30 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 07:54:30 [1618] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 0 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-136.bz2
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 0 (ref=pe_calc-dc-1592805270-9) derived from /var/lib/pacemaker/pengine/pe-warn-136.bz2
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation stonith-sbd_monitor_0 locally on vmi243500 | action 2
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'stonith-sbd' not found (0 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'stonith-sbd' to the rsc list (1 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=stonith-sbd_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/26)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.3 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.4 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_update_resource
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/26, version=1.589.4)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_database_monitor_0 locally on vmi243500 | action 3
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.4
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_database' not found (1 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_database' to the rsc list (2 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_database_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed Filesystem_meta-data_0 process 1714 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/27)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_database_monitor_0 locally on vmi243500 | action 4
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.4 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.5 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_database' not found (2 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/27, version=1.589.5)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_database' to the rsc list (3 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.5
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_database_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed IPaddr2_meta-data_0 process 1721 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/28)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_database_monitor_0 locally on vmi243500 | action 5
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_database' not found (3 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_database' to the rsc list (4 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.5 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.6 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" o
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_database_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/28, version=1.589.6)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.6
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed SAPDatabase_meta-data_0 process 1744 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/29)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_ASCS_monitor_0 locally on vmi243500 | action 6
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.6 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.7 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" o
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.7
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_ASCS' not found (4 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_ASCS' to the rsc list (5 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_ASCS_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/29, version=1.589.7)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/30)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_ASCS_monitor_0 locally on vmi243500 | action 7
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.7 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.8 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ASCS' not found (5 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/30, version=1.589.8)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ASCS' to the rsc list (6 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.8
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ASCS_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ASCS00_monitor_0 locally on vmi243500 | action 8
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ASCS00' not found (6 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ASCS00' to the rsc list (7 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/31)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ASCS00_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.8 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.9 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/31, version=1.589.9)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.9
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed SAPInstance_meta-data_0 process 1820 exited with rc=0
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_2_DEV_ASCS_monitor_0 locally on vmi243500 | action 9
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/32)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_2_DEV_ASCS' not found (7 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_2_DEV_ASCS' to the rsc list (8 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_2_DEV_ASCS_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for stonith-sbd on vmi243500: 7 (not running) | call=5 key=stonith-sbd_monitor_0 confirmed=true cib-update=34
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_database on vmi243500: 7 (not running) | call=9 key=fs_DEV_database_monitor_0 confirmed=true cib-update=35
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_database on vmi243500: 7 (not running) | call=13 key=vip_DEV_database_monitor_0 confirmed=true cib-update=36
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_ASCS on vmi243500: 7 (not running) | call=21 key=fs_DEV_ASCS_monitor_0 confirmed=true cib-update=37
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.9 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.10 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/32, version=1.589.10)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/33)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/34)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/35)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/36)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.10
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/37)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_database on vmi243500: 7 (not running) | call=17 key=rsc_DEV_database_monitor_0 confirmed=true cib-update=38
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.10 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.11 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-stat
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/33, version=1.589.11)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.11 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.12 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:7;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=5, @rc-code=7, @op-status=0, @exec-time=8
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/34, version=1.589.12)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.11
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.12 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.13 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:7;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=9, @rc-code=7, @op-status=0, @exec-time=90
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/35, version=1.589.13)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.13 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.14 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:7;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=13, @rc-code=7, @op-status=0, @exec-time=72
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/36, version=1.589.14)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.14 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.15 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:7;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=21, @rc-code=7, @op-status=0, @exec-time=81
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.12
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/37, version=1.589.15)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/38)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.13
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.15 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.16 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:7;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=17, @rc-code=7, @op-status=0, @exec-time=98
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/38, version=1.589.16)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action stonith-sbd_monitor_0 (2) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_monitor_0 (3) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_monitor_0 (4) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_monitor_0 (6) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_monitor_0 (5) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_3_DEV_ASCS_monitor_0 locally on vmi243500 | action 10
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.14
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_3_DEV_ASCS' not found (8 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_3_DEV_ASCS' to the rsc list (9 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_3_DEV_ASCS_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_CI_monitor_0 locally on vmi243500 | action 11
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_CI' not found (9 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.15
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_CI' to the rsc list (10 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_CI_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_CI_monitor_0 locally on vmi243500 | action 12
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/39)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/40)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_CI' not found (10 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_CI' to the rsc list (11 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_CI_monitor_0
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.16
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_CI_monitor_0 locally on vmi243500 | action 13
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (11 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (12 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_CI_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.16 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.17 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_ERS_monitor_0 locally on vmi243500 | action 14
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/39, version=1.589.17)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.17 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.18 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/40, version=1.589.18)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.17
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/41)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/42)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ERS' not found (12 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ERS' to the rsc list (13 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ERS_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/43)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.18 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.19 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.18
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/41, version=1.589.19)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.19 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.20 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/42, version=1.589.20)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.20 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.21 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.19
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/43, version=1.589.21)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.20
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ASCS on vmi243500: 7 (not running) | call=25 key=vip_DEV_ASCS_monitor_0 confirmed=true cib-update=44
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/44)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.21 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.22 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:7;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=25, @rc-code=7, @op-status=0, @exec-time=117
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/44, version=1.589.22)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_monitor_0 (7) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ERS10_monitor_0 locally on vmi243500 | action 15
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ERS10' not found (13 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.21
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ERS10' to the rsc list (14 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ERS10_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/45)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.22
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.22 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.23 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/45, version=1.589.23)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.23
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ASCS00 on vmi243500: 7 (not running) | call=29 key=rsc_DEV_ASCS00_monitor_0 confirmed=true cib-update=46
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/46)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.23 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.24 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:7;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=29, @rc-code=7, @op-status=0, @exec-time=121
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/46, version=1.589.24)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.24
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_monitor_0 (8) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_CPU_monitor_0 locally on vmi243500 | action 16
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_CPU' not found (14 active resources)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_CPU' to the rsc list (15 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_monitor_0
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed HealthCPU_meta-data_0 process 2183 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/47)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_2_DEV_ASCS on vmi243500: 7 (not running) | call=33 key=fs_2_DEV_ASCS_monitor_0 confirmed=true cib-update=48
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.24 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.25 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_3_DEV_ASCS on vmi243500: 7 (not running) | call=37 key=fs_3_DEV_ASCS_monitor_0 confirmed=true cib-update=49
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_CI on vmi243500: 7 (not running) | call=41 key=fs_DEV_CI_monitor_0 confirmed=true cib-update=50
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/47, version=1.589.25)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/48)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/49)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/50)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_CI on vmi243500: 7 (not running) | call=45 key=vip_DEV_CI_monitor_0 confirmed=true cib-update=51
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/51)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.25
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.25 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.26 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:7;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=33, @rc-code=7, @op-status=0, @exec-time=128
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/48, version=1.589.26)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_monitor_0 (9) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_NIC_monitor_0 locally on vmi243500 | action 17
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.26 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.27 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:7;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=37, @rc-code=7, @op-status=0, @exec-time=110
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/49, version=1.589.27)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_NIC' not found (15 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.27 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.28 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_NIC' to the rsc list (16 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:7;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=41, @rc-code=7, @op-status=0, @exec-time=119
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/50, version=1.589.28)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.28 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.29 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:7;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=45, @rc-code=7, @op-status=0, @exec-time=124
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/51, version=1.589.29)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.26
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.27
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.28
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.29
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed ethmonitor_meta-data_0 process 2289 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/52)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_monitor_0 (10) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_monitor_0 (11) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.29 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.30 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_monitor_0 (12) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=49 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=53
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/52, version=1.589.30)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ERS on vmi243500: 7 (not running) | call=53 key=vip_DEV_ERS_monitor_0 confirmed=true cib-update=54
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/53)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_CPU on vmi243500: 7 (not running) | call=61 key=global_rsc_DEV_CPU_monitor_0 confirmed=true cib-update=55
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/54)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/55)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation dlm_DEV:0_monitor_0 locally on vmi243500 | action 18
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV' not found (16 active resources)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.30 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.31 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=49, @rc-code=7, @op-status=0, @exec-time=140
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.30
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV:0' not found (16 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/53, version=1.589.31)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'dlm_DEV' to the rsc list (17 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=dlm_DEV_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.31 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.32 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:7;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=53, @rc-code=7, @op-status=0, @exec-time=140
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/54, version=1.589.32)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.32 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.33 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:7;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=61, @rc-code=7, @op-status=0, @exec-time=23, @queue-time=1
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/55, version=1.589.33)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.31
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.32
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.33
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: action_synced_wait:	Managed controld_meta-data_0 process 2303 exited with rc=0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/56)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_sapmnt:0_monitor_0 locally on vmi243500 | action 19
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.33 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.34 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1" in
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/56, version=1.589.34)
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt' not found (17 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.34
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt:0' not found (17 active resources)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1616] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_sapmnt' to the rsc list (18 active resources)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_sapmnt_monitor_0
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/57)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_monitor_0 (13) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ERS_monitor_0 (14) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_monitor_0 (16) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.34 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.35 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat"/>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/57, version=1.589.35)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ERS10 on vmi243500: 7 (not running) | call=57 key=rsc_DEV_ERS10_monitor_0 confirmed=true cib-update=58
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/58)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.35 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.36 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:7;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=57, @rc-code=7, @op-status=0, @exec-time=166
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ERS10_monitor_0 (15) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/58, version=1.589.36)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.35
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.36
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_NIC on vmi243500: 7 (not running) | call=65 key=global_rsc_DEV_NIC_monitor_0 confirmed=true cib-update=59
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/59)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.36 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.37 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:7;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=65, @rc-code=7, @op-status=0, @exec-time=71
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_monitor_0 (17) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.37
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/59, version=1.589.37)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for dlm_DEV on vmi243500: 7 (not running) | call=70 key=dlm_DEV_monitor_0 confirmed=true cib-update=60
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/60)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.37 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.38 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:7;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=70, @rc-code=7, @op-status=0, @exec-time=58
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/60, version=1.589.38)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action dlm_DEV_monitor_0 (18) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.38
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_sapmnt on vmi243500: 7 (not running) | call=75 key=fs_DEV_sapmnt_monitor_0 confirmed=true cib-update=61
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/61)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.38 2
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.39 (null)
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:7;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=75, @rc-code=7, @op-status=0, @exec-time=65
Jun 22 07:54:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/61, version=1.589.39)
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_sapmnt_monitor_0 (19) confirmed on vmi243500 (rc=7)
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: run_graph:	Transition 0 (Complete=18, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-136.bz2): Complete
Jun 22 07:54:30 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 07:54:30 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.39
Jun 22 07:54:30 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 07:54:34 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:34 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:35 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:35 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:35 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 1b56380b603b2da583516cc0463c4599 for 1.589.39 (0x55a43032c1a0 0)
Jun 22 07:54:35 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:36 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:36 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 07:54:39 [1619] vmi243500       crmd:     info: crm_procfs_pid_of:	Found cib active as process 1614
Jun 22 07:54:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was ffffffff)
Jun 22 08:09:30 [1619] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 08:09:30 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 08:09:30 [1619] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:09:30 [1618] vmi243500    pengine:  warning: cluster_status:	Fencing and resource management disabled due to lack of quorum
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:09:30 [1618] vmi243500    pengine:  warning: stage6:	Node vmi243493 is unclean!
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: stage6:	Cannot fence unclean nodes until quorum is attained (or no-quorum-policy is set to ignore)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )   due to no quorum (blocked)
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:09:30 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:09:30 [1618] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 1 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-137.bz2
Jun 22 08:09:30 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:09:30 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 1 (ref=pe_calc-dc-1592806170-29) derived from /var/lib/pacemaker/pengine/pe-warn-137.bz2
Jun 22 08:09:30 [1619] vmi243500       crmd:   notice: run_graph:	Transition 1 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-warn-137.bz2): Complete
Jun 22 08:09:30 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 08:09:30 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:15:10 [1619] vmi243500       crmd:   notice: pcmk_quorum_notification:	Quorum acquired | membership=1160 members=2
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:   notice: pcmk_quorum_notification:	Quorum acquired | membership=1160 members=2
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: crm_get_peer:	Created entry 8c09477e-a9ed-4702-bff5-0d881b7f5e94/0x559ba30e48f0 for node (null)/96317541 (2 total)
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry fa3a89df-f6df-4b8b-99fb-9a291872862b/0x55e8374ee920 for node (null)/96317541 (2 total)
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:10 [1619] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Jun 22 08:15:10 [1619] vmi243500       crmd:   notice: crm_update_quorum:	Updating quorum status to true (call=63)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section cib to all (origin=local/crmd/63)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/65)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/66)
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:10 [1613] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.39 2
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.40 48579413cc2796a79c1ee85235582641
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=40, @have-quorum=1
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243500/crmd/63, version=1.589.40)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/65, version=1.589.40)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.40 2
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.41 (null)
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=41
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=post_cache_update
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="96317541" in_ccm="true" crmd="offline" crm-debug-origin="post_cache_update"/>
Jun 22 08:15:10 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/66, version=1.589.41)
Jun 22 08:15:11 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:15:11 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:15:11 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:15:12 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 joined group pacemakerd (counter=1.0)
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 still member of group pacemakerd (peer=(null), counter=1.0)
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=1.1)
Jun 22 08:15:14 [1613] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 joined group attrd (counter=1.0)
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 joined group stonith-ng (counter=1.0)
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:14 [1617] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry 9b77f19f-493a-4a90-8645-86d4a21d728c/0x5613424336c0 for node (null)/96317541 (2 total)
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 still member of group stonith-ng (peer=(null), counter=1.0)
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: crm_get_peer:	Created entry 8e9dcaef-11b5-4c0a-97a5-c11de84b0898/0x5600cea06820 for node (null)/96317541 (2 total)
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 still member of group attrd (peer=(null), counter=1.0)
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:14 [1617] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=1.1)
Jun 22 08:15:14 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=1.1)
Jun 22 08:15:14 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:14 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 joined group cib (counter=1.0)
Jun 22 08:15:14 [1614] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:14 [1614] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:14 [1614] vmi243500        cib:     info: crm_get_peer:	Created entry 2cba37d7-942a-4939-b35b-da618e0898b2/0x55a43040c190 for node (null)/96317541 (2 total)
Jun 22 08:15:14 [1614] vmi243500        cib:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:14 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 still member of group cib (peer=(null), counter=1.0)
Jun 22 08:15:14 [1614] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:14 [1614] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:14 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=1.1)
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 1 aborted: Quorum gained | source=abort_timer_popped:489 complete=true
Jun 22 08:15:15 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (3600s) for stonith-sbd on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ERS on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ERS10 on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_CPU on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_NIC on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (60s) for dlm_DEV:0 on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_sapmnt:0 on vmi243500
Jun 22 08:15:15 [1618] vmi243500    pengine:  warning: stage6:	Scheduling Node vmi243493 for STONITH
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogNodeActions:	 * Fence (reboot) vmi243493 'node is unclean'
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )  
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:15:15 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:15:15 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 7c126d3f28c4fe1aa687c17876fdf2ae for 1.589.41 (0x55a4303cde10 0)
Jun 22 08:15:15 [1618] vmi243500    pengine:  warning: process_pe_message:	Calculated transition 2 (with warnings), saving inputs in /var/lib/pacemaker/pengine/pe-warn-138.bz2
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:15:15 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 2 (ref=pe_calc-dc-1592806515-31) derived from /var/lib/pacemaker/pengine/pe-warn-138.bz2
Jun 22 08:15:15 [1619] vmi243500       crmd:   notice: te_fence_node:	Requesting fencing (reboot) of node vmi243493 | action=67 timeout=86000
Jun 22 08:15:15 [1615] vmi243500 stonith-ng:   notice: handle_request:	Client crmd.1619.b147cd0b wants to fence (reboot) 'vmi243493' with device '(any)'
Jun 22 08:15:15 [1615] vmi243500 stonith-ng:   notice: initiate_remote_stonith_op:	Requesting peer fencing (reboot) of vmi243493 | id=9bc4c8b7-6b29-42b9-85d2-00ce65c33b03 state=0
Jun 22 08:15:15 [1614] vmi243500        cib:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:15 [1614] vmi243500        cib:   notice: process_ping_reply:	Local CIB 1.589.41.7c126d3f28c4fe1aa687c17876fdf2ae differs from vmi243493: 1.588.0.5635f855a8a5eef628247c0ea236b17c 0x55a43040fbd0
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 joined group crmd (counter=1.0)
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:15 [1619] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 still member of group crmd (peer=(null), counter=1.0)
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:15 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=1.1)
Jun 22 08:15:15 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/2, version=1.589.41)
Jun 22 08:15:15 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243493/attrd/2, version=1.589.41)
Jun 22 08:15:16 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:16 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243493]: (null) -> 2 from vmi243493
Jun 22 08:15:16 [1617] vmi243500      attrd:     info: write_attribute:	Processed 2 private changes for #attrd-protocol, id=<n/a>, set=(null)
Jun 22 08:15:16 [1619] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:16 [1619] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243493 is now member
Jun 22 08:15:16 [1615] vmi243500 stonith-ng:     info: dynamic_list_search_cb:	Refreshing port list for stonith-sbd
Jun 22 08:15:16 [1615] vmi243500 stonith-ng:     info: process_remote_stonith_query:	Query result 1 of 2 from vmi243500 for vmi243493/reboot (1 devices) 9bc4c8b7-6b29-42b9-85d2-00ce65c33b03
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_INTEGRATION | input=I_NODE_JOIN cause=C_HA_MESSAGE origin=route_message
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: do_dc_join_offer_one:	join-2: Processing join_announce request from vmi243493 in state S_INTEGRATION
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: join_make_offer:	Making join offers based on membership 1160
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243493
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243493[96317541] - join-2 phase none -> welcomed
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase confirmed -> none
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243500
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase none -> welcomed
Jun 22 08:15:17 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 2 aborted: Node join | source=do_dc_join_offer_one:278 complete=false
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:17 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:     info: process_remote_stonith_query:	Query result 2 of 2 from vmi243493 for vmi243493/reboot (1 devices) 9bc4c8b7-6b29-42b9-85d2-00ce65c33b03
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:     info: process_remote_stonith_query:	All query replies have arrived, continuing (2 expected/2 received) 
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:     info: call_remote_stonith:	Total timeout set to 86 for peer's fencing of vmi243493 for crmd.1619|id=9bc4c8b7-6b29-42b9-85d2-00ce65c33b03
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:     info: call_remote_stonith:	Requesting that 'vmi243500' perform op 'vmi243493 reboot' for crmd.1619 (103s, 0s)
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:   notice: can_fence_host_with_device:	stonith-sbd can fence (reboot) vmi243493: dynamic-list
Jun 22 08:15:17 [1615] vmi243500 stonith-ng:     info: stonith_fence_get_devices_cb:	Found 1 matching devices for 'vmi243493'
Jun 22 08:15:43 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 left group attrd (peer=vmi243493, counter=2.0)
Jun 22 08:15:43 [1617] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:15:43 [1617] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:15:43 [1617] vmi243500      attrd:   notice: attrd_peer_remove:	Removing all vmi243493 attributes for peer loss
Jun 22 08:15:43 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 left group pacemakerd (peer=vmi243493, counter=2.0)
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 left group stonith-ng (peer=vmi243493, counter=2.0)
Jun 22 08:15:43 [1613] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:15:43 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=2.0)
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:15:43 [1613] vmi243500 pacemakerd:     info: crm_cs_flush:	Sent 0 CPG messages  (1 remaining, last=8): Try again (6)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 left group cib (peer=vmi243493, counter=2.0)
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:15:43 [1614] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 left group crmd (peer=vmi243493, counter=2.0)
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: peer_update_callback:	Client vmi243493/peer now has status [offline] (DC=true, changed=4000000)
Jun 22 08:15:43 [1614] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: peer_update_callback:	Peer vmi243493 left us
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:     info: crm_cs_flush:	Sent 0 CPG messages  (1 remaining, last=7): Try again (6)
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting transient_attributes status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/transient_attributes
Jun 22 08:15:43 [1617] vmi243500      attrd:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:15:43 [1614] vmi243500        cib:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:15:43 [1617] vmi243500      attrd:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:15:43 [1614] vmi243500        cib:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:15:43 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=2.0)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=2.0)
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:15:43 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=2.0)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes to all (origin=local/crmd/68)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: crm_cs_flush:	Sent 0 CPG messages  (1 remaining, last=58): Try again (6)
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=2.0)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/69)
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: crm_cs_flush:	Sent 0 CPG messages  (1 remaining, last=13): Try again (6)
Jun 22 08:15:43 [1613] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Quorum retained | membership=1168 members=2
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: pcmk_quorum_notification:	Quorum retained | membership=1168 members=2
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: crm_update_peer_join:	reap_dead_nodes: Node vmi243493[96317541] - join-2 phase welcomed -> none
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: do_dc_join_offer_one:	An unknown node joined - (re-)offer to any unconfirmed nodes
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: join_make_offer:	Making join offers based on membership 1168
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: join_make_offer:	Skipping vmi243500: already known 1
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: join_make_offer:	Not making an offer to vmi243493: not active (member)
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:43 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:43 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/73)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/74)
Jun 22 08:15:43 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 7c126d3f28c4fe1aa687c17876fdf2ae for 1.589.41 (0x55a43040fd00 0)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: crm_cs_flush:	Sent 5 CPG messages  (0 remaining, last=63): OK (1)
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crm_cs_flush:	Sent 2 CPG messages  (0 remaining, last=15): OK (1)
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243500[771304931] - join-2 phase welcomed -> integrated
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_INTEGRATION -> S_FINALIZE_JOIN | input=I_INTEGRATED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243500=integrated
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243493=none
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_dc_join_finalize:	join-2: Syncing our CIB to the rest of the cluster
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243500/crmd/68, version=1.589.41)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.41 2
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.42 (null)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=42
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=peer_update_callback, @uname=vmi243493
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/69, version=1.589.42)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/73, version=1.589.42)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.42 2
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.43 (null)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=43
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=post_cache_update
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/74, version=1.589.43)
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crm_update_peer_join:	finalize_join_for: Node vmi243500[771304931] - join-2 phase integrated -> finalized
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243500: 1ed05a4156802310e38afbd00aa51101
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_replace:	Replaced 1.589.43 with 1.589.43 from vmi243500
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243500/crmd/75, version=1.589.43)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/76)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/76, version=1.589.43)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-23.raw
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: 24d34f2504dce9111c60efb503b1db3e)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.OJxfct (digest: /var/lib/pacemaker/cib/cib.1SE5Lw)
Jun 22 08:15:44 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_FINALIZE_JOIN
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_FINALIZE_JOIN
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_ack: Node vmi243500[771304931] - join-2 phase finalized -> confirmed
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_dc_join_ack:	join-2: Updating node state to member for vmi243500
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243500 | xpath=//node_state[@uname='vmi243500']/lrm
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/lrm to all (origin=local/crmd/77)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/78)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.43 2
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.44 (null)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by deletion of lrm[@id='771304931']: Resource state removal | cib=1.589.44 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/lrm[@id='771304931'] complete=false
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/lrm: OK (rc=0, origin=vmi243500/crmd/77, version=1.589.44)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.44 2
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.45 (null)
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_lrm_query_internal
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <lrm id="771304931"/>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             <lrm_resources>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="9" rc-code="7" op-status="0" interval="0" last-run="15928
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="70" rc-code="7" op-status="0" interval="0" last-run="1592805270" last-r
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="75" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="33" rc-code="7" op-status="0" interval="0" last-run="15928052
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="41" rc-code="7" op-status="0" interval="0" last-run="1592805270" la
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="49" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="45" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="61" rc-code="7" op-status="0" interval="0" last-r
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="57" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="5" rc-code="7" op-status="0" interval="0" last-run="1592805270" l
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="21" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="25" rc-code="7" op-status="0" interval="0" last-run="1592805270
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="17" rc-code="7" op-status="0" interval="0" last-run="15
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="29" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="37" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="53" rc-code="7" op-status="0" interval="0" last-run="1592805270
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="13" rc-code="7" op-status="0" interval="0" last-run="15
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat">
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="65" rc-code="7" op-status="0" interval="0" last-r
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             </lrm_resources>
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_perform_op:	++                                           </lrm>
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.3) fs_DEV_database_monitor_0.9=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation dlm_DEV_monitor_0 'create' on vmi243500: Old event | magic=0:7;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.18) dlm_DEV_monitor_0.70=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_sapmnt_monitor_0 'create' on vmi243500: Old event | magic=0:7;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.19) fs_DEV_sapmnt_monitor_0.75=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_2_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.9) fs_2_DEV_ASCS_monitor_0.33=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.11) fs_DEV_CI_monitor_0.41=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.13) rsc_DEV_CI_monitor_0.49=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.12) vip_DEV_CI_monitor_0.45=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation global_rsc_DEV_CPU_monitor_0 'create' on vmi243500: Old event | magic=0:7;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.16) global_rsc_DEV_CPU_monitor_0.61=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_ERS10_monitor_0 'create' on vmi243500: Old event | magic=0:7;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.15) rsc_DEV_ERS10_monitor_0.57=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation stonith-sbd_monitor_0 'create' on vmi243500: Old event | magic=0:7;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.2) stonith-sbd_monitor_0.5=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.6) fs_DEV_ASCS_monitor_0.21=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.7) vip_DEV_ASCS_monitor_0.25=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.5) rsc_DEV_database_monitor_0.17=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_ASCS00_monitor_0 'create' on vmi243500: Old event | magic=0:7;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.8) rsc_DEV_ASCS00_monitor_0.29=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_3_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.10) fs_3_DEV_ASCS_monitor_0.37=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_ERS_monitor_0 'create' on vmi243500: Old event | magic=0:7;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.14) vip_DEV_ERS_monitor_0.53=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.4) vip_DEV_database_monitor_0.13=not running: arrived really late
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation global_rsc_DEV_NIC_monitor_0 'create' on vmi243500: Old event | magic=0:7;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.45 source=process_graph_event:486 complete=false
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.17) global_rsc_DEV_NIC_monitor_0.65=not running: arrived really late
Jun 22 08:15:44 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/78, version=1.589.45)
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:44 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:45 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 joined group pacemakerd (counter=3.0)
Jun 22 08:15:45 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 still member of group pacemakerd (peer=vmi243493, counter=3.0)
Jun 22 08:15:45 [1613] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now online
Jun 22 08:15:45 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=3.1)
Jun 22 08:15:45 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_FINALIZE_JOIN
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_FINALIZE_JOIN -> S_POLICY_ENGINE | input=I_FINALIZED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 08:15:45 [1619] vmi243500       crmd:   notice: crm_update_quorum:	Updating quorum status to true (call=83)
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Cancelled | source=do_te_invoke:131 complete=false
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/81)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/82)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section cib to all (origin=local/crmd/83)
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/81, version=1.589.45)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.45 2
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.46 (null)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_state_transition
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_state_transition, @join=down
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/82, version=1.589.46)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243500/crmd/83, version=1.589.46)
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 joined group stonith-ng (counter=3.0)
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry d5ed9e07-a56e-4ba9-9066-fa0a31e305b7/0x561342467ec0 for node (null)/96317541 (2 total)
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 still member of group stonith-ng (peer=(null), counter=3.0)
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=3.1)
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 joined group attrd (counter=3.0)
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:45 [1617] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: crm_get_peer:	Created entry e9b9e696-3155-4ae6-9e57-7309d08d7236/0x5600cea03b30 for node (null)/96317541 (2 total)
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 still member of group attrd (peer=(null), counter=3.0)
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:45 [1617] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:45 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=3.1)
Jun 22 08:15:45 [1615] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:45 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 joined group cib (counter=3.0)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Jun 22 08:15:45 [1614] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Jun 22 08:15:45 [1614] vmi243500        cib:     info: crm_get_peer:	Created entry fd13ac82-1a19-49d7-a1a3-07992891dca7/0x55a4305175e0 for node (null)/96317541 (2 total)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Jun 22 08:15:45 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 still member of group cib (peer=(null), counter=3.0)
Jun 22 08:15:45 [1614] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Jun 22 08:15:45 [1614] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Jun 22 08:15:45 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=3.1)
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:45 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:45 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 joined group crmd (counter=3.0)
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 still member of group crmd (peer=vmi243493, counter=3.0)
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now online
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: peer_update_callback:	Client vmi243493/peer now has status [online] (DC=true, changed=4000000)
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=3.1)
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_INTEGRATION | input=I_NODE_JOIN cause=C_FSA_INTERNAL origin=peer_update_callback
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_dc_join_offer_one:	An unknown node joined - (re-)offer to any unconfirmed nodes
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: join_make_offer:	Skipping vmi243500: already known 4
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243493
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243493[96317541] - join-2 phase none -> welcomed
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/84)
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.46 2
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.47 (null)
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crmd=online, @crm-debug-origin=peer_update_callback
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/84, version=1.589.47)
Jun 22 08:15:46 [1614] vmi243500        cib:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:46 [1617] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Jun 22 08:15:46 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243493]: (null) -> 2 from vmi243493
Jun 22 08:15:46 [1617] vmi243500      attrd:     info: write_attribute:	Processed 2 private changes for #attrd-protocol, id=<n/a>, set=(null)
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243493/attrd/2, version=1.589.47)
Jun 22 08:15:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/2, version=1.589.47)
Jun 22 08:15:46 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_dc_join_offer_one:	join-2: Processing join_announce request from vmi243493 in state S_INTEGRATION
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_offer_one: Node vmi243493[96317541] - join-2 phase welcomed -> none
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243493
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243493[96317541] - join-2 phase none -> welcomed
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase confirmed -> none
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243500
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase none -> welcomed
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Node join | source=do_dc_join_offer_one:278 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:47 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243500[771304931] - join-2 phase welcomed -> integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243493[96317541] - join-2 phase welcomed -> integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_expected:	do_dc_join_filter_offer: Node vmi243493[96317541] - expected state is now member (was (null))
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_INTEGRATION -> S_FINALIZE_JOIN | input=I_INTEGRATED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243500=integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243493=integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_dc_join_finalize:	join-2: Syncing our CIB to the rest of the cluster
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_FINALIZE_JOIN -> S_INTEGRATION | input=I_JOIN_REQUEST cause=C_HA_MESSAGE origin=route_message
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_dc_join_offer_one:	join-2: Processing join_request request from vmi243493 in state S_INTEGRATION
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_offer_one: Node vmi243493[96317541] - join-2 phase integrated -> none
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243493
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243493[96317541] - join-2 phase none -> welcomed
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase integrated -> none
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: join_make_offer:	join-2: Sending offer to vmi243500
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	join_make_offer: Node vmi243500[771304931] - join-2 phase none -> welcomed
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Node join | source=do_dc_join_offer_one:278 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243493[96317541] - join-2 phase welcomed -> integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_INTEGRATION from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243500: 3e922dfd8a4220fe1d676922163b841d
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_replace:	Replaced 1.589.47 with 1.589.47 from vmi243500
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243500/crmd/86, version=1.589.47)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-24.raw
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: c229e07ced62c15962da3f13e6a06780)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.e6b6BX (digest: /var/lib/pacemaker/cib/cib.mj2Axb)
Jun 22 08:15:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_INTEGRATION
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_filter_offer: Node vmi243500[771304931] - join-2 phase welcomed -> integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_INTEGRATION -> S_FINALIZE_JOIN | input=I_INTEGRATED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243500=integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crmd_join_phase_log:	join-2: vmi243493=integrated
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_dc_join_finalize:	join-2: Syncing our CIB to the rest of the cluster
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	finalize_join_for: Node vmi243500[771304931] - join-2 phase integrated -> finalized
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	finalize_join_for: Node vmi243493[96317541] - join-2 phase integrated -> finalized
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/89)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/90)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243500: 3e922dfd8a4220fe1d676922163b841d
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_replace:	Replaced 1.589.47 with 1.589.47 from vmi243500
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243500/crmd/88, version=1.589.47)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/89, version=1.589.47)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_ack: Node vmi243493[96317541] - join-2 phase finalized -> confirmed
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_dc_join_ack:	join-2: Updating node state to member for vmi243493
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/lrm
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/90, version=1.589.47)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/lrm to all (origin=local/crmd/91)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/92)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243500/crmd/91, version=1.589.47)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.47 2
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.48 (null)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=48
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_lrm_query_internal
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']:  <lrm id="96317541"/>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                            <lrm_resources/>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                          </lrm>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/92, version=1.589.48)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-25.raw
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.589.0 of the CIB to disk (digest: c229e07ced62c15962da3f13e6a06780)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.eQByk3 (digest: /var/lib/pacemaker/cib/cib.N0ixoh)
Jun 22 08:15:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_FINALIZE_JOIN
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: crm_update_peer_join:	do_dc_join_ack: Node vmi243500[771304931] - join-2 phase finalized -> confirmed
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_dc_join_ack:	join-2: Updating node state to member for vmi243500
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243500 | xpath=//node_state[@uname='vmi243500']/lrm
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/lrm to all (origin=local/crmd/93)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.48 2
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.49 (null)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=49
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/lrm: OK (rc=0, origin=vmi243500/crmd/93, version=1.589.49)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by deletion of lrm[@id='771304931']: Resource state removal | cib=1.589.49 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/lrm[@id='771304931'] complete=false
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/94)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.49 2
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.50 (null)
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=50
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_lrm_query_internal
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <lrm id="771304931"/>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             <lrm_resources>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="9" rc-code="7" op-status="0" interval="0" last-run="15928
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="70" rc-code="7" op-status="0" interval="0" last-run="1592805270" last-r
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="75" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="33" rc-code="7" op-status="0" interval="0" last-run="15928052
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="41" rc-code="7" op-status="0" interval="0" last-run="1592805270" la
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="49" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="45" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="61" rc-code="7" op-status="0" interval="0" last-r
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="57" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="5" rc-code="7" op-status="0" interval="0" last-run="1592805270" l
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="21" rc-code="7" op-status="0" interval="0" last-run="1592805270" 
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="25" rc-code="7" op-status="0" interval="0" last-run="1592805270
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="17" rc-code="7" op-status="0" interval="0" last-run="15
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="29" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="37" rc-code="7" op-status="0" interval="0" last-run="159280
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="53" rc-code="7" op-status="0" interval="0" last-run="1592805270
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="13" rc-code="7" op-status="0" interval="0" last-run="15
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat">
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                                 <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="0:7;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id="65" rc-code="7" op-status="0" interval="0" last-r
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               </lrm_resource>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             </lrm_resources>
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_perform_op:	++                                           </lrm>
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;3:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.3) fs_DEV_database_monitor_0.9=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation dlm_DEV_monitor_0 'create' on vmi243500: Old event | magic=0:7;18:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.18) dlm_DEV_monitor_0.70=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_sapmnt_monitor_0 'create' on vmi243500: Old event | magic=0:7;19:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.19) fs_DEV_sapmnt_monitor_0.75=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_2_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;9:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.9) fs_2_DEV_ASCS_monitor_0.33=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;11:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.11) fs_DEV_CI_monitor_0.41=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;13:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.13) rsc_DEV_CI_monitor_0.49=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_CI_monitor_0 'create' on vmi243500: Old event | magic=0:7;12:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.12) vip_DEV_CI_monitor_0.45=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation global_rsc_DEV_CPU_monitor_0 'create' on vmi243500: Old event | magic=0:7;16:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.16) global_rsc_DEV_CPU_monitor_0.61=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_ERS10_monitor_0 'create' on vmi243500: Old event | magic=0:7;15:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.15) rsc_DEV_ERS10_monitor_0.57=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation stonith-sbd_monitor_0 'create' on vmi243500: Old event | magic=0:7;2:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.2) stonith-sbd_monitor_0.5=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;6:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.6) fs_DEV_ASCS_monitor_0.21=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;7:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.7) vip_DEV_ASCS_monitor_0.25=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;5:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.5) rsc_DEV_database_monitor_0.17=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation rsc_DEV_ASCS00_monitor_0 'create' on vmi243500: Old event | magic=0:7;8:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.8) rsc_DEV_ASCS00_monitor_0.29=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation fs_3_DEV_ASCS_monitor_0 'create' on vmi243500: Old event | magic=0:7;10:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.10) fs_3_DEV_ASCS_monitor_0.37=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_ERS_monitor_0 'create' on vmi243500: Old event | magic=0:7;14:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.14) vip_DEV_ERS_monitor_0.53=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation vip_DEV_database_monitor_0 'create' on vmi243500: Old event | magic=0:7;4:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.4) vip_DEV_database_monitor_0.13=not running: arrived really late
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted by operation global_rsc_DEV_NIC_monitor_0 'create' on vmi243500: Old event | magic=0:7;17:0:7:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.589.50 source=process_graph_event:486 complete=false
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (0.17) global_rsc_DEV_NIC_monitor_0.65=not running: arrived really late
Jun 22 08:15:48 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/94, version=1.589.50)
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_FINALIZE_JOIN from do_te_invoke
Jun 22 08:15:48 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_FINALIZE_JOIN -> S_POLICY_ENGINE | input=I_FINALIZED cause=C_FSA_INTERNAL origin=check_join_state
Jun 22 08:15:49 [1619] vmi243500       crmd:   notice: crm_update_quorum:	Updating quorum status to true (call=99)
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Cancelled | source=do_te_invoke:131 complete=false
Jun 22 08:15:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/97)
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/98)
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section cib to all (origin=local/crmd/99)
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/97, version=1.589.50)
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.50 2
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.51 (null)
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=51
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_state_transition
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_state_transition, @join=member, @expected=member
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/98, version=1.589.51)
Jun 22 08:15:49 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243500/crmd/99, version=1.589.51)
Jun 22 08:15:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:49 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:50 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:51 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:51 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:15:51 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:15:54 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 6de4895095586128ead5e04b40837abb for 1.589.51 (0x55a4303f08c0 0)
Jun 22 08:16:16 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:16:16 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=false
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:   notice: log_operation:	Operation 'reboot' [4864] (call 2 from crmd.1619) for host 'vmi243493' with device 'stonith-sbd' returned: 0 (OK)
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:   notice: remote_op_done:	Operation reboot of vmi243493 by vmi243500 for crmd.1619@vmi243500.9bc4c8b7: OK
Jun 22 08:16:18 [1619] vmi243500       crmd:   notice: tengine_stonith_callback:	Stonith operation 2/67:2:0:b58f891c-6e09-4d3a-be21-ca68613900d7: OK (0)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: tengine_stonith_callback:	Stonith operation 2 for vmi243493 passed
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: crm_update_peer_join:	crmd_peer_down: Node vmi243493[96317541] - join-2 phase confirmed -> none
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: crm_update_peer_expected:	crmd_peer_down: Node vmi243493[96317541] - expected state is now down (was member)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/lrm
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting transient_attributes status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/transient_attributes
Jun 22 08:16:18 [1619] vmi243500       crmd:   notice: tengine_stonith_notify:	Peer vmi243493 was terminated (reboot) by vmi243500 on behalf of crmd.1619: OK | initiator=vmi243500 ref=9bc4c8b7-6b29-42b9-85d2-00ce65c33b03
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/100)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/lrm
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting transient_attributes status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/transient_attributes
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/lrm to all (origin=local/crmd/101)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes to all (origin=local/crmd/102)
Jun 22 08:16:18 [1619] vmi243500       crmd:   notice: run_graph:	Transition 2 (Complete=5, Pending=0, Fired=0, Skipped=5, Incomplete=46, Source=/var/lib/pacemaker/pengine/pe-warn-138.bz2): Stopped
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: do_log:	Input I_WAIT_FOR_EVENT received in state S_POLICY_ENGINE from do_te_invoke
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Halt | source=do_te_invoke:138 complete=true
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 2 aborted: Peer Cancelled | source=do_te_invoke:131 complete=true
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.51 2
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.52 (null)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=52
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=send_stonith_update, @join=down, @expected=down
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/100, version=1.589.52)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: cib_fencing_updated:	Fencing update 100 for vmi243493: complete
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.52 2
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.53 37baad77450d80328c75a98d4206968d
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='96317541']/lrm[@id='96317541']
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=53
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243500/crmd/101, version=1.589.53)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 left group crmd (peer=vmi243493, counter=4.0)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: peer_update_callback:	Client vmi243493/peer now has status [offline] (DC=true, changed=4000000)
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: peer_update_callback:	Peer vmi243493 left us
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting transient_attributes status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/transient_attributes
Jun 22 08:16:18 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 left group attrd (peer=vmi243493, counter=4.0)
Jun 22 08:16:18 [1617] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243500/crmd/102, version=1.589.53)
Jun 22 08:16:18 [1617] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:16:18 [1617] vmi243500      attrd:   notice: attrd_peer_remove:	Removing all vmi243493 attributes for peer loss
Jun 22 08:16:18 [1617] vmi243500      attrd:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:16:18 [1617] vmi243500      attrd:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=4.0)
Jun 22 08:16:18 [1617] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=4.0)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/103)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/lrm to all (origin=local/crmd/104)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes to all (origin=local/crmd/105)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/103, version=1.589.53)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243500/crmd/104, version=1.589.53)
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 left group stonith-ng (peer=vmi243493, counter=4.0)
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:16:18 [1619] vmi243500       crmd:     info: cib_fencing_updated:	Fencing update 103 for vmi243493: complete
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:16:18 [1615] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=4.0)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243500/crmd/105, version=1.589.53)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_shutdown_req:	Peer vmi243493 is requesting to shut down
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_shutdown_req:	Peer vmi243493 is requesting to shut down
Jun 22 08:16:18 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 left group cib (peer=vmi243493, counter=4.0)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:16:18 [1614] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_update_peer_proc
Jun 22 08:16:18 [1614] vmi243500        cib:     info: crm_reap_dead_member:	Removing node with name vmi243493 and id 96317541 from membership cache
Jun 22 08:16:18 [1614] vmi243500        cib:   notice: reap_crm_member:	Purged 1 peer with id=96317541 and/or uname=vmi243493 from the membership cache
Jun 22 08:16:18 [1614] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=4.0)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes to all (origin=local/crmd/109)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/110)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243500/crmd/109, version=1.589.53)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.53 2
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.54 (null)
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=54
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crmd=offline, @crm-debug-origin=peer_update_callback
Jun 22 08:16:18 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/110, version=1.589.54)
Jun 22 08:16:18 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 left group pacemakerd (peer=vmi243493, counter=4.0)
Jun 22 08:16:18 [1613] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node vmi243493[96317541] - corosync-cpg is now offline
Jun 22 08:16:18 [1613] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=4.0)
Jun 22 08:16:18 [1613] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Quorum retained | membership=1172 members=1
Jun 22 08:16:18 [1613] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_reap_unseen_nodes
Jun 22 08:16:19 [1619] vmi243500       crmd:     info: pcmk_quorum_notification:	Quorum retained | membership=1172 members=1
Jun 22 08:16:19 [1619] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node vmi243493 state is now lost | nodeid=96317541 previous=member source=crm_reap_unseen_nodes
Jun 22 08:16:19 [1619] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243493 is now lost (was member)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/112)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/115)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/116)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/112, version=1.589.54)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/115, version=1.589.54)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.54 2
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.55 (null)
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=55
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=post_cache_update
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @in_ccm=false, @crm-debug-origin=post_cache_update
Jun 22 08:16:19 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/116, version=1.589.55)
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: unpack_status:	Node vmi243493 is in maintenance-mode
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (3600s) for stonith-sbd on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ERS on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ERS10 on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_CPU on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_NIC on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (60s) for dlm_DEV:0 on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_sapmnt:0 on vmi243500
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      stonith-sbd            ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_database        ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ERS            ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ERS10          ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )  
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:16:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:16:20 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 3, saving inputs in /var/lib/pacemaker/pengine/pe-input-580.bz2
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 3 (ref=pe_calc-dc-1592806580-49) derived from /var/lib/pacemaker/pengine/pe-input-580.bz2
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation stonith-sbd_start_0 locally on vmi243500 | action 2
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=2:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=stonith-sbd_start_0
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/118)
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_database_start_0 locally on vmi243500 | action 4
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:stonith-sbd action:start call_id:76
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=4:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_database_start_0
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/119)
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:start call_id:77
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_ERS_start_0 locally on vmi243500 | action 38
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.55 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.56 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=56
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_update_resource
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @operation_key=stonith-sbd_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=2:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;2:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592806580, @last-
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=38:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ERS_start_0
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/118, version=1.589.56)
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_ERS action:start call_id:78
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.56
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.56 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.57 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=57
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=4:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;4:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=159280
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/119, version=1.589.57)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/120)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.57 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.58 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=58
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @operation_key=vip_DEV_ERS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=38:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;38:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592806580, @las
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/120, version=1.589.58)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation global_rsc_DEV_CPU_start_0 locally on vmi243500 | action 46
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=46:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_start_0
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:start call_id:79
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation global_rsc_DEV_NIC_start_0 locally on vmi243500 | action 48
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=48:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_start_0
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/121)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/122)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.58 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.59 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=59
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=46:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;46:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:start call_id:80
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/121, version=1.589.59)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.59 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.60 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=60
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=48:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;48:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/122, version=1.589.60)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.57
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.58
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.59
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:start call_id:79 pid:5304 exit-code:0 exec-time:40ms queue-time:1ms
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=79 key=global_rsc_DEV_CPU_start_0 confirmed=true cib-update=123
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/123)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.60
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.60 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.61 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=61
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;46:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=79, @rc-code=0, @op-status=0, @exec-time=40, @queue-time=1
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_start_0 (46) confirmed on vmi243500 (rc=0)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_CPU_monitor_10000 locally on vmi243500 | action 47
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.61
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=47:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_monitor_10000
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/123, version=1.589.61)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/124)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.61 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.62 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=62
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']:  <lrm_rsc_op id="global_rsc_DEV_CPU_monitor_10000" operation_key="global_rsc_DEV_CPU_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="47:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;47:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reas
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/124, version=1.589.62)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_CPU']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.62
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_ERS action:start call_id:78 pid:5303 exit-code:0 exec-time:144ms queue-time:0ms
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_ERS on vmi243500: 0 (ok) | call=78 key=vip_DEV_ERS_start_0 confirmed=true cib-update=125
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/125)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.62 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.63 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=63
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:0;38:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=78, @rc-code=0, @op-status=0, @exec-time=144
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/125, version=1.589.63)
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ERS_start_0 (38) confirmed on vmi243500 (rc=0)
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_ERS_monitor_10000 locally on vmi243500 | action 39
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=39:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ERS_monitor_10000
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.63
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/126)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.63 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.64 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=64
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']:  <lrm_rsc_op id="vip_DEV_ERS_monitor_10000" operation_key="vip_DEV_ERS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="39:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;39:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/126, version=1.589.64)
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_ERS10_start_0 locally on vmi243500 | action 40
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=40:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ERS10_start_0
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/127)
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ERS10 action:start call_id:83
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ERS']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.64
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.64 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.65 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=65
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @operation_key=rsc_DEV_ERS10_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=40:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;40:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592806580
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/127, version=1.589.65)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.65
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_ERS on vmi243500: 0 (ok) | call=82 key=vip_DEV_ERS_monitor_10000 confirmed=false cib-update=128
Jun 22 08:16:20 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: (null) -> 1 from vmi243500
Jun 22 08:16:20 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 4 with 1 changes for ethmonitor-eth0, id=<n/a>, set=(null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/128)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/4)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.65 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.66 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=66
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']:  @transition-magic=0:0;39:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=82, @rc-code=0, @op-status=0, @exec-time=73
Jun 22 08:16:20 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:start call_id:80 pid:5305 exit-code:0 exec-time:218ms queue-time:0ms
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ERS_monitor_10000 (39) confirmed on vmi243500 (rc=0)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.66
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=80 key=global_rsc_DEV_NIC_start_0 confirmed=true cib-update=129
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/128, version=1.589.66)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.66 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.67 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=67
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <transient_attributes id="771304931"/>
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             <instance_attributes id="status-771304931">
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++                                               <nvpair id="status-771304931-ethmonitor-eth0" name="ethmonitor-eth0" value="1"/>
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++                                             </instance_attributes>
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	++                                           </transient_attributes>
Jun 22 08:16:20 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 3 aborted by transient_attributes.771304931 'create': Transient attribute change | cib=1.589.67 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931'] complete=false
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/4, version=1.589.67)
Jun 22 08:16:20 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for ethmonitor-eth0: OK (0)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/129)
Jun 22 08:16:20 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 4 for ethmonitor-eth0[vmi243500]=1: OK (0)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.67 2
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.68 (null)
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=68
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;48:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=80, @rc-code=0, @op-status=0, @exec-time=218
Jun 22 08:16:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_start_0 (48) confirmed on vmi243500 (rc=0)
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.68
Jun 22 08:16:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/129, version=1.589.68)
Jun 22 08:16:21 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:21 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:21 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:22 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:22 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:22 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:stonith-sbd action:start call_id:76  exit-code:0 exec-time:2332ms queue-time:1ms
Jun 22 08:16:22 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for stonith-sbd on vmi243500: 0 (ok) | call=76 key=stonith-sbd_start_0 confirmed=true cib-update=130
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/130)
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.68 2
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.69 (null)
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=69
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:0;2:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=76, @rc-code=0, @op-status=0, @exec-time=2332, @queue-time=1
Jun 22 08:16:22 [1619] vmi243500       crmd:     info: match_graph_event:	Action stonith-sbd_start_0 (2) confirmed on vmi243500 (rc=0)
Jun 22 08:16:22 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Jun 22 08:16:22 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.69
Jun 22 08:16:22 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/130, version=1.589.69)
Jun 22 08:16:22 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:23 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: (null) -> green from vmi243500
Jun 22 08:16:23 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=81 key=global_rsc_DEV_CPU_monitor_10000 confirmed=false cib-update=131
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/131)
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.69 2
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.70 (null)
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=70
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-magic=0:0;47:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=81, @rc-code=0, @op-status=0, @exec-time=3244
Jun 22 08:16:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/131, version=1.589.70)
Jun 22 08:16:23 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Jun 22 08:16:23 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.70
Jun 22 08:16:23 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:23 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_monitor_10000 (47) confirmed on vmi243500 (rc=0)
Jun 22 08:16:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:26 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:26 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:28 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: cd9472b57e85163339d8b1cbdb2e4b2d for 1.589.70 (0x55a42ff553b0 0)
Jun 22 08:16:31 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting runs_ers_DEV[vmi243500]: (null) -> 1 from vmi243500
Jun 22 08:16:31 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 5 with 1 changes for runs_ers_DEV, id=<n/a>, set=(null)
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/5)
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.70 2
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.71 (null)
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=71
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-runs_ers_DEV" name="runs_ers_DEV" value="1"/>
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/5, version=1.589.71)
Jun 22 08:16:31 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 3 aborted by status-771304931-runs_ers_DEV doing create runs_ers_DEV=1: Transient attribute change | cib=1.589.71 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=false
Jun 22 08:16:31 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ERS10 action:start call_id:83 pid:5488 exit-code:0 exec-time:10222ms queue-time:1ms
Jun 22 08:16:31 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_ERS10 on vmi243500: 0 (ok) | call=83 key=rsc_DEV_ERS10_start_0 confirmed=true cib-update=132
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/132)
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.71 2
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.72 (null)
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=72
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:0;40:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=83, @rc-code=0, @op-status=0, @exec-time=10222, @queue-time=1
Jun 22 08:16:31 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/132, version=1.589.72)
Jun 22 08:16:31 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ERS10_start_0 (40) confirmed on vmi243500 (rc=0)
Jun 22 08:16:31 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 5 for runs_ers_DEV: OK (0)
Jun 22 08:16:31 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 5 for runs_ers_DEV[vmi243500]=1: OK (0)
Jun 22 08:16:31 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Jun 22 08:16:31 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.72
Jun 22 08:16:31 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:31 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:31 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:32 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:32 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:32 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:33 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:36 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 3b8249d475b843074b23e936366b3331 for 1.589.72 (0x55a42ff553b0 0)
Jun 22 08:16:45 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:start call_id:77 pid:5302 exit-code:0 exec-time:25362ms queue-time:0ms
Jun 22 08:16:45 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_database on vmi243500: 0 (ok) | call=77 key=fs_DEV_database_start_0 confirmed=true cib-update=133
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/133)
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.72 2
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.73 (null)
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=73
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;4:3:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=77, @rc-code=0, @op-status=0, @exec-time=25362
Jun 22 08:16:45 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/133, version=1.589.73)
Jun 22 08:16:45 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_start_0 (4) confirmed on vmi243500 (rc=0)
Jun 22 08:16:45 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Jun 22 08:16:45 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.73
Jun 22 08:16:45 [1619] vmi243500       crmd:   notice: run_graph:	Transition 3 (Complete=11, Pending=0, Fired=0, Skipped=5, Incomplete=37, Source=/var/lib/pacemaker/pengine/pe-input-580.bz2): Stopped
Jun 22 08:16:45 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: unpack_status:	Node vmi243493 is in maintenance-mode
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (3600s) for stonith-sbd on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_database on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_database on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ERS10 on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_NIC on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (60s) for dlm_DEV:0 on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_sapmnt:0 on vmi243500
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_database       ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_database       ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )  
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:16:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:16:46 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 4, saving inputs in /var/lib/pacemaker/pengine/pe-input-581.bz2
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 4 (ref=pe_calc-dc-1592806606-58) derived from /var/lib/pacemaker/pengine/pe-input-581.bz2
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation stonith-sbd_monitor_3600000 locally on vmi243500 | action 6
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=6:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=stonith-sbd_monitor_3600000
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/135)
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_database_monitor_20000 locally on vmi243500 | action 9
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_database_monitor_20000
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_database_start_0 locally on vmi243500 | action 10
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.73 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.74 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=74
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_database_start_0
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']:  <lrm_rsc_op id="stonith-sbd_monitor_3600000" operation_key="stonith-sbd_monitor_3600000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;6:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/135, version=1.589.74)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/136)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/137)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.74 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.75 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=75
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']:  <lrm_rsc_op id="fs_DEV_database_monitor_20000" operation_key="fs_DEV_database_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;9:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_no
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/136, version=1.589.75)
Jun 22 08:16:46 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:start call_id:86
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ERS10_monitor_120000 locally on vmi243500 | action 46
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='stonith-sbd']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.74
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=46:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ERS10_monitor_120000
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.75 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.76 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=76
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=10:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;10:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/137, version=1.589.76)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/138)
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_NIC_monitor_10000 locally on vmi243500 | action 55
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=55:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_monitor_10000
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_database']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.75
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.76
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.76 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.77 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=77
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']:  <lrm_rsc_op id="rsc_DEV_ERS10_monitor_120000" operation_key="rsc_DEV_ERS10_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="46:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;46:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/138, version=1.589.77)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/139)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ERS10']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.77
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.77 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.78 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=78
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']:  <lrm_rsc_op id="global_rsc_DEV_NIC_monitor_10000" operation_key="global_rsc_DEV_NIC_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="55:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;55:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reas
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/139, version=1.589.78)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_NIC']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.78
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: 0 (ok) | call=85 key=fs_DEV_database_monitor_20000 confirmed=false cib-update=140
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/140)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.78 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.79 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=79
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-magic=0:0;9:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=85, @rc-code=0, @op-status=0, @exec-time=72, @queue-time=1
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_database_monitor_20000 (9) confirmed on vmi243500 (rc=0)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.79
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/140, version=1.589.79)
Jun 22 08:16:46 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:start call_id:86 pid:6041 exit-code:0 exec-time:112ms queue-time:0ms
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_database on vmi243500: 0 (ok) | call=86 key=vip_DEV_database_start_0 confirmed=true cib-update=141
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/141)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.79 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.80 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=80
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;10:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=86, @rc-code=0, @op-status=0, @exec-time=112
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/141, version=1.589.80)
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_start_0 (10) confirmed on vmi243500 (rc=0)
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_database_monitor_10000 locally on vmi243500 | action 11
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=11:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_database_monitor_10000
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/142)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.80
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.80 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.81 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=81
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_database_start_0 locally on vmi243500 | action 12
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']:  <lrm_rsc_op id="vip_DEV_database_monitor_10000" operation_key="vip_DEV_database_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;11:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" 
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=12:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_database_start_0
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/142, version=1.589.81)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/143)
Jun 22 08:16:46 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:start call_id:90
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.81 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.82 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=82
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=12:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;12:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/143, version=1.589.82)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_database']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.81
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.82
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=88 key=global_rsc_DEV_NIC_monitor_10000 confirmed=false cib-update=144
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/144)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.82 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.83 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=83
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']:  @transition-magic=0:0;55:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=88, @rc-code=0, @op-status=0, @exec-time=172
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/144, version=1.589.83)
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_monitor_10000 (55) confirmed on vmi243500 (rc=0)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.83
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ERS10 on vmi243500: 0 (ok) | call=87 key=rsc_DEV_ERS10_monitor_120000 confirmed=false cib-update=145
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/145)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.83 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.84 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=84
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']:  @transition-magic=0:0;46:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=87, @rc-code=0, @op-status=0, @exec-time=183
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/145, version=1.589.84)
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ERS10_monitor_120000 (46) confirmed on vmi243500 (rc=0)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.84
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: 0 (ok) | call=89 key=vip_DEV_database_monitor_10000 confirmed=false cib-update=146
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/146)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.84 2
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.85 (null)
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=85
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-magic=0:0;11:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=89, @rc-code=0, @op-status=0, @exec-time=72
Jun 22 08:16:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/146, version=1.589.85)
Jun 22 08:16:46 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_database_monitor_10000 (11) confirmed on vmi243500 (rc=0)
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.85
Jun 22 08:16:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:46 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:47 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for stonith-sbd on vmi243500: 0 (ok) | call=84 key=stonith-sbd_monitor_3600000 confirmed=false cib-update=147
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/147)
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.85 2
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.86 (null)
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=86
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_monitor_3600000']:  @transition-magic=0:0;6:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=84, @rc-code=0, @op-status=0, @exec-time=1514
Jun 22 08:16:47 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/147, version=1.589.86)
Jun 22 08:16:47 [1619] vmi243500       crmd:     info: match_graph_event:	Action stonith-sbd_monitor_3600000 (6) confirmed on vmi243500 (rc=0)
Jun 22 08:16:47 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_monitor_3600000']
Jun 22 08:16:47 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.589.86
Jun 22 08:16:47 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:16:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:52 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: e5da14ea0051b26f3a8d661c4881cffb for 1.589.86 (0x55a42ff553b0 0)
Jun 22 08:16:53 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 6 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/6)
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.86 2
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.87 (null)
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=87
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-.health-cpu" name="#health-cpu" value="green"/>
Jun 22 08:16:53 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 4 aborted by status-771304931-.health-cpu doing create #health-cpu=green: Transient attribute change | cib=1.589.87 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=false
Jun 22 08:16:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/6, version=1.589.87)
Jun 22 08:16:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 6 for #health-cpu: OK (0)
Jun 22 08:16:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 6 for #health-cpu[vmi243500]=green: OK (0)
Jun 22 08:16:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:56 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:16:58 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: ef672b24c13f50ff88361eed74e0f787 for 1.589.87 (0x55a42ff553b0 0)
Jun 22 08:19:02 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jun 22 08:19:32 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 7 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/7)
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.87 2
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.88 (null)
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=88
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jun 22 08:19:32 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/7, version=1.589.88)
Jun 22 08:19:32 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 4 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.589.88 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jun 22 08:19:32 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 7 for #health-cpu: OK (0)
Jun 22 08:19:32 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 7 for #health-cpu[vmi243500]=yellow: OK (0)
Jun 22 08:19:32 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:19:33 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:19:33 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:19:37 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 889566a3390cc2a82e136dde6edb5b9b for 1.589.88 (0x55a42ff553b0 0)
Jun 22 08:20:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jun 22 08:23:00 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jun 22 08:23:30 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 8 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/8)
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.88 2
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.589.89 (null)
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=89
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jun 22 08:23:30 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/8, version=1.589.89)
Jun 22 08:23:30 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 8 for #health-cpu: OK (0)
Jun 22 08:23:30 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 8 for #health-cpu[vmi243500]=green: OK (0)
Jun 22 08:23:30 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 4 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.589.89 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jun 22 08:23:31 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:23:31 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:23:31 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:23:32 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:23:35 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 1d39b94042340ad4443dbb7b41e7f368 for 1.589.89 (0x55a42ff553b0 0)
Jun 22 08:23:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jun 22 08:26:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crm_attribute/4)
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.589.89 2
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.0 c86620786642f6817ba6b3f3fc5da78e
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=590, @num_updates=0
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/nodes/node[@id='96317541']/instance_attributes[@id='nodes-96317541']/nvpair[@id='nodes-96317541-maintenance']:  @value=off
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crm_attribute/4, version=1.590.0)
Jun 22 08:26:23 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 4 aborted by nodes-96317541-maintenance doing modify maintenance=off: Configuration change | cib=1.590.0 source=te_update_diff_v2:500 path=/cib/configuration/nodes/node[@id='96317541']/instance_attributes[@id='nodes-96317541']/nvpair[@id='nodes-96317541-maintenance'] complete=false
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-26.raw
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.590.0 of the CIB to disk (digest: 378f11fda353d86ea03f73bc13f7759d)
Jun 22 08:26:23 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.Ezw3F1 (digest: /var/lib/pacemaker/cib/cib.Tz08rR)
Jun 22 08:26:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:26 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:26:28 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: c86620786642f6817ba6b3f3fc5da78e for 1.590.0 (0x55a4306d7c90 0)
Jun 22 08:29:19 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:29:22 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:20 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:start call_id:90 pid:6246 exit-code:0 exec-time:1114606ms queue-time:1ms
Jun 22 08:35:20 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_database on vmi243500: 0 (ok) | call=90 key=rsc_DEV_database_start_0 confirmed=true cib-update=148
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/148)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.0 2
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.1 (null)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;12:4:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=90, @rc-code=0, @op-status=0, @exec-time=1114606, @queue-time=1
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/148, version=1.590.1)
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_start_0 (12) confirmed on vmi243500 (rc=0)
Jun 22 08:35:20 [1619] vmi243500       crmd:   notice: run_graph:	Transition 4 (Complete=11, Pending=0, Fired=0, Skipped=2, Incomplete=27, Source=/var/lib/pacemaker/pengine/pe-input-581.bz2): Stopped
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.1
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 vmi243500 ]
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_database on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_ASCS on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_ASCS on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_ASCS00 on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_2_DEV_ASCS on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_3_DEV_ASCS on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_CI on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for vip_DEV_CI on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (60s) for dlm_DEV:0 on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (20s) for fs_DEV_sapmnt:0 on vmi243500
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_ASCS            ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_ASCS           ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_ASCS00         ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_2_DEV_ASCS          ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_3_DEV_ASCS          ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_CI              ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      vip_DEV_CI             ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      rsc_DEV_CI             ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      dlm_DEV:0              ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      fs_DEV_sapmnt:0        ( vmi243500 )  
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:35:20 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:35:20 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 5, saving inputs in /var/lib/pacemaker/pengine/pe-input-582.bz2
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:35:20 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 5 (ref=pe_calc-dc-1592807720-68) derived from /var/lib/pacemaker/pengine/pe-input-582.bz2
Jun 22 08:35:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_database_monitor_120000 locally on vmi243500 | action 17
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=17:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_database_monitor_120000
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/150)
Jun 22 08:35:20 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation dlm_DEV_start_0 locally on vmi243500 | action 58
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=58:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=dlm_DEV_start_0
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.1 2
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.2 (null)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']:  <lrm_rsc_op id="rsc_DEV_database_monitor_120000" operation_key="rsc_DEV_database_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;17:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="
Jun 22 08:35:20 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:start call_id:92
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/150, version=1.590.2)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/151)
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_database']
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.2
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.2 2
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.3 (null)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=58:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;58:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807720, @last-rc-change=
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/151, version=1.590.3)
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.3
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 0 (ok) | call=91 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=152
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/152)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.3 2
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.4 (null)
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-magic=0:0;17:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=91, @rc-code=0, @op-status=0, @exec-time=76
Jun 22 08:35:20 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/152, version=1.590.4)
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.4
Jun 22 08:35:20 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:20 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_database_monitor_120000 (17) confirmed on vmi243500 (rc=0)
Jun 22 08:35:21 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:21 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:22 [1616] vmi243500       lrmd:   notice: operation_finished:	dlm_DEV_start_0:26470:stderr [ mount: /sys/kernel/config: none already mounted or mount point busy. ]
Jun 22 08:35:22 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:start call_id:92 pid:26470 exit-code:0 exec-time:1162ms queue-time:0ms
Jun 22 08:35:22 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for dlm_DEV on vmi243500: 0 (ok) | call=92 key=dlm_DEV_start_0 confirmed=true cib-update=153
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/153)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.4 2
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.5 (null)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;58:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=92, @rc-code=0, @op-status=0, @exec-time=1162
Jun 22 08:35:22 [1619] vmi243500       crmd:     info: match_graph_event:	Action dlm_DEV_start_0 (58) confirmed on vmi243500 (rc=0)
Jun 22 08:35:22 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation dlm_DEV_monitor_60000 locally on vmi243500 | action 59
Jun 22 08:35:22 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=59:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=dlm_DEV_monitor_60000
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.5
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:22 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_sapmnt_start_0 locally on vmi243500 | action 60
Jun 22 08:35:22 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=60:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_sapmnt_start_0
Jun 22 08:35:22 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:start call_id:94
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/153, version=1.590.5)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/154)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/155)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.5 2
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.6 (null)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']:  <lrm_rsc_op id="dlm_DEV_monitor_60000" operation_key="dlm_DEV_monitor_60000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="59:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;59:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/154, version=1.590.6)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.6 2
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.7 (null)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=60:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;60:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807722
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='dlm_DEV']
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.6
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/155, version=1.590.7)
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.7
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:22 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: 0 (ok) | call=93 key=dlm_DEV_monitor_60000 confirmed=false cib-update=156
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/156)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.7 2
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.8 (null)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;59:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=93, @rc-code=0, @op-status=0, @exec-time=43
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.8
Jun 22 08:35:22 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:22 [1619] vmi243500       crmd:     info: match_graph_event:	Action dlm_DEV_monitor_60000 (59) confirmed on vmi243500 (rc=0)
Jun 22 08:35:22 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/156, version=1.590.8)
Jun 22 08:35:22 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:22 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:23 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:start call_id:94 pid:26572 exit-code:0 exec-time:1359ms queue-time:0ms
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=94 key=fs_DEV_sapmnt_start_0 confirmed=true cib-update=157
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/157)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.8 2
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.9 (null)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;60:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=94, @rc-code=0, @op-status=0, @exec-time=1359
Jun 22 08:35:23 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_sapmnt_start_0 (60) confirmed on vmi243500 (rc=0)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/157, version=1.590.9)
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_sapmnt_monitor_20000 locally on vmi243500 | action 61
Jun 22 08:35:23 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=61:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_sapmnt_monitor_20000
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.9
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/158)
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_ASCS_start_0 locally on vmi243500 | action 22
Jun 22 08:35:23 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_ASCS_start_0
Jun 22 08:35:23 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_ASCS action:start call_id:96
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.9 2
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.10 (null)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']:  <lrm_rsc_op id="fs_DEV_sapmnt_monitor_20000" operation_key="fs_DEV_sapmnt_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="61:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;61:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/158, version=1.590.10)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/159)
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_sapmnt']
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.10
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.10 2
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.11 (null)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @operation_key=fs_DEV_ASCS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=22:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;22:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807723, @las
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/159, version=1.590.11)
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.11
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:23 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=95 key=fs_DEV_sapmnt_monitor_20000 confirmed=false cib-update=160
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/160)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.11 2
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.12 (null)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;61:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=95, @rc-code=0, @op-status=0, @exec-time=53
Jun 22 08:35:23 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_sapmnt_monitor_20000 (61) confirmed on vmi243500 (rc=0)
Jun 22 08:35:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/160, version=1.590.12)
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.12
Jun 22 08:35:23 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:24 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_ASCS action:start call_id:96 pid:26752 exit-code:0 exec-time:1548ms queue-time:0ms
Jun 22 08:35:24 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=96 key=fs_DEV_ASCS_start_0 confirmed=true cib-update=161
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/161)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.12 2
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.13 (null)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:0;22:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=96, @rc-code=0, @op-status=0, @exec-time=1548
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/161, version=1.590.13)
Jun 22 08:35:24 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_start_0 (22) confirmed on vmi243500 (rc=0)
Jun 22 08:35:24 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_ASCS_monitor_20000 locally on vmi243500 | action 23
Jun 22 08:35:24 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_ASCS_monitor_20000
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.13
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:24 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_ASCS_start_0 locally on vmi243500 | action 24
Jun 22 08:35:24 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=24:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ASCS_start_0
Jun 22 08:35:24 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_ASCS action:start call_id:98
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/162)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/163)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.13 2
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.14 (null)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']:  <lrm_rsc_op id="fs_DEV_ASCS_monitor_20000" operation_key="fs_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="23:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;23:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/162, version=1.590.14)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.14 2
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.15 (null)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @operation_key=vip_DEV_ASCS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=24:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;24:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807724, @
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/163, version=1.590.15)
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_ASCS']
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.14
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.15
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:24 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=97 key=fs_DEV_ASCS_monitor_20000 confirmed=false cib-update=164
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/164)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.15 2
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.16 (null)
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;23:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=97, @rc-code=0, @op-status=0, @exec-time=64
Jun 22 08:35:24 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/164, version=1.590.16)
Jun 22 08:35:24 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_ASCS_monitor_20000 (23) confirmed on vmi243500 (rc=0)
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.16
Jun 22 08:35:24 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:25 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_ASCS action:start call_id:98 pid:26900 exit-code:0 exec-time:124ms queue-time:0ms
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=98 key=vip_DEV_ASCS_start_0 confirmed=true cib-update=165
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/165)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.16 2
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.17 (null)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:0;24:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=98, @rc-code=0, @op-status=0, @exec-time=124
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/165, version=1.590.17)
Jun 22 08:35:25 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_start_0 (24) confirmed on vmi243500 (rc=0)
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_ASCS_monitor_10000 locally on vmi243500 | action 25
Jun 22 08:35:25 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=25:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_ASCS_monitor_10000
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.17
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/166)
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_ASCS00_start_0 locally on vmi243500 | action 26
Jun 22 08:35:25 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ASCS00_start_0
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.17 2
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.18 (null)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']:  <lrm_rsc_op id="vip_DEV_ASCS_monitor_10000" operation_key="vip_DEV_ASCS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="25:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;25:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi
Jun 22 08:35:25 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:start call_id:100
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/166, version=1.590.18)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/167)
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ASCS']
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.18
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.18 2
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.19 (null)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=26:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;26:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/167, version=1.590.19)
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.19
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:25 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=99 key=vip_DEV_ASCS_monitor_10000 confirmed=false cib-update=168
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/168)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.19 2
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.20 (null)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']:  @transition-magic=0:0;25:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=99, @rc-code=0, @op-status=0, @exec-time=60
Jun 22 08:35:25 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_ASCS_monitor_10000 (25) confirmed on vmi243500 (rc=0)
Jun 22 08:35:25 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/168, version=1.590.20)
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.20
Jun 22 08:35:25 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:26 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:26 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:27 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:27 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:30 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: e87a2ca4b734ee941533cabf2c6f54bd for 1.590.20 (0x55a4306d7c90 0)
Jun 22 08:35:52 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:start call_id:100 pid:27015 exit-code:0 exec-time:27707ms queue-time:0ms
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=100 key=rsc_DEV_ASCS00_start_0 confirmed=true cib-update=169
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/169)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.20 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.21 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;26:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=100, @rc-code=0, @op-status=0, @exec-time=27707
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/169, version=1.590.21)
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_start_0 (26) confirmed on vmi243500 (rc=0)
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation rsc_DEV_ASCS00_monitor_120000 locally on vmi243500 | action 27
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=27:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_ASCS00_monitor_120000
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.21
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_2_DEV_ASCS_start_0 locally on vmi243500 | action 28
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=28:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_2_DEV_ASCS_start_0
Jun 22 08:35:52 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:start call_id:102
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/170)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/171)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.21 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.22 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']:  <lrm_rsc_op id="rsc_DEV_ASCS00_monitor_120000" operation_key="rsc_DEV_ASCS00_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="27:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;27:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_n
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/170, version=1.590.22)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.22 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.23 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=28:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;28:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807752
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ASCS00']
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.22
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/171, version=1.590.23)
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.23
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=101 key=rsc_DEV_ASCS00_monitor_120000 confirmed=false cib-update=172
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/172)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.23 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.24 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-magic=0:0;27:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=101, @rc-code=0, @op-status=0, @exec-time=210
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/172, version=1.590.24)
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_ASCS00_monitor_120000 (27) confirmed on vmi243500 (rc=0)
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.24
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:52 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:start call_id:102 pid:28343 exit-code:0 exec-time:224ms queue-time:0ms
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=102 key=fs_2_DEV_ASCS_start_0 confirmed=true cib-update=173
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/173)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.24 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.25 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;28:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=102, @rc-code=0, @op-status=0, @exec-time=224
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/173, version=1.590.25)
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_start_0 (28) confirmed on vmi243500 (rc=0)
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_2_DEV_ASCS_monitor_20000 locally on vmi243500 | action 29
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=29:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_2_DEV_ASCS_monitor_20000
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/174)
Jun 22 08:35:52 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_3_DEV_ASCS_start_0 locally on vmi243500 | action 30
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.25 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.26 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Jun 22 08:35:52 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=30:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_3_DEV_ASCS_start_0
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']:  <lrm_rsc_op id="fs_2_DEV_ASCS_monitor_20000" operation_key="fs_2_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="29:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;29:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/174, version=1.590.26)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/175)
Jun 22 08:35:52 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:start call_id:104
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.25
Jun 22 08:35:52 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.26 2
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.27 (null)
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=30:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;30:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807752
Jun 22 08:35:52 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/175, version=1.590.27)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_2_DEV_ASCS']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.26
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.27
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=103 key=fs_2_DEV_ASCS_monitor_20000 confirmed=false cib-update=176
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/176)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.27 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.28 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;29:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=103, @rc-code=0, @op-status=0, @exec-time=61
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/176, version=1.590.28)
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_2_DEV_ASCS_monitor_20000 (29) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.28
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:start call_id:104 pid:28535 exit-code:0 exec-time:149ms queue-time:0ms
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=104 key=fs_3_DEV_ASCS_start_0 confirmed=true cib-update=177
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/177)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.28 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.29 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;30:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=104, @rc-code=0, @op-status=0, @exec-time=149
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_start_0 (30) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/177, version=1.590.29)
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_3_DEV_ASCS_monitor_20000 locally on vmi243500 | action 31
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=31:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_3_DEV_ASCS_monitor_20000
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.29
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/178)
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation fs_DEV_CI_start_0 locally on vmi243500 | action 36
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=36:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_CI_start_0
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.29 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.30 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']:  <lrm_rsc_op id="fs_3_DEV_ASCS_monitor_20000" operation_key="fs_3_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="31:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;31:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:start call_id:106
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/178, version=1.590.30)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/179)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_3_DEV_ASCS']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.30
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.30 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.31 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=36:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;36:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807753, @last-rc-c
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/179, version=1.590.31)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.31
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=105 key=fs_3_DEV_ASCS_monitor_20000 confirmed=false cib-update=180
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/180)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.31 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.32 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;31:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=105, @rc-code=0, @op-status=0, @exec-time=59
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/180, version=1.590.32)
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_3_DEV_ASCS_monitor_20000 (31) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.32
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:start call_id:106 pid:28639 exit-code:0 exec-time:348ms queue-time:0ms
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_CI on vmi243500: 0 (ok) | call=106 key=fs_DEV_CI_start_0 confirmed=true cib-update=181
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/181)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.32 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.33 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;36:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=106, @rc-code=0, @op-status=0, @exec-time=348
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/181, version=1.590.33)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.33
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_start_0 (36) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation fs_DEV_CI_monitor_20000 locally on vmi243500 | action 37
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=37:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=fs_DEV_CI_monitor_20000
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation vip_DEV_CI_start_0 locally on vmi243500 | action 38
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=38:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_CI_start_0
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/182)
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:start call_id:108
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/183)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.33 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.34 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']:  <lrm_rsc_op id="fs_DEV_CI_monitor_20000" operation_key="fs_DEV_CI_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="37:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;37:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" c
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/182, version=1.590.34)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.34 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.35 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=38:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;38:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807753, @last-r
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/183, version=1.590.35)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_CI']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.34
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.35
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: 0 (ok) | call=107 key=fs_DEV_CI_monitor_20000 confirmed=false cib-update=184
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/184)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.35 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.36 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;37:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=107, @rc-code=0, @op-status=0, @exec-time=56
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action fs_DEV_CI_monitor_20000 (37) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/184, version=1.590.36)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.36
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:start call_id:108 pid:28796 exit-code:0 exec-time:96ms queue-time:0ms
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_CI on vmi243500: 0 (ok) | call=108 key=vip_DEV_CI_start_0 confirmed=true cib-update=185
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/185)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.36 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.37 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;38:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=108, @rc-code=0, @op-status=0, @exec-time=96
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/185, version=1.590.37)
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_start_0 (38) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation vip_DEV_CI_monitor_10000 locally on vmi243500 | action 39
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=39:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=vip_DEV_CI_monitor_10000
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/186)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.37
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation rsc_DEV_CI_start_0 locally on vmi243500 | action 40
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_CI_start_0
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.37 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.38 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']:  <lrm_rsc_op id="vip_DEV_CI_monitor_10000" operation_key="vip_DEV_CI_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="39:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="-1:193;39:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500
Jun 22 08:35:53 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:110
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/186, version=1.590.38)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/187)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_CI']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.38
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.38 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.39 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807753, @last-r
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/187, version=1.590.39)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.39
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: 0 (ok) | call=109 key=vip_DEV_CI_monitor_10000 confirmed=false cib-update=188
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/188)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.39 2
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.40 (null)
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=40
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;39:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=109, @rc-code=0, @op-status=0, @exec-time=58
Jun 22 08:35:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/188, version=1.590.40)
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.40
Jun 22 08:35:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:35:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action vip_DEV_CI_monitor_10000 (39) confirmed on vmi243500 (rc=0)
Jun 22 08:35:53 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:35:58 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: 57fbba49375cf931dd7fdb378fd88021 for 1.590.40 (0x55a4306d7c90 0)
Jun 22 08:36:27 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jun 22 08:36:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0000)
Jun 22 08:36:57 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 9 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/9)
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.40 2
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.41 (null)
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=41
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=yellow
Jun 22 08:36:57 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 5 aborted by status-771304931-.health-cpu doing modify #health-cpu=yellow: Transient attribute change | cib=1.590.41 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jun 22 08:36:57 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/9, version=1.590.41)
Jun 22 08:36:57 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 9 for #health-cpu: OK (0)
Jun 22 08:36:57 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 9 for #health-cpu[vmi243500]=yellow: OK (0)
Jun 22 08:36:57 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:36:58 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:36:58 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:36:59 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:36:59 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:37:02 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: facaecac17a64d770d093758203bfb22 for 1.590.41 (0x55a4306d7c90 0)
Jun 22 08:37:33 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jun 22 08:37:39 [1619] vmi243500       crmd:   notice: throttle_check_thresholds:	High CPU load detected: 14.480000
Jun 22 08:37:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0100 (was 0001)
Jun 22 08:37:47 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Jun 22 08:38:09 [1619] vmi243500       crmd:   notice: throttle_check_thresholds:	High CPU load detected: 16.650000
Jun 22 08:38:17 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 10 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:38:17 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/10)
Jun 22 08:38:17 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/10, version=1.590.41)
Jun 22 08:38:17 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 10 for #health-cpu: OK (0)
Jun 22 08:38:17 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 10 for #health-cpu[vmi243500]=yellow: OK (0)
Jun 22 08:38:22 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: facaecac17a64d770d093758203bfb22 for 1.590.41 (0x55a4306d7c90 0)
Jun 22 08:38:39 [1619] vmi243500       crmd:   notice: throttle_check_thresholds:	High CPU load detected: 17.150000
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Jun 22 08:38:53 [1616] vmi243500       lrmd:  warning: child_timeout_callback:	rsc_DEV_CI_start_0 process (PID 28906) timed out
Jun 22 08:38:53 [1616] vmi243500       lrmd:  warning: operation_finished:	rsc_DEV_CI_start_0:28906 - timed out after 180000ms
Jun 22 08:38:53 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:110 pid:28906 exit-code:1 exec-time:180002ms queue-time:0ms
Jun 22 08:38:53 [1619] vmi243500       crmd:    error: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: Timed Out | call=110 key=rsc_DEV_CI_start_0 timeout=180000ms
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/189)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.41 2
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.42 (null)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=42
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=2:1;40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=110, @rc-code=1, @op-status=2, @exec-time=180002
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" transition-magic="2:1;40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7" exit-reason="" on_node="vmi243500" call-id=
Jun 22 08:38:53 [1619] vmi243500       crmd:  warning: status_from_rc:	Action 40 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 5 aborted by operation rsc_DEV_CI_start_0 'modify' on vmi243500: Event failed | magic=2:1;40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.590.42 source=match_graph_event:299 complete=false
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (40) confirmed on vmi243500 (rc=1)
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1592807933)
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: update_attrd_helper:	Connecting to attribute manager ... 5 retries remaining
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/189, version=1.590.42)
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.42
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (5.40) rsc_DEV_CI_start_0.110=unknown error: failed
Jun 22 08:38:53 [1619] vmi243500       crmd:  warning: status_from_rc:	Action 40 (rsc_DEV_CI_start_0) on vmi243500 failed (target: 0 vs. rc: 1): Error
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 5 aborted by operation rsc_DEV_CI_start_0 'create' on vmi243500: Event failed | magic=2:1;40:5:0:b58f891c-6e09-4d3a-be21-ca68613900d7 cib=1.590.42 source=match_graph_event:299 complete=false
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_start_0 (40) confirmed on vmi243500 (rc=1)
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: update_failcount:	Updating failcount for rsc_DEV_CI on vmi243500 after failed start: rc=1 (update=INFINITY, time=1592807933)
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: process_graph_event:	Detected action (5.40) rsc_DEV_CI_start_0.110=unknown error: failed
Jun 22 08:38:53 [1619] vmi243500       crmd:   notice: run_graph:	Transition 5 (Complete=27, Pending=0, Fired=0, Skipped=0, Incomplete=2, Source=/var/lib/pacemaker/pengine/pe-input-582.bz2): Complete
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: (null) -> INFINITY from vmi243500
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 11 with 1 changes for fail-count-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: (null) -> 1592807933 from vmi243500
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 12 with 1 changes for last-failure-rsc_DEV_CI#start_0, id=<n/a>, set=(null)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/11)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/12)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.42 2
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.43 (null)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=43
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/11, version=1.590.43)
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 11 for fail-count-rsc_DEV_CI#start_0: OK (0)
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 11 for fail-count-rsc_DEV_CI#start_0[vmi243500]=INFINITY: OK (0)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.43 2
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.44 (null)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1592807933"/>
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/12, version=1.590.44)
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 12 for last-failure-rsc_DEV_CI#start_0: OK (0)
Jun 22 08:38:53 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 12 for last-failure-rsc_DEV_CI#start_0[vmi243500]=1592807933: OK (0)
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 5 aborted by status-771304931-fail-count-rsc_DEV_CI.start_0 doing create fail-count-rsc_DEV_CI#start_0=INFINITY: Transient attribute change | cib=1.590.43 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 5 aborted by status-771304931-last-failure-rsc_DEV_CI.start_0 doing create last-failure-rsc_DEV_CI#start_0=1592807933: Transient attribute change | cib=1.590.44 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=true
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:38:53 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:38:53 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (120s) for rsc_DEV_CI on vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: LogAction:	 * Recover    rsc_DEV_CI             ( vmi243500 )  
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 6, saving inputs in /var/lib/pacemaker/pengine/pe-input-583.bz2
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: handle_response:	pe_calc calculation pe_calc-dc-1592807933-91 is obsolete
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:38:53 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:38:53 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	FAILED vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 08:38:53 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: LogAction:	 * Stop       rsc_DEV_CI             ( vmi243500 )   due to node availability
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:38:53 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:38:53 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 7, saving inputs in /var/lib/pacemaker/pengine/pe-input-584.bz2
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:38:53 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 7 (ref=pe_calc-dc-1592807933-92) derived from /var/lib/pacemaker/pengine/pe-input-584.bz2
Jun 22 08:38:53 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation rsc_DEV_CI_stop_0 locally on vmi243500 | action 6
Jun 22 08:38:53 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=6:7:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=rsc_DEV_CI_stop_0
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/193)
Jun 22 08:38:53 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:stop call_id:111
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.44 2
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.45 (null)
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=6:7:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;6:7:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592807933, @last-rc-change=1592807933, @exec-time=0
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.45
Jun 22 08:38:53 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:38:53 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/193, version=1.590.45)
Jun 22 08:38:53 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:38:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:38:54 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:38:55 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:38:58 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: e6d27f0b1f907c1a5907e000bdfe136d for 1.590.45 (0x55a4306d7c90 0)
Jun 22 08:39:09 [1619] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 11.360000
Jun 22 08:39:09 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0010 (was 0100)
Jun 22 08:39:23 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 13 with 1 changes for #health-cpu, id=<n/a>, set=(null)
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/13)
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.45 2
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.46 (null)
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu']:  @value=green
Jun 22 08:39:23 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/13, version=1.590.46)
Jun 22 08:39:23 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 7 aborted by status-771304931-.health-cpu doing modify #health-cpu=green: Transient attribute change | cib=1.590.46 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-.health-cpu'] complete=false
Jun 22 08:39:23 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 13 for #health-cpu: OK (0)
Jun 22 08:39:23 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 13 for #health-cpu[vmi243500]=green: OK (0)
Jun 22 08:39:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:39:23 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:39:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:39:24 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:39:25 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 08:39:28 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: fbde3eee66e5113a80e5b68d8f4eaca8 for 1.590.46 (0x55a4306d7c90 0)
Jun 22 08:39:33 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:stop call_id:111 pid:4422 exit-code:0 exec-time:40330ms queue-time:0ms
Jun 22 08:39:33 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=111 key=rsc_DEV_CI_stop_0 confirmed=true cib-update=194
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/194)
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.46 2
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.47 (null)
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;6:7:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=111, @rc-code=0, @op-status=0, @exec-time=40330
Jun 22 08:39:33 [1619] vmi243500       crmd:     info: match_graph_event:	Action rsc_DEV_CI_stop_0 (6) confirmed on vmi243500 (rc=0)
Jun 22 08:39:33 [1619] vmi243500       crmd:   notice: run_graph:	Transition 7 (Complete=4, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-584.bz2): Complete
Jun 22 08:39:33 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:39:33 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Jun 22 08:39:33 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.590.47
Jun 22 08:39:33 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:39:33 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/194, version=1.590.47)
Jun 22 08:39:33 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:39:34 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 08:39:34 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:39:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:39:34 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 8, saving inputs in /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 08:39:34 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:39:34 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 8 (ref=pe_calc-dc-1592807973-95) derived from /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 08:39:34 [1619] vmi243500       crmd:   notice: run_graph:	Transition 8 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-585.bz2): Complete
Jun 22 08:39:34 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 08:39:34 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 08:39:34 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:39:34 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:39:35 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:39:35 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:39:36 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 08:39:38 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: facfdffb19b1f3f29597c47603176498 for 1.590.47 (0x55a4306d7c90 0)
Jun 22 08:39:39 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0010)
Jun 22 08:40:09 [1619] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Jun 22 08:54:34 [1619] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 08:54:34 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 08:54:34 [1619] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 08:54:34 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 08:54:34 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 08:54:34 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 08:54:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 08:54:34 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 9, saving inputs in /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 08:54:34 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 08:54:34 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 9 (ref=pe_calc-dc-1592808874-98) derived from /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 08:54:34 [1619] vmi243500       crmd:   notice: run_graph:	Transition 9 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-585.bz2): Complete
Jun 22 08:54:34 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 08:54:34 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:09:34 [1619] vmi243500       crmd:     info: crm_timer_popped:	PEngine Recheck Timer (I_PE_CALC) just popped (900000ms)
Jun 22 09:09:34 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped
Jun 22 09:09:34 [1619] vmi243500       crmd:     info: do_state_transition:	Progressed to state S_POLICY_ENGINE after C_TIMER_POPPED
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: process_pe_message:	Input has not changed since last time, not saving to disk
Jun 22 09:09:34 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:09:34 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:09:34 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:09:34 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:09:34 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 10, saving inputs in /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 09:09:34 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:09:34 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 10 (ref=pe_calc-dc-1592809774-99) derived from /var/lib/pacemaker/pengine/pe-input-585.bz2
Jun 22 09:09:34 [1619] vmi243500       crmd:   notice: run_graph:	Transition 10 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-585.bz2): Complete
Jun 22 09:09:34 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:09:34 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:21:40 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:41 [1615] vmi243500 stonith-ng:   notice: handle_request:	Received manual confirmation that vmi243493 is fenced
Jun 22 09:21:41 [1615] vmi243500 stonith-ng:   notice: initiate_remote_stonith_op:	Initiating manual confirmation for vmi243493: bc11bd59-dcb2-4a43-8c08-eae8611d130f
Jun 22 09:21:41 [1615] vmi243500 stonith-ng:   notice: stonith_manual_ack:	Injecting manual confirmation that vmi243493 is safely off/down
Jun 22 09:21:41 [1615] vmi243500 stonith-ng:   notice: remote_op_done:	Operation off of vmi243493 by a human for stonith_admin.6121@vmi243500.bc11bd59: OK
Jun 22 09:21:41 [1619] vmi243500       crmd:   notice: tengine_stonith_notify:	Peer vmi243493 was terminated (off) by a human on behalf of stonith_admin.6121: OK | initiator=vmi243500 ref=bc11bd59-dcb2-4a43-8c08-eae8611d130f
Jun 22 09:21:41 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting lrm status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/lrm
Jun 22 09:21:41 [1619] vmi243500       crmd:     info: erase_status_tag:	Deleting transient_attributes status entries for vmi243493 | xpath=//node_state[@uname='vmi243493']/transient_attributes
Jun 22 09:21:41 [1619] vmi243500       crmd:     info: tengine_stonith_notify:	External fencing operation from stonith_admin.6121 fenced vmi243493
Jun 22 09:21:41 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 10 aborted: External Fencing Operation | source=tengine_stonith_notify:310 complete=true
Jun 22 09:21:41 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/198)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/lrm to all (origin=local/crmd/199)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes to all (origin=local/crmd/200)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.47 2
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.590.48 (null)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=48
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=send_stonith_update
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/198, version=1.590.48)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243500/crmd/199, version=1.590.48)
Jun 22 09:21:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/transient_attributes: OK (rc=0, origin=vmi243500/crmd/200, version=1.590.48)
Jun 22 09:21:42 [1619] vmi243500       crmd:     info: cib_fencing_updated:	Fencing update 198 for vmi243493: complete
Jun 22 09:21:42 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_POLICY_ENGINE
Jun 22 09:21:42 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:21:42 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:21:42 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:21:42 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:21:42 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:21:42 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 11 (ref=pe_calc-dc-1592810502-100) derived from /var/lib/pacemaker/pengine/pe-input-586.bz2
Jun 22 09:21:42 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 11, saving inputs in /var/lib/pacemaker/pengine/pe-input-586.bz2
Jun 22 09:21:42 [1619] vmi243500       crmd:   notice: run_graph:	Transition 11 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-586.bz2): Complete
Jun 22 09:21:42 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:21:42 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:21:42 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:43 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:43 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:43 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:44 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:46 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: d42a68e54ad990fdf7662a2cd53ef53e for 1.590.48 (0x55a43032c670 0)
Jun 22 09:21:56 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.590.48 2
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.591.0 (null)
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=591, @num_updates=0
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/primitive[@id='global_rsc_DEV_CPU']/meta_attributes[@id='global_rsc_DEV_CPU-meta_attributes']/nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role']:  @value=Stopped
Jun 22 09:21:57 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 11 aborted by global_rsc_DEV_CPU-meta_attributes-target-role doing modify target-role=Stopped: Configuration change | cib=1.591.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/primitive[@id='global_rsc_DEV_CPU']/meta_attributes[@id='global_rsc_DEV_CPU-meta_attributes']/nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role'] complete=true
Jun 22 09:21:57 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.591.0)
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role']
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.591.0
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:21:57 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:21:57 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500 (disabled)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:21:57 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_CPU cannot run anywhere
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:   notice: LogAction:	 * Stop       global_rsc_DEV_CPU     ( vmi243500 )   due to node availability
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:21:57 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:21:57 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:21:57 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 12 (ref=pe_calc-dc-1592810517-101) derived from /var/lib/pacemaker/pengine/pe-input-587.bz2
Jun 22 09:21:57 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation global_rsc_DEV_CPU_stop_0 locally on vmi243500 | action 61
Jun 22 09:21:57 [1616] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation global_rsc_DEV_CPU_monitor_10000
Jun 22 09:21:57 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 12, saving inputs in /var/lib/pacemaker/pengine/pe-input-587.bz2
Jun 22 09:21:57 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=61:12:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_stop_0
Jun 22 09:21:57 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:stop call_id:113
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/204)
Jun 22 09:21:57 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: Cancelled | call=81 key=global_rsc_DEV_CPU_monitor_10000 confirmed=true
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.591.0 2
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.591.1 (null)
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_stop_0, @operation=stop, @transition-key=61:12:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;61:12:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592810517, @last-rc-change=15928
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/204, version=1.591.1)
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.591.1
Jun 22 09:21:57 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-27.raw
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.591.0 of the CIB to disk (digest: d258ed928e38bf4e7f08ef755e001058)
Jun 22 09:21:57 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.NqiYz9 (digest: /var/lib/pacemaker/cib/cib.EfjpB7)
Jun 22 09:21:58 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:21:58 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:21:59 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:21:59 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:22:00 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:22:00 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:22:01 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:stop call_id:113 pid:6909 exit-code:0 exec-time:3227ms queue-time:0ms
Jun 22 09:22:01 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=113 key=global_rsc_DEV_CPU_stop_0 confirmed=true cib-update=205
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/205)
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.591.1 2
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.591.2 (null)
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;61:12:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=113, @rc-code=0, @op-status=0, @exec-time=3227
Jun 22 09:22:01 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/205, version=1.591.2)
Jun 22 09:22:01 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_stop_0 (61) confirmed on vmi243500 (rc=0)
Jun 22 09:22:01 [1619] vmi243500       crmd:   notice: run_graph:	Transition 12 (Complete=2, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-587.bz2): Complete
Jun 22 09:22:01 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:22:01 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:22:01 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 09:22:01 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.591.2
Jun 22 09:22:01 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:22:01 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:01 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:02 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:02 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:02 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:03 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:22:06 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: cfd4d71dc12380c7a953b50e8093cb31 for 1.591.2 (0x55a4303e0c40 0)
Jun 22 09:23:02 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.591.2 2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.592.0 c40ba9c13ca5ce42676bc90d80b771e2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=592, @num_updates=0
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/primitive[@id='global_rsc_DEV_NIC']/meta_attributes[@id='local_rsc_DEV_NIC-meta_attributes']/nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role']:  @value=Stopped
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 12 aborted by local_rsc_DEV_NIC-meta_attributes-target-role doing modify target-role=Stopped: Configuration change | cib=1.592.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/primitive[@id='global_rsc_DEV_NIC']/meta_attributes[@id='local_rsc_DEV_NIC-meta_attributes']/nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role'] complete=true
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.592.0)
Jun 22 09:23:04 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:23:04 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped (disabled)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500 (disabled)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role']
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.592.0
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_CPU cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:   notice: LogAction:	 * Stop       global_rsc_DEV_NIC     ( vmi243500 )   due to node availability
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 13, saving inputs in /var/lib/pacemaker/pengine/pe-input-588.bz2
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 13 (ref=pe_calc-dc-1592810584-103) derived from /var/lib/pacemaker/pengine/pe-input-588.bz2
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating stop operation global_rsc_DEV_NIC_stop_0 locally on vmi243500 | action 60
Jun 22 09:23:04 [1616] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation global_rsc_DEV_NIC_monitor_10000
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-28.raw
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=60:13:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_stop_0
Jun 22 09:23:04 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:stop call_id:115
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: Cancelled | call=88 key=global_rsc_DEV_NIC_monitor_10000 confirmed=true
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/207)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.592.0 2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.592.1 (null)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_stop_0, @operation=stop, @transition-key=60:13:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;60:13:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592810584, @last-rc-change=15928
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/207, version=1.592.1)
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.592.1
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.592.0 of the CIB to disk (digest: 6ec95980e469aa3e98b86bd74bfc4765)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.hu0mBx (digest: /var/lib/pacemaker/cib/cib.rpuy25)
Jun 22 09:23:04 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: 1 -> (null) from vmi243500
Jun 22 09:23:04 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 14 with 1 changes for ethmonitor-eth0, id=<n/a>, set=(null)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/14)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.592.1 2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.592.2 (null)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-ethmonitor-eth0']
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/14, version=1.592.2)
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 13 aborted by deletion of nvpair[@id='status-771304931-ethmonitor-eth0']: Transient attribute change | cib=1.592.2 source=abort_unless_down:344 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-ethmonitor-eth0'] complete=false
Jun 22 09:23:04 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:stop call_id:115 pid:9611 exit-code:0 exec-time:40ms queue-time:0ms
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=115 key=global_rsc_DEV_NIC_stop_0 confirmed=true cib-update=208
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/208)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.592.2 2
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.592.3 (null)
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;60:13:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=115, @rc-code=0, @op-status=0, @exec-time=40
Jun 22 09:23:04 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/208, version=1.592.3)
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_stop_0 (60) confirmed on vmi243500 (rc=0)
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: run_graph:	Transition 13 (Complete=2, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-588.bz2): Complete
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.592.3
Jun 22 09:23:04 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:04 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 14 for ethmonitor-eth0: OK (0)
Jun 22 09:23:04 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 14 for ethmonitor-eth0[vmi243500]=(null): OK (0)
Jun 22 09:23:04 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:23:04 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped (disabled)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped (disabled)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:23:04 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_CPU cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:23:04 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 14, saving inputs in /var/lib/pacemaker/pengine/pe-input-589.bz2
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 14 (ref=pe_calc-dc-1592810584-105) derived from /var/lib/pacemaker/pengine/pe-input-589.bz2
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: run_graph:	Transition 14 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-589.bz2): Complete
Jun 22 09:23:04 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:23:04 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:23:05 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:05 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:06 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:06 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:07 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:07 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:09 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: cbd822eaaa4d7a5cda8cdb3ec3e5a228 for 1.592.3 (0x55a42ff465c0 0)
Jun 22 09:23:40 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.592.3 2
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.593.0 (null)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=593, @num_updates=0
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/primitive[@id='global_rsc_DEV_CPU']/meta_attributes[@id='global_rsc_DEV_CPU-meta_attributes']/nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role']:  @value=Started
Jun 22 09:23:41 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 14 aborted by global_rsc_DEV_CPU-meta_attributes-target-role doing modify target-role=Started: Configuration change | cib=1.593.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/primitive[@id='global_rsc_DEV_CPU']/meta_attributes[@id='global_rsc_DEV_CPU-meta_attributes']/nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role'] complete=true
Jun 22 09:23:41 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.593.0)
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='global_rsc_DEV_CPU-meta_attributes-target-role']
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.593.0
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:41 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:23:41 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Stopped
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped (disabled)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: native_color:	Resource global_rsc_DEV_NIC cannot run anywhere
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_CPU on vmi243500
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_CPU     ( vmi243500 )  
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Stopped)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:23:41 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-29.raw
Jun 22 09:23:41 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 15, saving inputs in /var/lib/pacemaker/pengine/pe-input-590.bz2
Jun 22 09:23:41 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:23:41 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 15 (ref=pe_calc-dc-1592810621-106) derived from /var/lib/pacemaker/pengine/pe-input-590.bz2
Jun 22 09:23:41 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation global_rsc_DEV_CPU_start_0 locally on vmi243500 | action 59
Jun 22 09:23:41 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=59:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_start_0
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.593.0 of the CIB to disk (digest: 5348214bc0e49d609fa8c88dd2634c9f)
Jun 22 09:23:41 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:start call_id:116
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.GSfob4 (digest: /var/lib/pacemaker/cib/cib.SAD2H3)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/211)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.593.0 2
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.593.1 (null)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_start_0, @operation=start, @transition-key=59:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;59:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592810621, @last-rc-change=159
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/211, version=1.593.1)
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.593.1
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:41 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:start call_id:116 pid:10954 exit-code:0 exec-time:23ms queue-time:0ms
Jun 22 09:23:41 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=116 key=global_rsc_DEV_CPU_start_0 confirmed=true cib-update=212
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/212)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.593.1 2
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.593.2 (null)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;59:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=116, @rc-code=0, @op-status=0, @exec-time=23
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/212, version=1.593.2)
Jun 22 09:23:41 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_start_0 (59) confirmed on vmi243500 (rc=0)
Jun 22 09:23:41 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_CPU_monitor_10000 locally on vmi243500 | action 60
Jun 22 09:23:41 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=60:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_CPU_monitor_10000
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/213)
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.593.2
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.593.2 2
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.593.3 (null)
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-key=60:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;60:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1592810621, @exec-time=0
Jun 22 09:23:41 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/213, version=1.593.3)
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.593.3
Jun 22 09:23:41 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:42 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:42 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:43 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:43 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:44 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:44 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:45 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:45 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=117 key=global_rsc_DEV_CPU_monitor_10000 confirmed=false cib-update=214
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/214)
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.593.3 2
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.593.4 (null)
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-magic=0:0;60:15:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=117, @rc-code=0, @op-status=0, @exec-time=3225
Jun 22 09:23:45 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_CPU_monitor_10000 (60) confirmed on vmi243500 (rc=0)
Jun 22 09:23:45 [1619] vmi243500       crmd:   notice: run_graph:	Transition 15 (Complete=2, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-590.bz2): Complete
Jun 22 09:23:45 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:23:45 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:23:45 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Jun 22 09:23:45 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.593.4
Jun 22 09:23:45 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:45 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/214, version=1.593.4)
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.593.4 2
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.0 (null)
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=594, @num_updates=0
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/primitive[@id='global_rsc_DEV_NIC']/meta_attributes[@id='local_rsc_DEV_NIC-meta_attributes']/nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role']:  @value=Started
Jun 22 09:23:46 [1619] vmi243500       crmd:     info: abort_transition_graph:	Transition 15 aborted by local_rsc_DEV_NIC-meta_attributes-target-role doing modify target-role=Started: Configuration change | cib=1.594.0 source=te_update_diff_v2:500 path=/cib/configuration/resources/primitive[@id='global_rsc_DEV_NIC']/meta_attributes[@id='local_rsc_DEV_NIC-meta_attributes']/nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role'] complete=true
Jun 22 09:23:46 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_IDLE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='local_rsc_DEV_NIC-meta_attributes-target-role']
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.594.0
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.594.0)
Jun 22 09:23:46 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:23:46 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Stopped
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_NIC on vmi243500
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:   notice: LogAction:	 * Start      global_rsc_DEV_NIC     ( vmi243500 )  
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:23:46 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:23:46 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 16, saving inputs in /var/lib/pacemaker/pengine/pe-input-591.bz2
Jun 22 09:23:46 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:23:46 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 16 (ref=pe_calc-dc-1592810626-109) derived from /var/lib/pacemaker/pengine/pe-input-591.bz2
Jun 22 09:23:46 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating start operation global_rsc_DEV_NIC_start_0 locally on vmi243500 | action 62
Jun 22 09:23:46 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=62:16:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_start_0
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/216)
Jun 22 09:23:46 [1616] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:start call_id:118
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.594.0 2
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.1 (null)
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_start_0, @operation=start, @transition-key=62:16:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;62:16:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1592810626, @last-rc-change=159
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/216, version=1.594.1)
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.594.1
Jun 22 09:23:46 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-30.raw
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.594.0 of the CIB to disk (digest: 98852dcf2286f59af10e506e5e6a2a02)
Jun 22 09:23:46 [1614] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.44wpRp (digest: /var/lib/pacemaker/cib/cib.MiFfIB)
Jun 22 09:23:47 [1617] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: (null) -> 1 from vmi243500
Jun 22 09:23:47 [1617] vmi243500      attrd:     info: write_attribute:	Sent update 15 with 1 changes for ethmonitor-eth0, id=<n/a>, set=(null)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/attrd/15)
Jun 22 09:23:47 [1616] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:start call_id:118 pid:11205 exit-code:0 exec-time:262ms queue-time:0ms
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.594.1 2
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.2 (null)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-ethmonitor-eth0" name="ethmonitor-eth0" value="1"/>
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/attrd/15, version=1.594.2)
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=118 key=global_rsc_DEV_NIC_start_0 confirmed=true cib-update=217
Jun 22 09:23:47 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 15 for ethmonitor-eth0: OK (0)
Jun 22 09:23:47 [1617] vmi243500      attrd:     info: attrd_cib_callback:	Update 15 for ethmonitor-eth0[vmi243500]=1: OK (0)
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: abort_transition_graph:	Transition 16 aborted by status-771304931-ethmonitor-eth0 doing create ethmonitor-eth0=1: Transient attribute change | cib=1.594.2 source=abort_unless_down:330 path=/cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931'] complete=false
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/217)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.594.2 2
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.3 (null)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;62:16:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=118, @rc-code=0, @op-status=0, @exec-time=262
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/217, version=1.594.3)
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_start_0 (62) confirmed on vmi243500 (rc=0)
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: run_graph:	Transition 16 (Complete=1, Pending=0, Fired=0, Skipped=1, Incomplete=1, Source=/var/lib/pacemaker/pengine/pe-input-591.bz2): Stopped
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_POLICY_ENGINE | input=I_PE_CALC cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.594.3
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:47 [1618] vmi243500    pengine:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: determine_online_status_fencing:	Node vmi243500 is active
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: determine_online_status:	Node vmi243500 is online
Jun 22 09:23:47 [1618] vmi243500    pengine:  warning: unpack_rsc_op_failure:	Processing failed op start for rsc_DEV_CI on vmi243500: unknown error (1)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 771304931 is already processed
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: unpack_node_loop:	Node 96317541 is already processed
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	stonith-sbd	(stonith:external/sbd):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_database
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_database	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_database	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_database	(ocf::heartbeat:SAPDatabase):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ascs
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ASCS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ASCS00	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     fs_2_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     fs_3_DEV_ASCS	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ci
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     fs_DEV_CI	(ocf::heartbeat:Filesystem):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_CI	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_CI	(ocf::heartbeat:SAPInstance):	Stopped
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: group_print:	 Resource Group: grp_DEV_ers
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     vip_DEV_ERS	(ocf::heartbeat:IPaddr2):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	     rsc_DEV_ERS10	(ocf::heartbeat:SAPInstance):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_CPU	(ocf::pacemaker:HealthCPU):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: common_print:	global_rsc_DEV_NIC	(ocf::heartbeat:ethmonitor):	Started vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: clone_print:	 Clone Set: cl-storage [grp_DEV_storage_dlm]
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: short_print:	     Started: [ vmi243500 ]
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: short_print:	     Stopped: [ vmi243493 ]
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: pe_get_failcount:	rsc_DEV_CI has failed INFINITY times on vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:  warning: check_migration_threshold:	Forcing rsc_DEV_CI away from vmi243500 after 1000000 failures (max=1000000)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: rsc_merge_weights:	fs_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: rsc_merge_weights:	vip_DEV_CI: Rolling back scores from rsc_DEV_CI
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: native_color:	Resource rsc_DEV_CI cannot run anywhere
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: colocation_match:	vip_DEV_ERS: Rolling back scores from fs_DEV_ASCS (1, -5000)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: rsc_merge_weights:	dlm_DEV:1: Rolling back scores from fs_DEV_sapmnt:1
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: native_color:	Resource dlm_DEV:1 cannot run anywhere
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: native_color:	Resource fs_DEV_sapmnt:1 cannot run anywhere
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: RecurringOp:	 Start recurring monitor (10s) for global_rsc_DEV_NIC on vmi243500
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   stonith-sbd	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_database	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_database	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_database	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ASCS00	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_2_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_3_DEV_ASCS	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_CI	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_CI	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_CI	(Stopped)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   vip_DEV_ERS	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   rsc_DEV_ERS10	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_CPU	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   global_rsc_DEV_NIC	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:0	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:0	(Started vmi243500)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   dlm_DEV:1	(Stopped)
Jun 22 09:23:47 [1618] vmi243500    pengine:     info: LogActions:	Leave   fs_DEV_sapmnt:1	(Stopped)
Jun 22 09:23:47 [1618] vmi243500    pengine:   notice: process_pe_message:	Calculated transition 17, saving inputs in /var/lib/pacemaker/pengine/pe-input-592.bz2
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: do_state_transition:	State transition S_POLICY_ENGINE -> S_TRANSITION_ENGINE | input=I_PE_SUCCESS cause=C_IPC_MESSAGE origin=handle_response
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: do_te_invoke:	Processing graph 17 (ref=pe_calc-dc-1592810627-111) derived from /var/lib/pacemaker/pengine/pe-input-592.bz2
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: te_rsc_command:	Initiating monitor operation global_rsc_DEV_NIC_monitor_10000 locally on vmi243500 | action 64
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=64:17:0:b58f891c-6e09-4d3a-be21-ca68613900d7 op=global_rsc_DEV_NIC_monitor_10000
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/219)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.594.3 2
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.4 (null)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']:  @transition-key=64:17:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @transition-magic=-1:193;64:17:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1592810627, @exec-time=0
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/219, version=1.594.4)
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.594.4
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_TRANSITION_ENGINE
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=119 key=global_rsc_DEV_NIC_monitor_10000 confirmed=false cib-update=220
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/220)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.594.4 2
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.594.5 (null)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']:  @transition-magic=0:0;64:17:0:b58f891c-6e09-4d3a-be21-ca68613900d7, @call-id=119, @rc-code=0, @op-status=0, @exec-time=367
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: match_graph_event:	Action global_rsc_DEV_NIC_monitor_10000 (64) confirmed on vmi243500 (rc=0)
Jun 22 09:23:47 [1614] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/220, version=1.594.5)
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: run_graph:	Transition 17 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-592.bz2): Complete
Jun 22 09:23:47 [1619] vmi243500       crmd:     info: do_log:	Input I_TE_SUCCESS received in state S_TRANSITION_ENGINE from notify_crmd
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: do_state_transition:	State transition S_TRANSITION_ENGINE -> S_IDLE | input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.594.5
Jun 22 09:23:47 [1615] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Jun 22 09:23:47 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:48 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:49 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:50 [1619] vmi243500       crmd:   notice: handle_request:	Current ping state: S_IDLE
Jun 22 09:23:52 [1614] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243500: e04d49915ac91aa4bbbe36aea197c75e for 1.594.5 (0x55a430640e40 0)
Set r/w permissions for uid=90, gid=90 on /var/log/pacemaker/pacemaker.log
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: get_cluster_type:	Detected an active 'corosync' cluster
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: mcp_read_config:	Reading configure for stack: corosync
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: main:	Starting Pacemaker 1.1.18+20180430.b12c320f5-lp150.1.4 | build=b12c320f5 features: generated-manpages agent-manpages ncurses libqb-logging libqb-ipc lha-fencing systemd nagios  corosync-native atomic-attrd acls cibsecrets
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: main:	Maximum core file size is: 18446744073709551615
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: qb_ipcs_us_publish:	server name: pacemakerd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry 08ba4658-a9ff-4419-8f12-f102197e3624/0x55722c2f10d0 for node (null)/771304931 (1 total)
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: cluster_connect_quorum:	Quorum acquired
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process cib
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1674 for process cib
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1675 for process stonith-ng
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1676 for process lrmd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process attrd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1677 for process attrd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process pengine
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1678 for process pengine
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Using uid=90 and group=90 for process crmd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: start_child:	Forked child 1679 for process crmd
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: main:	Starting mainloop
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Quorum retained | membership=1184 members=2
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Created entry 2c8816f8-6709-46f6-a381-a368adc4c7aa/0x55722c5f3460 for node (null)/96317541 (2 total)
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1674] vmi243500        cib:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Feb 07 11:49:38 [1674] vmi243500        cib:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Feb 07 11:49:38 [1674] vmi243500        cib:     info: retrieveCib:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.xml (digest: /var/lib/pacemaker/cib/cib.xml.sig)
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 joined group pacemakerd (counter=0.0)
Feb 07 11:49:38 [1674] vmi243500        cib:     info: validate_with_relaxng:	Creating RNG parser context
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 96317541 still member of group pacemakerd (peer=(null), counter=0.0)
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: pcmk_cpg_membership:	Node 771304931 still member of group pacemakerd (peer=vmi243500, counter=0.1)
Feb 07 11:49:38 [1670] vmi243500 pacemakerd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Feb 07 11:49:38 [1674] vmi243500        cib:     info: startCib:	CIB Initialization completed successfully
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Feb 07 11:49:38 [1674] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_get_peer:	Created entry b69c3de8-966a-4264-a7cc-675b3d10552a/0x55d324b41050 for node (null)/771304931 (1 total)
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1674] vmi243500        cib:     info: init_cs_connection_once:	Connection to 'corosync': established
Feb 07 11:49:38 [1676] vmi243500       lrmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1676] vmi243500       lrmd:     info: qb_ipcs_us_publish:	server name: lrmd
Feb 07 11:49:38 [1676] vmi243500       lrmd:     info: main:	Starting
Feb 07 11:49:38 [1674] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: main:	Starting up
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Feb 07 11:49:38 [1678] vmi243500    pengine:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1678] vmi243500    pengine:     info: qb_ipcs_us_publish:	server name: pengine
Feb 07 11:49:38 [1678] vmi243500    pengine:     info: main:	Starting pengine
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Feb 07 11:49:38 [1674] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_ro
Feb 07 11:49:38 [1674] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_rw
Feb 07 11:49:38 [1674] vmi243500        cib:     info: qb_ipcs_us_publish:	server name: cib_shm
Feb 07 11:49:38 [1674] vmi243500        cib:     info: cib_init:	Starting cib mainloop
Feb 07 11:49:38 [1674] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 joined group cib (counter=0.0)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Created entry e6e6ddde-af88-4bad-b6f1-dbad760d8534/0x55934a907260 for node (null)/771304931 (1 total)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: init_cs_connection_once:	Connection to 'corosync': established
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_log_init:	Changed active directory to /var/lib/pacemaker/cores
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: main:	CRM Git Version: 1.1.18+20180430.b12c320f5-lp150.1.4 (b12c320f5)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_log:	Input I_STARTUP received in state S_STARTING from crmd_init
Feb 07 11:49:38 [1674] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_get_peer:	Created entry 823b8389-9622-4d70-bece-05b6c6c62802/0x55d324b44c20 for node (null)/96317541 (2 total)
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Feb 07 11:49:38 [1674] vmi243500        cib:     info: pcmk_cpg_membership:	Node 96317541 still member of group cib (peer=(null), counter=0.0)
Feb 07 11:49:38 [1674] vmi243500        cib:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1674] vmi243500        cib:     info: pcmk_cpg_membership:	Node 771304931 still member of group cib (peer=vmi243500, counter=0.1)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: get_cluster_type:	Verifying cluster type: 'corosync'
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: get_cluster_type:	Assuming an active 'corosync' cluster
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: crm_cluster_connect:	Connecting to cluster infrastructure: corosync
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry 4566b382-df48-4ae6-b2a1-087b5877deb6/0x56018eddc180 for node (null)/771304931 (1 total)
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=771304931 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: main:	Cluster connection active
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 771304931
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: init_cs_connection_once:	Connection to 'corosync': established
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_get_peer:	Created entry 94ea784b-a226-428d-89f3-e6412f064d49/0x55df7cb68a40 for node (null)/771304931 (1 total)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 has uuid 771304931
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_update_peer_proc:	cluster_connect_cpg: Node (null)[771304931] - corosync-cpg is now online
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: init_cs_connection_once:	Connection to 'corosync': established
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_erase_attrs:	Clearing transient attributes from CIB | xpath=//node_state[@uname='vmi243500']/transient_attributes
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_client_update:	Starting an election to determine the writer
Feb 07 11:49:38 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes to all (origin=local/attrd/2)
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_get_peer:	Node 771304931 is now known as vmi243500
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now in unknown state
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: main:	CIB connection active
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: qb_ipcs_us_publish:	server name: attrd
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: main:	Accepting attribute updates
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 joined group attrd (counter=0.0)
Feb 07 11:49:38 [1674] vmi243500        cib:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1674] vmi243500        cib:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/transient_attributes: OK (rc=0, origin=vmi243500/attrd/2, version=1.598.0)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Created entry 4564784e-73d0-45e7-a0a7-692c7ae29ff3/0x55934aa11000 for node (null)/96317541 (2 total)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 96317541 still member of group attrd (peer=(null), counter=0.0)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: pcmk_cpg_membership:	Node 771304931 still member of group attrd (peer=vmi243500, counter=0.1)
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Feb 07 11:49:38 [1677] vmi243500      attrd:   notice: attrd_peer_message:	Recorded attribute writer: vmi243493
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_peer_message:	Processing sync-response from vmi243493
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243493]: (null) -> 2 from vmi243493
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting runs_ers_DEV[vmi243493]: (null) -> 0 from vmi243493
Feb 07 11:49:38 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #attrd-protocol[vmi243500]: (null) -> 2 from vmi243500
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: setup_cib:	Watching for stonith topology changes
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: qb_ipcs_us_publish:	server name: stonith-ng
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: main:	Starting stonith-ng mainloop
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 joined group stonith-ng (counter=0.0)
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: cluster_connect_quorum:	Quorum acquired
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Created entry 19fa9149-a82a-4f6d-8855-95a4abafb193/0x56018eee9d90 for node (null)/96317541 (2 total)
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 96317541 still member of group stonith-ng (peer=(null), counter=0.0)
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=crm_update_peer_proc
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: pcmk_cpg_membership:	Node 771304931 still member of group stonith-ng (peer=vmi243500, counter=0.1)
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: init_cib_cache_cb:	Updating device list from the cib: init
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.0
Feb 07 11:49:38 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_ha_control:	Connected to the cluster
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: lrmd_ipc_connect:	Connecting to lrmd
Feb 07 11:49:38 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section nodes to all (origin=local/crmd/2)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_lrm_control:	LRM connection established
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_started:	Delaying start, no membership data (0000000000100000)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: pcmk_quorum_notification:	Quorum retained | membership=1184 members=2
Feb 07 11:49:38 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243500/crmd/2, version=1.598.0)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_get_peer:	Created entry fd7bad61-656d-43fe-ae17-90199e79eff4/0x55df7cc69ce0 for node (null)/96317541 (2 total)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 has uuid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: pcmk_quorum_notification:	Obtaining name for new node 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node (null) state is now member | nodeid=96317541 previous=unknown source=pcmk_quorum_notification
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: crm_update_peer_state_iter:	Node vmi243500 state is now member | nodeid=771304931 previous=unknown source=pcmk_quorum_notification
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243500 is now member (was in unknown state)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 771304931
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: get_node_name:	Defaulting to uname -n for the local corosync node name
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_started:	Delaying start, Config not read (0000000000000040)
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: qb_ipcs_us_publish:	server name: crmd
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: do_started:	The local CRM is operational
Feb 07 11:49:38 [1679] vmi243500       crmd:     info: do_log:	Input I_PENDING received in state S_STARTING from do_started
Feb 07 11:49:38 [1679] vmi243500       crmd:   notice: do_state_transition:	State transition S_STARTING -> S_PENDING | input=I_PENDING cause=C_FSA_INTERNAL origin=do_started
Feb 07 11:49:39 [1674] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-37.raw
Feb 07 11:49:39 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.598.0 of the CIB to disk (digest: 80c7589de1e617f818ca6614a62e1313)
Feb 07 11:49:39 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.XEyzhs (digest: /var/lib/pacemaker/cib/cib.GFkMeI)
Feb 07 11:49:39 [1679] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 joined group crmd (counter=0.0)
Feb 07 11:49:39 [1679] vmi243500       crmd:     info: corosync_node_name:	Unable to get node name for nodeid 96317541
Feb 07 11:49:39 [1679] vmi243500       crmd:   notice: get_node_name:	Could not obtain a node name for corosync nodeid 96317541
Feb 07 11:49:39 [1679] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 96317541 still member of group crmd (peer=(null), counter=0.0)
Feb 07 11:49:39 [1679] vmi243500       crmd:     info: crm_update_peer_proc:	pcmk_cpg_membership: Node (null)[96317541] - corosync-cpg is now online
Feb 07 11:49:39 [1679] vmi243500       crmd:     info: pcmk_cpg_membership:	Node 771304931 still member of group crmd (peer=vmi243500, counter=0.1)
Feb 07 11:49:39 [1675] vmi243500 stonith-ng:     info: stonith_device_register:	Added 'stonith-sbd' to the device list (1 active devices)
Feb 07 11:49:39 [1675] vmi243500 stonith-ng:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: peer_update_callback:	Cluster node vmi243493 is now member
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: update_dc:	Set DC to vmi243493 (3.1.0)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: crm_update_peer_expected:	update_dc: Node vmi243493[96317541] - expected state is now member (was (null))
Feb 07 11:49:40 [1674] vmi243500        cib:     info: crm_get_peer:	Node 96317541 is now known as vmi243493
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_log:	Input I_NOT_DC received in state S_PENDING from do_cl_join_finalize_respond
Feb 07 11:49:40 [1679] vmi243500       crmd:   notice: do_state_transition:	State transition S_PENDING -> S_NOT_DC | input=I_NOT_DC cause=C_HA_MESSAGE origin=do_cl_join_finalize_respond
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_replace:	Digest matched on replace from vmi243493: 3032225038c869aa94edd4c6a3d3f09e
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_replace:	Replaced 1.598.0 with 1.598.44 from vmi243493
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.0 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.44 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=44, @cib-last-written=Sun Feb  7 11:41:11 2021, @dc-uuid=96317541
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="96317541" uname="vmi243493" in_ccm="true" crmd="online" crm-debug-origin="post_cache_update" join="member" expected="member"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                 <lrm id="96317541">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                   <lrm_resources>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="2:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;2:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="5" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="161269468
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="3:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;3:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="9" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="1
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="4:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;4:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="13" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="5:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;5:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="17" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;6:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="21" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16126946
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="7:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;7:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="25" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="161269
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="8:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;8:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="29" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;9:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="33" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="1612
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="10:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;10:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="37" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;11:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="41" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="1612694688
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="12:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;12:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="45" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16126946
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="13:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;13:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="49" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16126946
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="14:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;14:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="53" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="161269
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_stop_0" operation="stop" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="40:1:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:0;40:1:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="76" rc-code="0" op-status="0" interval="0" last-run="1612694688" last-rc-change="16126946
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="rsc_DEV_ERS10_last_failure_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:0;15:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="57" rc-code="0" op-status="0" interval="0" last-run="1612694688" last-rc-ch
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="16:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;16:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="61" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;17:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="65" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="18:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;18:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="70" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="1612694688" ex
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                       <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="19:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;19:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="75" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc-change="16
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                   </lrm_resources>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                 </lrm>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                 <transient_attributes id="96317541">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                   <instance_attributes id="status-96317541">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                     <nvpair id="status-96317541-runs_ers_DEV" name="runs_ers_DEV" value="0"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                   </instance_attributes>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                 </transient_attributes>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++               </node_state>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status:  <node_state id="771304931" in_ccm="true" crmd="offline" crm-debug-origin="post_cache_update"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_replace_notify:	Replaced: 1.598.0 -> 1.598.44 from vmi243493
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_replace operation for section 'all': OK (rc=0, origin=vmi243493/crmd/71, version=1.598.44)
Feb 07 11:49:40 [1677] vmi243500      attrd:   notice: attrd_cib_replaced_cb:	Updating all attributes after cib_refresh_notify event
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/72, version=1.598.44)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/73, version=1.598.44)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']/lrm: OK (rc=0, origin=vmi243493/crmd/74, version=1.598.44)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.44 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.45 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=45
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crmd=online, @crm-debug-origin=do_lrm_query_internal, @uname=vmi243500
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <lrm id="771304931"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                             <lrm_resources/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                           </lrm>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/75, version=1.598.45)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.45 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.46 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='96317541']/lrm[@id='96317541']
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=46
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243493']/lrm: OK (rc=0, origin=vmi243493/crmd/76, version=1.598.46)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.46 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.47 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=47
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_lrm_query_internal
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']:  <lrm id="96317541"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                            <lrm_resources>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="3:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;3:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="9" rc-code="7" op-status="0" interval="0" last-run="161269
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="18:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;18:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="70" rc-code="7" op-status="0" interval="0" last-run="1612694688" last-rc
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="19:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;19:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="75" rc-code="7" op-status="0" interval="0" last-run="1612694
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="9:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;9:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="33" rc-code="7" op-status="0" interval="0" last-run="161269468
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="11:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;11:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="41" rc-code="7" op-status="0" interval="0" last-run="1612694688" las
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="13:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;13:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="49" rc-code="7" op-status="0" interval="0" last-run="1612694688" l
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="12:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;12:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="45" rc-code="7" op-status="0" interval="0" last-run="1612694688" l
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="16:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;16:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="61" rc-code="7" op-status="0" interval="0" last-ru
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="rsc_DEV_ERS10_last_failure_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="15:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:0;15:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="57" rc-code="0" op-status="0" interval="0" last-run=
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_stop_0" operation="stop" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="40:1:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:0;40:1:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="76" rc-code="0" op-status="0" interval="0" last-run="1612694688" l
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="2:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;2:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="5" rc-code="7" op-status="0" interval="0" last-run="1612694688" la
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="7:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;7:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="25" rc-code="7" op-status="0" interval="0" last-run="1612694688"
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="5:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;5:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="17" rc-code="7" op-status="0" interval="0" last-run="161
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="8:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;8:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="29" rc-code="7" op-status="0" interval="0" last-run="1612694
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="6:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;6:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="21" rc-code="7" op-status="0" interval="0" last-run="1612694688" l
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="10:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;10:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="37" rc-code="7" op-status="0" interval="0" last-run="1612694
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="14:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;14:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="53" rc-code="7" op-status="0" interval="0" last-run="1612694688"
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="4:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;4:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="13" rc-code="7" op-status="0" interval="0" last-run="161
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat">
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="build_active_RAs" crm_feature_set="3.1.0" transition-key="17:0:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;17:0:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="65" rc-code="7" op-status="0" interval="0" last-ru
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                            </lrm_resources>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                          </lrm>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/77, version=1.598.47)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section nodes: OK (rc=0, origin=vmi243493/crmd/80, version=1.598.47)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-38.raw
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.47 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.48 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=48
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_state_transition
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_state_transition, @join=member, @expected=member
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/81, version=1.598.48)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.598.0 of the CIB to disk (digest: c94ea0494a2d2dd80c25c92731a87d46)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section cib: OK (rc=0, origin=vmi243493/crmd/82, version=1.598.48)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.FLuMlq (digest: /var/lib/pacemaker/cib/cib.FNwmAK)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'stonith-sbd' not found (0 active resources)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'stonith-sbd' to the rsc list (1 active resources)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=2:3:7:24d705d1-0549-478b-9776-868390dd465b op=stonith-sbd_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/6)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.48 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.49 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=49
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']:  @crm-debug-origin=do_update_resource
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="stonith-sbd" type="external/sbd" class="stonith"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="stonith-sbd_last_0" operation_key="stonith-sbd_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="2:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;2:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/6, version=1.598.49)
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.49
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_database' not found (1 active resources)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_database' to the rsc list (2 active resources)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=3:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_database_monitor_0
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed Filesystem_meta-data_0 process 1729 exited with rc=0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/7)
Feb 07 11:49:40 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for stonith-sbd on vmi243500: 7 (not running) | call=5 key=stonith-sbd_monitor_0 confirmed=true cib-update=8
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/8)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_database' not found (2 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.49 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.50 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=50
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_database" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_database' to the rsc list (3 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_database_last_0" operation_key="fs_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="3:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;3:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=4:3:7:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_database_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/7, version=1.598.50)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.50 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.51 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=51
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:7;2:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=5, @rc-code=7, @op-status=0, @exec-time=7
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.50
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/8, version=1.598.51)
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.51
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.51 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.52 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=52
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']:  @crm-debug-origin=do_update_resource
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @operation_key=stonith-sbd_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=20:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;20:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612694980, @last-
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/86, version=1.598.52)
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.52
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed IPaddr2_meta-data_0 process 1736 exited with rc=0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/9)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_database' not found (3 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.52 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.53 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=53
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_database" type="IPaddr2" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_database_last_0" operation_key="vip_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="4:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;4:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" o
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_database' to the rsc list (4 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/9, version=1.598.53)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=5:3:7:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_database_monitor_0
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.53
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed SAPDatabase_meta-data_0 process 1754 exited with rc=0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/10)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_ASCS' not found (4 active resources)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_ASCS' to the rsc list (5 active resources)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=6:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_ASCS_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.53 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.54 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=54
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_database" type="SAPDatabase" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_database_last_0" operation_key="rsc_DEV_database_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="5:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;5:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" o
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/10, version=1.598.54)
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.54
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ASCS' not found (5 active resources)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ASCS' to the rsc list (6 active resources)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=7:3:7:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_ASCS_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/11)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ASCS00' not found (6 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/12)
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ASCS00' to the rsc list (7 active resources)
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=8:3:7:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_ASCS00_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.54 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.55 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=55
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_ASCS_last_0" operation_key="fs_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;6:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/11, version=1.598.55)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.55 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.56 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=56
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ASCS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ASCS_last_0" operation_key="vip_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="7:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;7:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/12, version=1.598.56)
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.55
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.56
Feb 07 11:49:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed SAPInstance_meta-data_0 process 1788 exited with rc=0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/13)
Feb 07 11:49:40 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_database on vmi243500: 7 (not running) | call=9 key=fs_DEV_database_monitor_0 confirmed=true cib-update=14
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_2_DEV_ASCS' not found (7 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.56 2
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.57 (null)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=57
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ASCS00" type="SAPInstance" class="ocf" provider="heartbeat"/>
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ASCS00_last_0" operation_key="rsc_DEV_ASCS00_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="8:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;8:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Feb 07 11:49:40 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_2_DEV_ASCS' to the rsc list (8 active resources)
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_2_DEV_ASCS_monitor_0
Feb 07 11:49:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/13, version=1.598.57)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/14)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.57
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_database on vmi243500: 7 (not running) | call=13 key=vip_DEV_database_monitor_0 confirmed=true cib-update=16
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_3_DEV_ASCS' not found (8 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_3_DEV_ASCS' to the rsc list (9 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_3_DEV_ASCS_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.57 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.58 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=58
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:7;3:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=9, @rc-code=7, @op-status=0, @exec-time=76
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/14, version=1.598.58)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/15)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:3:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_database_start_0
Feb 07 11:49:41 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_database action:start call_id:38
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/16)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/17)
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_ASCS on vmi243500: 7 (not running) | call=21 key=fs_DEV_ASCS_monitor_0 confirmed=true cib-update=19
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.58 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.59 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=59
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_2_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_2_DEV_ASCS_last_0" operation_key="fs_2_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;9:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-stat
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/15, version=1.598.59)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.59 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.60 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=60
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:7;4:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=13, @rc-code=7, @op-status=0, @exec-time=82
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/16, version=1.598.60)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.60 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.61 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=61
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_3_DEV_ASCS" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_3_DEV_ASCS_last_0" operation_key="fs_3_DEV_ASCS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="10:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;10:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/17, version=1.598.61)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/18)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.58
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/19)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.61 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.62 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=62
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @operation_key=fs_DEV_database_start_0, @operation=start, @transition-key=22:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;22:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612694981, @last-rc-change=1612694981, @e
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_CI' not found (9 active resources)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/18, version=1.598.62)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_CI' to the rsc list (10 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=11:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.62 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.63 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=63
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:7;6:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=21, @rc-code=7, @op-status=0, @exec-time=65
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/19, version=1.598.63)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/20)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_CI' not found (10 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_CI' to the rsc list (11 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=12:3:7:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.63 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.64 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=64
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_CI" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_CI_last_0" operation_key="fs_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;11:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.59
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/20, version=1.598.64)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/21)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.64 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.65 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=65
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_CI" type="IPaddr2" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_CI_last_0" operation_key="vip_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="12:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;12:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/21, version=1.598.65)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.60
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.61
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_database on vmi243500: 7 (not running) | call=17 key=rsc_DEV_database_monitor_0 confirmed=true cib-update=22
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/22)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.65 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.66 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=66
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:7;5:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=17, @rc-code=7, @op-status=0, @exec-time=96
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.62
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/22, version=1.598.66)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (11 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (12 active resources)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.63
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=13:3:7:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/23)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.66 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.67 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=67
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="13:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;13:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/23, version=1.598.67)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.64
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.65
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.66
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ASCS on vmi243500: 7 (not running) | call=25 key=vip_DEV_ASCS_monitor_0 confirmed=true cib-update=24
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/24)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.67
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.67 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.68 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=68
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:7;7:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=25, @rc-code=7, @op-status=0, @exec-time=117
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/24, version=1.598.68)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.68
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'vip_DEV_ERS' not found (12 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'vip_DEV_ERS' to the rsc list (13 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=14:3:7:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_ERS_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/25)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.68 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.69 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=69
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="vip_DEV_ERS" type="IPaddr2" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="vip_DEV_ERS_last_0" operation_key="vip_DEV_ERS_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="14:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;14:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/25, version=1.598.69)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.69
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_3_DEV_ASCS on vmi243500: 7 (not running) | call=37 key=fs_3_DEV_ASCS_monitor_0 confirmed=true cib-update=26
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/26)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.69 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.70 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=70
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:7;10:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=37, @rc-code=7, @op-status=0, @exec-time=90
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/26, version=1.598.70)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.70
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_ERS10' not found (13 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_ERS10' to the rsc list (14 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=15:3:7:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_ERS10_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/27)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.70 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.71 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=71
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_ERS10" type="SAPInstance" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_ERS10_last_0" operation_key="rsc_DEV_ERS10_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="15:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;15:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/27, version=1.598.71)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.71
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_2_DEV_ASCS on vmi243500: 7 (not running) | call=33 key=fs_2_DEV_ASCS_monitor_0 confirmed=true cib-update=28
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/28)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_CPU' not found (14 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_CPU' to the rsc list (15 active resources)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.71 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.72 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=72
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:7;9:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=33, @rc-code=7, @op-status=0, @last-run=1612694981, @last-rc-change=1612694981, @exec-time=107
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=16:3:7:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_CPU_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/28, version=1.598.72)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.72
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed HealthCPU_meta-data_0 process 2243 exited with rc=0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/29)
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_CI on vmi243500: 7 (not running) | call=46 key=vip_DEV_CI_monitor_0 confirmed=true cib-update=30
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_CI on vmi243500: 7 (not running) | call=42 key=fs_DEV_CI_monitor_0 confirmed=true cib-update=31
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ASCS00 on vmi243500: 7 (not running) | call=29 key=rsc_DEV_ASCS00_monitor_0 confirmed=true cib-update=32
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=50 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=33
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.72 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.73 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=73
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_CPU" type="HealthCPU" class="ocf" provider="pacemaker"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_CPU_last_0" operation_key="global_rsc_DEV_CPU_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="16:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;16:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/29, version=1.598.73)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/30)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/31)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/32)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/33)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.73
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.73 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.74 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=74
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:7;12:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=46, @rc-code=7, @op-status=0, @exec-time=97
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/30, version=1.598.74)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.74 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.75 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=75
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:7;11:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=42, @rc-code=7, @op-status=0, @exec-time=101
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/31, version=1.598.75)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.75 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.76 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=76
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:7;8:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=29, @rc-code=7, @op-status=0, @last-run=1612694981, @last-rc-change=1612694981, @exec-time=125
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/32, version=1.598.76)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.74
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.76 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.77 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=77
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;13:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=50, @rc-code=7, @op-status=0, @exec-time=87
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/33, version=1.598.77)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'global_rsc_DEV_NIC' not found (15 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'global_rsc_DEV_NIC' to the rsc list (16 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=17:3:7:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_NIC_monitor_0
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.75
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.76
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.77
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed ethmonitor_meta-data_0 process 2329 exited with rc=0
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_CPU on vmi243500: 7 (not running) | call=62 key=global_rsc_DEV_CPU_monitor_0 confirmed=true cib-update=35
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for vip_DEV_ERS on vmi243500: 7 (not running) | call=54 key=vip_DEV_ERS_monitor_0 confirmed=true cib-update=36
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV' not found (16 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'dlm_DEV:1' not found (16 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'dlm_DEV' to the rsc list (17 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=18:3:7:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/34)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/35)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/36)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.77 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.78 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=78
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="global_rsc_DEV_NIC" type="ethmonitor" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="global_rsc_DEV_NIC_last_0" operation_key="global_rsc_DEV_NIC_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;17:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/34, version=1.598.78)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.78
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.78 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.79 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=79
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:7;16:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=62, @rc-code=7, @op-status=0, @exec-time=17
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/35, version=1.598.79)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.79 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.80 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=80
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:7;14:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=54, @rc-code=7, @op-status=0, @exec-time=85
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/36, version=1.598.80)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.79
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.80 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.81 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=81
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @operation_key=vip_DEV_ERS_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=56:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;56:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612694981, @last-
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/87, version=1.598.81)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.80
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.81
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: action_synced_wait:	Managed controld_meta-data_0 process 2356 exited with rc=0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/37)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt' not found (17 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'fs_DEV_sapmnt:1' not found (17 active resources)
Feb 07 11:49:41 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'fs_DEV_sapmnt' to the rsc list (18 active resources)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=19:3:7:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_monitor_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.81 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.82 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=82
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="dlm_DEV" type="controld" class="ocf" provider="pacemaker"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="dlm_DEV_last_0" operation_key="dlm_DEV_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="18:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;18:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status="-1" in
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/37, version=1.598.82)
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=64:3:0:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_CPU_start_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/38)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/39)
Feb 07 11:49:41 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_CPU action:start call_id:77
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.82 2
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.83 (null)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.82
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=83
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="fs_DEV_sapmnt" type="Filesystem" class="ocf" provider="heartbeat"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="fs_DEV_sapmnt_last_0" operation_key="fs_DEV_sapmnt_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="19:3:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;19:3:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-st
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/38, version=1.598.83)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.83 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.84 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=84
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @operation_key=global_rsc_DEV_CPU_start_0, @operation=start, @transition-key=64:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;64:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/39, version=1.598.84)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.83
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.84
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for global_rsc_DEV_NIC on vmi243500: 7 (not running) | call=66 key=global_rsc_DEV_NIC_monitor_0 confirmed=true cib-update=40
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/40)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.84 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.85 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=85
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:7;17:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=66, @rc-code=7, @op-status=0, @exec-time=48
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/40, version=1.598.85)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.85
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=66:3:0:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_NIC_start_0
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/41)
Feb 07 11:49:41 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:global_rsc_DEV_NIC action:start call_id:78
Feb 07 11:49:41 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_CPU action:start call_id:77 pid:2379 exit-code:0 exec-time:27ms queue-time:0ms
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=77 key=global_rsc_DEV_CPU_start_0 confirmed=true cib-update=42
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.85 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.86 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=86
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @operation_key=global_rsc_DEV_NIC_start_0, @operation=start, @transition-key=66:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;66:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @exec-time=0
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.86
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/41, version=1.598.86)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/42)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.86 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.87 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=87
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']:  @transition-magic=0:0;64:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=77, @rc-code=0, @op-status=0, @exec-time=27
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/42, version=1.598.87)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.87
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=65:3:0:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_CPU_monitor_10000
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/43)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.87 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.88 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=88
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']:  <lrm_rsc_op id="global_rsc_DEV_CPU_monitor_10000" operation_key="global_rsc_DEV_CPU_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="65:3:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;65:3:0:24d705d1-0549-478b-9776-868390dd465b" exit-reas
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/43, version=1.598.88)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_CPU']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.88
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.88 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.89 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=89
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_last_0']:  @transition-magic=0:0;56:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=78, @rc-code=0, @op-status=0, @exec-time=95
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/88, version=1.598.89)
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for dlm_DEV on vmi243500: 7 (not running) | call=71 key=dlm_DEV_monitor_0 confirmed=true cib-update=44
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.89
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/44)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.89 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.90 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=90
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:7;18:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=71, @rc-code=7, @op-status=0, @exec-time=76
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/44, version=1.598.90)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.90
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.90 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.91 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=91
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']:  <lrm_rsc_op id="vip_DEV_ERS_monitor_10000" operation_key="vip_DEV_ERS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="57:3:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;57:3:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi24349
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/89, version=1.598.91)
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_ERS10 on vmi243500: 7 (not running) | call=58 key=rsc_DEV_ERS10_monitor_0 confirmed=true cib-update=45
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/45)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ERS']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.91
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.91 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.92 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=92
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:7;15:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=58, @rc-code=7, @op-status=0, @exec-time=192
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/45, version=1.598.92)
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for fs_DEV_sapmnt on vmi243500: 7 (not running) | call=76 key=fs_DEV_sapmnt_monitor_0 confirmed=true cib-update=46
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/46)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.92
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.92 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.93 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=93
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:7;19:3:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=76, @rc-code=7, @op-status=0, @exec-time=93
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/46, version=1.598.93)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.93
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.93 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.94 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=94
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @operation_key=rsc_DEV_ERS10_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=58:3:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;58:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612694981, 
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/90, version=1.598.94)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.94
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.94 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.95 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=95
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_ERS']/lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']:  @transition-magic=0:0;57:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=79, @rc-code=0, @op-status=0, @exec-time=60
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/91, version=1.598.95)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ERS_monitor_10000']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.95
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:41 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting ethmonitor-eth0[vmi243500]: (null) -> 1 from vmi243500
Feb 07 11:49:41 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:global_rsc_DEV_NIC action:start call_id:78 pid:2413 exit-code:0 exec-time:199ms queue-time:0ms
Feb 07 11:49:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=78 key=global_rsc_DEV_NIC_start_0 confirmed=true cib-update=47
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/47)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.95 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.96 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=96
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']:  <transient_attributes id="771304931"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                             <instance_attributes id="status-771304931">
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                               <nvpair id="status-771304931-ethmonitor-eth0" name="ethmonitor-eth0" value="1"/>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                             </instance_attributes>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	++                                           </transient_attributes>
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/5, version=1.598.96)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.96 2
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.97 (null)
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=97
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']:  @transition-magic=0:0;66:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=78, @rc-code=0, @op-status=0, @exec-time=199
Feb 07 11:49:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/47, version=1.598.97)
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_last_0']
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.97
Feb 07 11:49:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.97 2
Feb 07 11:49:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.98 (null)
Feb 07 11:49:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=98
Feb 07 11:49:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_last_0']:  @transition-magic=0:0;20:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=77, @rc-code=0, @op-status=0, @exec-time=2657
Feb 07 11:49:43 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/92, version=1.598.98)
Feb 07 11:49:43 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_last_0']
Feb 07 11:49:43 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.98
Feb 07 11:49:43 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:44 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: (null) -> green from vmi243500
Feb 07 11:49:44 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_CPU on vmi243500: 0 (ok) | call=79 key=global_rsc_DEV_CPU_monitor_10000 confirmed=false cib-update=48
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/48)
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.98 2
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.99 (null)
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=99
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_CPU']/lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']:  @transition-magic=0:0;65:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=79, @rc-code=0, @op-status=0, @exec-time=3262
Feb 07 11:49:44 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/48, version=1.598.99)
Feb 07 11:49:44 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_CPU_monitor_10000']
Feb 07 11:49:44 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.99
Feb 07 11:49:44 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 04bb249c3ae1e4f89f03ae2202046482 for 1.598.99 (0x55d324e50ac0 0)
Feb 07 11:49:49 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_database action:start call_id:38 pid:1947 exit-code:0 exec-time:8707ms queue-time:0ms
Feb 07 11:49:49 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_database on vmi243500: 0 (ok) | call=38 key=fs_DEV_database_start_0 confirmed=true cib-update=49
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/49)
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.99 2
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.100 (null)
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=100
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_last_0']:  @transition-magic=0:0;22:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=38, @rc-code=0, @op-status=0, @exec-time=8707
Feb 07 11:49:49 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/49, version=1.598.100)
Feb 07 11:49:49 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_last_0']
Feb 07 11:49:49 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.100
Feb 07 11:49:49 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:49:54 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 7fccb4c6a166733fc4cb6d4871dfe943 for 1.598.100 (0x55d324e50ac0 0)
Feb 07 11:50:01 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting runs_ers_DEV[vmi243493]: 0 -> 1 from vmi243493
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.100 2
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.101 (null)
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=101
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']/nvpair[@id='status-96317541-runs_ers_DEV']:  @value=1
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/6, version=1.598.101)
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.101 2
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.102 (null)
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=102
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']:  @transition-magic=0:0;58:3:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=80, @rc-code=0, @op-status=0, @exec-time=20636
Feb 07 11:50:01 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/93, version=1.598.102)
Feb 07 11:50:01 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_last_0']
Feb 07 11:50:01 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.102
Feb 07 11:50:01 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.102 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.103 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=103
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']:  <lrm_rsc_op id="stonith-sbd_monitor_3600000" operation_key="stonith-sbd_monitor_3600000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="6:4:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;6:4:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/95, version=1.598.103)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='stonith-sbd']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.103
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=9:4:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_database_monitor_20000
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/50)
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=10:4:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_database_start_0
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.103 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.104 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=104
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']:  <lrm_rsc_op id="rsc_DEV_ERS10_monitor_120000" operation_key="rsc_DEV_ERS10_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="46:4:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;46:4:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/96, version=1.598.104)
Feb 07 11:50:02 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_database action:start call_id:81
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=55:4:0:24d705d1-0549-478b-9776-868390dd465b op=global_rsc_DEV_NIC_monitor_10000
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/51)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/52)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ERS10']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.104
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.104 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.105 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=105
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']:  <lrm_rsc_op id="fs_DEV_database_monitor_20000" operation_key="fs_DEV_database_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="9:4:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;9:4:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_no
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_database']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.105
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/50, version=1.598.105)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.105 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.106 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=106
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @operation_key=vip_DEV_database_start_0, @operation=start, @transition-key=10:4:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;10:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695002, @last-rc-change=1612695002,
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/51, version=1.598.106)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.106 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.107 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=107
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']:  <lrm_rsc_op id="global_rsc_DEV_NIC_monitor_10000" operation_key="global_rsc_DEV_NIC_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="55:4:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;55:4:0:24d705d1-0549-478b-9776-868390dd465b" exit-reas
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/52, version=1.598.107)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.106
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='global_rsc_DEV_NIC']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.107
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_database on vmi243500: 0 (ok) | call=80 key=fs_DEV_database_monitor_20000 confirmed=false cib-update=53
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/53)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.107 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.108 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=108
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_database']/lrm_rsc_op[@id='fs_DEV_database_monitor_20000']:  @transition-magic=0:0;9:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=80, @rc-code=0, @op-status=0, @exec-time=342, @queue-time=1
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/53, version=1.598.108)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_database_monitor_20000']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.108
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for global_rsc_DEV_NIC on vmi243500: 0 (ok) | call=82 key=global_rsc_DEV_NIC_monitor_10000 confirmed=false cib-update=54
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/54)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.108 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.109 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=109
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='global_rsc_DEV_NIC']/lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']:  @transition-magic=0:0;55:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=82, @rc-code=0, @op-status=0, @exec-time=334
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/54, version=1.598.109)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='global_rsc_DEV_NIC_monitor_10000']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.109
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_database action:start call_id:81 pid:2530 exit-code:0 exec-time:434ms queue-time:0ms
Feb 07 11:50:02 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_database on vmi243500: 0 (ok) | call=81 key=vip_DEV_database_start_0 confirmed=true cib-update=55
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/55)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.109 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.110 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=110
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_last_0']:  @transition-magic=0:0;10:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=81, @rc-code=0, @op-status=0, @exec-time=434
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/55, version=1.598.110)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_last_0']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.110
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=11:4:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_database_monitor_10000
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/56)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.110 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.111 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=111
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']:  <lrm_rsc_op id="vip_DEV_database_monitor_10000" operation_key="vip_DEV_database_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="11:4:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;11:4:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" 
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/56, version=1.598.111)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_database']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.111
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=12:4:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_database_start_0
Feb 07 11:50:02 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_database action:start call_id:84
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/57)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.111 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.112 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=112
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @operation_key=rsc_DEV_database_start_0, @operation=start, @transition-key=12:4:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;12:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695002, @last-rc-change=1612695002,
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/57, version=1.598.112)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.112
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.112 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.113 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=113
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_ERS10']/lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']:  @transition-magic=0:0;46:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=82, @rc-code=0, @op-status=0, @exec-time=641
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/97, version=1.598.113)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ERS10_monitor_120000']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.113
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:02 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_database on vmi243500: 0 (ok) | call=83 key=vip_DEV_database_monitor_10000 confirmed=false cib-update=58
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/58)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.113 2
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.114 (null)
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=114
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_database']/lrm_rsc_op[@id='vip_DEV_database_monitor_10000']:  @transition-magic=0:0;11:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=83, @rc-code=0, @op-status=0, @exec-time=222
Feb 07 11:50:02 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/58, version=1.598.114)
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_database_monitor_10000']
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.114
Feb 07 11:50:02 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:04 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.114 2
Feb 07 11:50:04 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.115 (null)
Feb 07 11:50:04 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=115
Feb 07 11:50:04 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='stonith-sbd']/lrm_rsc_op[@id='stonith-sbd_monitor_3600000']:  @transition-magic=0:0;6:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=81, @rc-code=0, @op-status=0, @last-rc-change=1612695002, @exec-time=2886
Feb 07 11:50:04 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/98, version=1.598.115)
Feb 07 11:50:04 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='stonith-sbd_monitor_3600000']
Feb 07 11:50:04 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.115
Feb 07 11:50:04 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:50:08 [1679] vmi243500       crmd:     info: crm_procfs_pid_of:	Found cib active as process 1674
Feb 07 11:50:08 [1679] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was ffffffff)
Feb 07 11:50:09 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 86db75f17ae91798fa91b7377de87d33 for 1.598.115 (0x55d324e50ac0 0)
Feb 07 11:50:14 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.115 2
Feb 07 11:50:14 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.116 (null)
Feb 07 11:50:14 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=116
Feb 07 11:50:14 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-.health-cpu" name="#health-cpu" value="green"/>
Feb 07 11:50:14 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/7, version=1.598.116)
Feb 07 11:50:19 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 1212c3479c85d0bf1be5755e267e5719 for 1.598.116 (0x55d324e50ac0 0)
Feb 07 11:52:10 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 11:52:23 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 11:52:36 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 11:52:49 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 11:53:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/8, version=1.598.116)
Feb 07 11:53:24 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 1212c3479c85d0bf1be5755e267e5719 for 1.598.116 (0x55d324e50ac0 0)
Feb 07 11:57:40 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_database action:start call_id:84 pid:2675 exit-code:0 exec-time:457566ms queue-time:0ms
Feb 07 11:57:40 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_database on vmi243500: 0 (ok) | call=84 key=rsc_DEV_database_start_0 confirmed=true cib-update=59
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/59)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.116 2
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.117 (null)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=117
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_last_0']:  @transition-magic=0:0;12:4:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=84, @rc-code=0, @op-status=0, @exec-time=457566
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/59, version=1.598.117)
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_last_0']
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.117
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=17:5:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_database_monitor_120000
Feb 07 11:57:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=66:5:0:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_start_0
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.117 2
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.118 (null)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=118
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=58:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;58:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695460, @last-rc-change=16
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/100, version=1.598.118)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/60)
Feb 07 11:57:40 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:start call_id:86
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/61)
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.118
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.118 2
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.119 (null)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=119
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']:  <lrm_rsc_op id="rsc_DEV_database_monitor_120000" operation_key="rsc_DEV_database_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="17:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;17:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/60, version=1.598.119)
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_database']
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.119
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.119 2
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.120 (null)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=120
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @transition-key=66:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;66:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695460, @last-rc-change=1612695460, @exec-time=0
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/61, version=1.598.120)
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.120
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:40 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_database on vmi243500: 0 (ok) | call=85 key=rsc_DEV_database_monitor_120000 confirmed=false cib-update=62
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/62)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.120 2
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.121 (null)
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=121
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_database']/lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']:  @transition-magic=0:0;17:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=85, @rc-code=0, @op-status=0, @exec-time=62
Feb 07 11:57:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/62, version=1.598.121)
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_database_monitor_120000']
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.121
Feb 07 11:57:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:start call_id:86 pid:9586 exit-code:0 exec-time:1110ms queue-time:0ms
Feb 07 11:57:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for dlm_DEV on vmi243500: 0 (ok) | call=86 key=dlm_DEV_start_0 confirmed=true cib-update=63
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/63)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.121 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.122 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=122
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;66:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=86, @rc-code=0, @op-status=0, @exec-time=1110
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/63, version=1.598.122)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.122
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=67:5:0:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_monitor_60000
Feb 07 11:57:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=68:5:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_start_0
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/64)
Feb 07 11:57:41 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:start call_id:88
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/65)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.122 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.123 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=123
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']:  <lrm_rsc_op id="dlm_DEV_monitor_60000" operation_key="dlm_DEV_monitor_60000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="67:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;67:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/64, version=1.598.123)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.123 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.124 (null)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='dlm_DEV']
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=124
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.123
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @transition-key=68:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;68:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695461, @last-rc-change=1612695461, @exec-ti
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/65, version=1.598.124)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.124
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: 0 (ok) | call=87 key=dlm_DEV_monitor_60000 confirmed=false cib-update=66
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/66)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.124 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.125 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=125
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;67:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=87, @rc-code=0, @op-status=0, @exec-time=45
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/66, version=1.598.125)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.125
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.125 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.126 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=126
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;58:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=83, @rc-code=0, @op-status=0, @exec-time=1246
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/101, version=1.598.126)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.126
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.126 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.127 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=127
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']:  <lrm_rsc_op id="dlm_DEV_monitor_60000" operation_key="dlm_DEV_monitor_60000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="59:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;59:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id="
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/102, version=1.598.127)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='dlm_DEV']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.127
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.127 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.128 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=128
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=60:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;60:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695461, 
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/103, version=1.598.128)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.128
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.128 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.129 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=129
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;59:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=84, @rc-code=0, @op-status=0, @exec-time=38
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/104, version=1.598.129)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.129
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:start call_id:88 pid:9726 exit-code:0 exec-time:264ms queue-time:0ms
Feb 07 11:57:41 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=88 key=fs_DEV_sapmnt_start_0 confirmed=true cib-update=67
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/67)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.129 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.130 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=130
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;68:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=88, @rc-code=0, @op-status=0, @exec-time=264
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/67, version=1.598.130)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.130
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=69:5:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_monitor_20000
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/68)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.130 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.131 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=131
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']:  <lrm_rsc_op id="fs_DEV_sapmnt_monitor_20000" operation_key="fs_DEV_sapmnt_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="69:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;69:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/68, version=1.598.131)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_sapmnt']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.131
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:41 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=89 key=fs_DEV_sapmnt_monitor_20000 confirmed=false cib-update=69
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/69)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.131 2
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.132 (null)
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=132
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;69:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=89, @rc-code=0, @op-status=0, @exec-time=50
Feb 07 11:57:41 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/69, version=1.598.132)
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.132
Feb 07 11:57:41 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.132 2
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.133 (null)
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=133
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;60:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=85, @rc-code=0, @op-status=0, @exec-time=1134
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/105, version=1.598.133)
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.133
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:42 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=22:5:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_ASCS_start_0
Feb 07 11:57:42 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_ASCS action:start call_id:90
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.133 2
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.134 (null)
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=134
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']:  <lrm_rsc_op id="fs_DEV_sapmnt_monitor_20000" operation_key="fs_DEV_sapmnt_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="61:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;61:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vm
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/106, version=1.598.134)
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/70)
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_sapmnt']
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.134
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.134 2
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.135 (null)
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=135
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @operation_key=fs_DEV_ASCS_start_0, @operation=start, @transition-key=22:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;22:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695462, @last-rc-change=1612695462, @exec-time=0
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/70, version=1.598.135)
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.135
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.135 2
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.136 (null)
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=136
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;61:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=86, @rc-code=0, @op-status=0, @exec-time=109
Feb 07 11:57:42 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/107, version=1.598.136)
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.136
Feb 07 11:57:42 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_ASCS action:start call_id:90 pid:9907 exit-code:0 exec-time:2885ms queue-time:0ms
Feb 07 11:57:45 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=90 key=fs_DEV_ASCS_start_0 confirmed=true cib-update=71
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/71)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.136 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.137 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=137
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_last_0']:  @transition-magic=0:0;22:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=90, @rc-code=0, @op-status=0, @exec-time=2885
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/71, version=1.598.137)
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_last_0']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.137
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=23:5:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_ASCS_monitor_20000
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/72)
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=24:5:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_ASCS_start_0
Feb 07 11:57:45 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_ASCS action:start call_id:92
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.137 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.138 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=138
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']:  <lrm_rsc_op id="fs_DEV_ASCS_monitor_20000" operation_key="fs_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="23:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;23:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_ASCS']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.138
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/72, version=1.598.138)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/73)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.138 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.139 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=139
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @operation_key=vip_DEV_ASCS_start_0, @operation=start, @transition-key=24:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;24:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695465, @last-rc-change=1612695465, @exec-time=
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.139
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/73, version=1.598.139)
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_ASCS on vmi243500: 0 (ok) | call=91 key=fs_DEV_ASCS_monitor_20000 confirmed=false cib-update=74
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/74)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.139 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.140 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=140
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_ASCS']/lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;23:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=91, @rc-code=0, @op-status=0, @exec-time=57
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/74, version=1.598.140)
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_ASCS_monitor_20000']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.140
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_ASCS action:start call_id:92 pid:10082 exit-code:0 exec-time:120ms queue-time:0ms
Feb 07 11:57:45 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=92 key=vip_DEV_ASCS_start_0 confirmed=true cib-update=75
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/75)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.140 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.141 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=141
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_last_0']:  @transition-magic=0:0;24:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=92, @rc-code=0, @op-status=0, @exec-time=120
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/75, version=1.598.141)
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_last_0']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.141
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=25:5:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_ASCS_monitor_10000
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/76)
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=26:5:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_ASCS00_start_0
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/77)
Feb 07 11:57:45 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_ASCS00 action:start call_id:94
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.141 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.142 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=142
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']:  <lrm_rsc_op id="vip_DEV_ASCS_monitor_10000" operation_key="vip_DEV_ASCS_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="25:5:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;25:5:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/76, version=1.598.142)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.142 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.143 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=143
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @operation_key=rsc_DEV_ASCS00_start_0, @operation=start, @transition-key=26:5:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;26:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695465, @last-rc-change=1612695465, @exec
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_ASCS']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.142
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/77, version=1.598.143)
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.143
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:45 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_ASCS on vmi243500: 0 (ok) | call=93 key=vip_DEV_ASCS_monitor_10000 confirmed=false cib-update=78
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/78)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.143 2
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.598.144 (null)
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=144
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_ASCS']/lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']:  @transition-magic=0:0;25:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=93, @rc-code=0, @op-status=0, @exec-time=60
Feb 07 11:57:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/78, version=1.598.144)
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_ASCS_monitor_10000']
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.598.144
Feb 07 11:57:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.598.144 2
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.0 8ed219e3ee62977c4b36fb7cf0b8be76
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/configuration/resources/clone[@id='cl-storage']/group[@id='grp_DEV_storage_dlm']/primitive[@id='dlm_DEV']/meta_attributes[@id='dlm_DEV-meta_attributes']
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/configuration/resources/clone[@id='cl-storage']/group[@id='grp_DEV_storage_dlm']/primitive[@id='fs_DEV_sapmnt']/meta_attributes[@id='fs_DEV_sapmnt-meta_attributes']
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=599, @num_updates=0
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/clone[@id='cl-storage']/meta_attributes[@id='cl-storage-meta_attributes']/nvpair[@id='cl-storage-meta_attributes-target-role']:  @value=Stopped
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.599.0)
Feb 07 11:57:48 [1675] vmi243500 stonith-ng:     info: stonith_device_remove:	Device 'dlm_DEV' not found (1 active devices)
Feb 07 11:57:48 [1675] vmi243500 stonith-ng:     info: stonith_device_remove:	Device 'fs_DEV_sapmnt' not found (1 active devices)
Feb 07 11:57:48 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='cl-storage-meta_attributes-target-role']
Feb 07 11:57:48 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.0
Feb 07 11:57:48 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-39.raw
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.599.0 of the CIB to disk (digest: 61118b518503d726af7cd829592c91dc)
Feb 07 11:57:48 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.GNbnKA (digest: /var/lib/pacemaker/cib/cib.Efx6nN)
Feb 07 11:57:53 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 8ed219e3ee62977c4b36fb7cf0b8be76 for 1.599.0 (0x55d324e43210 0)
Feb 07 11:58:17 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_ASCS00 action:start call_id:94 pid:10195 exit-code:0 exec-time:32071ms queue-time:0ms
Feb 07 11:58:17 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=94 key=rsc_DEV_ASCS00_start_0 confirmed=true cib-update=79
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/79)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.0 2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.1 (null)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']:  @transition-magic=0:0;26:5:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=94, @rc-code=0, @op-status=0, @exec-time=32071
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/79, version=1.599.1)
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_last_0']
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.1
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:17 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=34:6:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_ASCS00_monitor_120000
Feb 07 11:58:17 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=35:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_2_DEV_ASCS_start_0
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.1 2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.2 (null)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_stop_0, @operation=stop, @transition-key=66:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;66:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695497, @last-rc-change=1612695497, @exec-time=0
Feb 07 11:58:17 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_2_DEV_ASCS action:start call_id:96
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/109, version=1.599.2)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/80)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/81)
Feb 07 11:58:17 [1676] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_sapmnt_monitor_20000
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.2
Feb 07 11:58:17 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=72:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_stop_0
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:17 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:stop call_id:98
Feb 07 11:58:17 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: Cancelled | call=89 key=fs_DEV_sapmnt_monitor_20000 confirmed=true
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/82)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.2 2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.3 (null)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']:  <lrm_rsc_op id="rsc_DEV_ASCS00_monitor_120000" operation_key="rsc_DEV_ASCS00_monitor_120000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="34:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;34:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_n
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/80, version=1.599.3)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.3 2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.4 (null)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @operation_key=fs_2_DEV_ASCS_start_0, @operation=start, @transition-key=35:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;35:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695497, @last-rc-change=1612695497, @exec-ti
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/81, version=1.599.4)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.4 2
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.5 (null)
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_stop_0, @operation=stop, @transition-key=72:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;72:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695497, @last-rc-change=1612695497, @exec-time
Feb 07 11:58:17 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/82, version=1.599.5)
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='rsc_DEV_ASCS00']
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.3
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.4
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.5
Feb 07 11:58:17 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:18 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for rsc_DEV_ASCS00 on vmi243500: 0 (ok) | call=95 key=rsc_DEV_ASCS00_monitor_120000 confirmed=false cib-update=83
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/83)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.5 2
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.6 (null)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_ASCS00']/lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']:  @transition-magic=0:0;34:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=95, @rc-code=0, @op-status=0, @exec-time=236
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/83, version=1.599.6)
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_ASCS00_monitor_120000']
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.6
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:18 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_2_DEV_ASCS action:start call_id:96 pid:11514 exit-code:0 exec-time:1034ms queue-time:0ms
Feb 07 11:58:18 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=96 key=fs_2_DEV_ASCS_start_0 confirmed=true cib-update=84
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/84)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.6 2
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.7 (null)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']:  @transition-magic=0:0;35:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=96, @rc-code=0, @op-status=0, @exec-time=1034
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/84, version=1.599.7)
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_last_0']
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.7
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:18 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=36:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_2_DEV_ASCS_monitor_20000
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/85)
Feb 07 11:58:18 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=37:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_3_DEV_ASCS_start_0
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/86)
Feb 07 11:58:18 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_3_DEV_ASCS action:start call_id:100
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.7 2
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.8 (null)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']:  <lrm_rsc_op id="fs_2_DEV_ASCS_monitor_20000" operation_key="fs_2_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="36:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;36:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/85, version=1.599.8)
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_2_DEV_ASCS']
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.8
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.8 2
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.9 (null)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @operation_key=fs_3_DEV_ASCS_start_0, @operation=start, @transition-key=37:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;37:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695498, @last-rc-change=1612695498, @exec-ti
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/86, version=1.599.9)
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.9
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:18 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_2_DEV_ASCS on vmi243500: 0 (ok) | call=99 key=fs_2_DEV_ASCS_monitor_20000 confirmed=false cib-update=87
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/87)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.9 2
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.10 (null)
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_2_DEV_ASCS']/lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;36:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=99, @rc-code=0, @op-status=0, @exec-time=66, @queue-time=1
Feb 07 11:58:18 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/87, version=1.599.10)
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_2_DEV_ASCS_monitor_20000']
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.10
Feb 07 11:58:18 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:19 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_3_DEV_ASCS action:start call_id:100 pid:11787 exit-code:0 exec-time:995ms queue-time:1ms
Feb 07 11:58:19 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=100 key=fs_3_DEV_ASCS_start_0 confirmed=true cib-update=88
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/88)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.10 2
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.11 (null)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']:  @transition-magic=0:0;37:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=100, @rc-code=0, @op-status=0, @exec-time=995, @queue-time=1
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/88, version=1.599.11)
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_last_0']
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.11
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:19 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=38:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_3_DEV_ASCS_monitor_20000
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/89)
Feb 07 11:58:19 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=43:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_start_0
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/90)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.11 2
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.12 (null)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']:  <lrm_rsc_op id="fs_3_DEV_ASCS_monitor_20000" operation_key="fs_3_DEV_ASCS_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="38:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;38:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="
Feb 07 11:58:19 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:start call_id:102
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/89, version=1.599.12)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.12 2
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.13 (null)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @transition-key=43:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;43:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695499, @last-rc-change=1612695499, @exec-time=0
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/90, version=1.599.13)
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_3_DEV_ASCS']
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.12
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.13
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:19 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_3_DEV_ASCS on vmi243500: 0 (ok) | call=101 key=fs_3_DEV_ASCS_monitor_20000 confirmed=false cib-update=91
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/91)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.13 2
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.14 (null)
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_3_DEV_ASCS']/lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']:  @transition-magic=0:0;38:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=101, @rc-code=0, @op-status=0, @exec-time=50
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_3_DEV_ASCS_monitor_20000']
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.14
Feb 07 11:58:19 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/91, version=1.599.14)
Feb 07 11:58:20 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:stop call_id:98 pid:11515 exit-code:0 exec-time:2331ms queue-time:0ms
Feb 07 11:58:20 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=98 key=fs_DEV_sapmnt_stop_0 confirmed=true cib-update=92
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/92)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.14 2
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.15 (null)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;72:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=98, @rc-code=0, @op-status=0, @exec-time=2331
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/92, version=1.599.15)
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.15
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:20 [1676] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation dlm_DEV_monitor_60000
Feb 07 11:58:20 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=71:6:0:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_stop_0
Feb 07 11:58:20 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:stop call_id:104
Feb 07 11:58:20 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: Cancelled | call=87 key=dlm_DEV_monitor_60000 confirmed=true
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/93)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.15 2
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.16 (null)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_stop_0, @operation=stop, @transition-key=71:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;71:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695500, @last-rc-change=1612695500, @exec-time=0
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/93, version=1.599.16)
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.16
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.16 2
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.17 (null)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;66:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=88, @rc-code=0, @op-status=0, @exec-time=2546
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/110, version=1.599.17)
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.17
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.17 2
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.18 (null)
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_stop_0, @operation=stop, @transition-key=65:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;65:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695500, @last-rc-change=1612695500, @exec-time=0
Feb 07 11:58:20 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/111, version=1.599.18)
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.18
Feb 07 11:58:20 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:21 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:stop call_id:104 pid:12039 exit-code:0 exec-time:1046ms queue-time:0ms
Feb 07 11:58:21 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for dlm_DEV on vmi243500: 0 (ok) | call=104 key=dlm_DEV_stop_0 confirmed=true cib-update=94
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/94)
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.18 2
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.19 (null)
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;71:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=104, @rc-code=0, @op-status=0, @exec-time=1046
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/94, version=1.599.19)
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.19
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.19 2
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.20 (null)
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;65:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=90, @rc-code=0, @op-status=0, @exec-time=1043
Feb 07 11:58:21 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/112, version=1.599.20)
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.20
Feb 07 11:58:21 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:start call_id:102 pid:11917 exit-code:0 exec-time:3763ms queue-time:0ms
Feb 07 11:58:23 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_CI on vmi243500: 0 (ok) | call=102 key=fs_DEV_CI_start_0 confirmed=true cib-update=95
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/95)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.20 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.21 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;43:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=102, @rc-code=0, @op-status=0, @exec-time=3763
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/95, version=1.599.21)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.21
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=44:6:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_monitor_20000
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/96)
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=45:6:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_start_0
Feb 07 11:58:23 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:start call_id:106
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.21 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.22 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']:  <lrm_rsc_op id="fs_DEV_CI_monitor_20000" operation_key="fs_DEV_CI_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="44:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;44:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" c
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/96, version=1.599.22)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/97)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_CI']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.22
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.22 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.23 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @transition-key=45:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;45:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695503, @last-rc-change=1612695503, @exec-time=0
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/97, version=1.599.23)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.23
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: 0 (ok) | call=105 key=fs_DEV_CI_monitor_20000 confirmed=false cib-update=98
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/98)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.23 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.24 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;44:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=105, @rc-code=0, @op-status=0, @exec-time=69
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/98, version=1.599.24)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.24
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:start call_id:106 pid:12181 exit-code:0 exec-time:127ms queue-time:0ms
Feb 07 11:58:23 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_CI on vmi243500: 0 (ok) | call=106 key=vip_DEV_CI_start_0 confirmed=true cib-update=99
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/99)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.24 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.25 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;45:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=106, @rc-code=0, @op-status=0, @exec-time=127
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/99, version=1.599.25)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.25
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=46:6:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_monitor_10000
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=47:6:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_start_0
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/100)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/101)
Feb 07 11:58:23 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:108
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.25 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.26 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']:  <lrm_rsc_op id="vip_DEV_CI_monitor_10000" operation_key="vip_DEV_CI_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="46:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;46:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/100, version=1.599.26)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.26 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.27 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @transition-key=47:6:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;47:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695503, @last-rc-change=1612695503, @exec-time=0
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_CI']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.26
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/101, version=1.599.27)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.27
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:23 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: 0 (ok) | call=107 key=vip_DEV_CI_monitor_10000 confirmed=false cib-update=102
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/102)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.27 2
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.28 (null)
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;46:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=107, @rc-code=0, @op-status=0, @exec-time=69
Feb 07 11:58:23 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/102, version=1.599.28)
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.28
Feb 07 11:58:23 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:25 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:108 pid:12295 exit-code:6 exec-time:1522ms queue-time:0ms
Feb 07 11:58:25 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: 6 (not configured) | call=108 key=rsc_DEV_CI_start_0 confirmed=true cib-update=103
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/103)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.28 2
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.29 (null)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:6;47:6:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=108, @rc-code=6, @op-status=0, @exec-time=1522
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="47:6:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:6;47:6:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id=
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/103, version=1.599.29)
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.29
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: (null) -> INFINITY from vmi243493
Feb 07 11:58:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: (null) -> 1612695505 from vmi243493
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.29 2
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.30 (null)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/9, version=1.599.30)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.30 2
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.31 (null)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1612695505"/>
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/10, version=1.599.31)
Feb 07 11:58:25 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=14:8:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_stop_0
Feb 07 11:58:25 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:stop call_id:109
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/104)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.31 2
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.32 (null)
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=14:8:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;14:8:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695505, @last-rc-change=1612695505, @exec-time=0
Feb 07 11:58:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/104, version=1.599.32)
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.32
Feb 07 11:58:25 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:26 [1676] vmi243500       lrmd:   notice: operation_finished:	rsc_DEV_CI_stop_0:12470:stderr [ cleanipc: Command not found. ]
Feb 07 11:58:26 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:stop call_id:109 pid:12470 exit-code:0 exec-time:1397ms queue-time:0ms
Feb 07 11:58:26 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=109 key=rsc_DEV_CI_stop_0 confirmed=true cib-update=105
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/105)
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.32 2
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.599.33 (null)
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;14:8:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=109, @rc-code=0, @op-status=0, @exec-time=1397
Feb 07 11:58:26 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/105, version=1.599.33)
Feb 07 11:58:26 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 11:58:26 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.599.33
Feb 07 11:58:26 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:31 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 19427324eb8954fb1e23f4f495a07218 for 1.599.33 (0x55d324e43210 0)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_apply_diff operation for section 'all' to all (origin=local/cibadmin/2)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.599.33 2
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.0 (null)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=600, @num_updates=0
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/resources/clone[@id='cl-storage']/meta_attributes[@id='cl-storage-meta_attributes']/nvpair[@id='cl-storage-meta_attributes-target-role']:  @value=Started
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_apply_diff operation for section 'all': OK (rc=0, origin=vmi243500/cibadmin/2, version=1.600.0)
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify nvpair[@id='cl-storage-meta_attributes-target-role']
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.0
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-40.raw
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.600.0 of the CIB to disk (digest: d5bd79af4b66dc32e584b5f9d9f441ab)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.9L0tcc (digest: /var/lib/pacemaker/cib/cib.vSS5k6)
Feb 07 11:58:32 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=71:9:0:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_start_0
Feb 07 11:58:32 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:dlm_DEV action:start call_id:110
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.0 2
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.1 (null)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @transition-key=63:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;63:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695512, @last-rc-change=1612695512, @exec-time=0
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.1
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/117, version=1.600.1)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/106)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.1 2
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.2 (null)
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @operation_key=dlm_DEV_start_0, @operation=start, @transition-key=71:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;71:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695512, @last-rc-change=1612695512, @exec-time=0
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.2
Feb 07 11:58:32 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:32 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/106, version=1.600.2)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.2 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.3 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;63:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=91, @rc-code=0, @op-status=0, @exec-time=1081
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/118, version=1.600.3)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.3 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.4 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-key=64:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;64:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612695513, @exec-time=0
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/119, version=1.600.4)
Feb 07 11:58:33 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:dlm_DEV action:start call_id:110 pid:13077 exit-code:0 exec-time:1080ms queue-time:0ms
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.3
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.4
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for dlm_DEV on vmi243500: 0 (ok) | call=110 key=dlm_DEV_start_0 confirmed=true cib-update=107
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/107)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.4 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.5 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @transition-key=65:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;65:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695513, @last-rc-change=1612695513, @exec-time
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/120, version=1.600.5)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.5
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.5 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.6 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_last_0']:  @transition-magic=0:0;71:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=110, @rc-code=0, @op-status=0, @exec-time=1080
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/107, version=1.600.6)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.6
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=72:9:0:24d705d1-0549-478b-9776-868390dd465b op=dlm_DEV_monitor_60000
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/108)
Feb 07 11:58:33 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=73:9:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_start_0
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/109)
Feb 07 11:58:33 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_sapmnt action:start call_id:112
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.6 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.7 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-key=72:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;72:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612695513, @exec-time=0
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/108, version=1.600.7)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.7
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.7 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.8 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @operation_key=fs_DEV_sapmnt_start_0, @operation=start, @transition-key=73:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;73:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612695513, @last-rc-change=1612695513, @exec-ti
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/109, version=1.600.8)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.8
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.8 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.9 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;64:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=92, @rc-code=0, @op-status=0, @exec-time=65
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/121, version=1.600.9)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.9
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for dlm_DEV on vmi243500: 0 (ok) | call=111 key=dlm_DEV_monitor_60000 confirmed=false cib-update=110
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/110)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.9 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.10 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='dlm_DEV']/lrm_rsc_op[@id='dlm_DEV_monitor_60000']:  @transition-magic=0:0;72:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=111, @rc-code=0, @op-status=0, @exec-time=55
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/110, version=1.600.10)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='dlm_DEV_monitor_60000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.10
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_sapmnt action:start call_id:112 pid:13176 exit-code:0 exec-time:225ms queue-time:0ms
Feb 07 11:58:33 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=112 key=fs_DEV_sapmnt_start_0 confirmed=true cib-update=111
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/111)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.10 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.11 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;73:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=112, @rc-code=0, @op-status=0, @exec-time=225
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/111, version=1.600.11)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.11
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=74:9:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_sapmnt_monitor_20000
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/112)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.11 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.12 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-key=74:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;74:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612695513, @exec-time=0
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/112, version=1.600.12)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.12
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_sapmnt on vmi243500: 0 (ok) | call=113 key=fs_DEV_sapmnt_monitor_20000 confirmed=false cib-update=113
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/113)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.12 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.13 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;74:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=113, @rc-code=0, @op-status=0, @exec-time=81
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/113, version=1.600.13)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.13
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.13 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.14 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']:  @transition-magic=0:0;65:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=93, @rc-code=0, @op-status=0, @exec-time=593
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/122, version=1.600.14)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_last_0']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.14
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.14 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.15 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-key=66:9:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;66:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612695513, @exec-time=0
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/123, version=1.600.15)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.15
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.15 2
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.16 (null)
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_sapmnt']/lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']:  @transition-magic=0:0;66:9:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=94, @rc-code=0, @op-status=0, @exec-time=74
Feb 07 11:58:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/124, version=1.600.16)
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_sapmnt_monitor_20000']
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.16
Feb 07 11:58:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 11:58:38 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: b17c9124bb02102d3a6fbf4f88d35875 for 1.600.16 (0x55d324da9cc0 0)
Feb 07 13:08:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: 1612695505 -> (null) from vmi243500
Feb 07 13:08:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: INFINITY -> (null) from vmi243500
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/114)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.16 2
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.17 cf8030c8de04881787067b730f41011a
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/114, version=1.600.16)
Feb 07 13:08:25 [1679] vmi243500       crmd:     info: delete_resource:	Removing resource rsc_DEV_CI for e7acf00f-decb-4c72-b7ec-396a49eeea1c (hacluster) on vmi243500
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.16 2
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.17 (null)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-last-failure-rsc_DEV_CI.start_0']
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Feb 07 13:08:25 [1679] vmi243500       crmd:     info: notify_deleted:	Notifying e7acf00f-decb-4c72-b7ec-396a49eeea1c on vmi243500 that rsc_DEV_CI was deleted
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/11, version=1.600.17)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI'] to all (origin=local/crmd/115)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.17 2
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.600.18 (null)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_delete operation for section //node_state[@uname='vmi243500']//lrm_resource[@id='rsc_DEV_CI']: OK (rc=0, origin=vmi243500/crmd/115, version=1.600.18)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section crm_config to all (origin=local/crmd/117)
Feb 07 13:08:25 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: delete lrm_resource[@id='rsc_DEV_CI']
Feb 07 13:08:25 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.600.18
Feb 07 13:08:25 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.600.18 2
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.0 (null)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @epoch=601, @num_updates=0
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/configuration/crm_config/cluster_property_set[@id='cib-bootstrap-options']/nvpair[@id='cib-bootstrap-options-last-lrm-refresh']:  @value=1612699705
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section crm_config: OK (rc=0, origin=vmi243500/crmd/117, version=1.601.0)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.0 2
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.1 (null)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	-- /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']/nvpair[@id='status-771304931-fail-count-rsc_DEV_CI.start_0']
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=1
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/12, version=1.601.1)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_file_backup:	Archived previous version as /var/lib/pacemaker/cib/cib-41.raw
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Wrote version 1.601.0 of the CIB to disk (digest: 6c8ec62f931331fc88711d047f98801c)
Feb 07 13:08:25 [1674] vmi243500        cib:     info: cib_file_write_with_digest:	Reading cluster configuration file /var/lib/pacemaker/cib/cib.KfdOR3 (digest: /var/lib/pacemaker/cib/cib.dMXH1n)
Feb 07 13:08:26 [1676] vmi243500       lrmd:     info: process_lrmd_get_rsc_info:	Resource 'rsc_DEV_CI' not found (17 active resources)
Feb 07 13:08:26 [1676] vmi243500       lrmd:     info: process_lrmd_rsc_register:	Added 'rsc_DEV_CI' to the rsc list (18 active resources)
Feb 07 13:08:26 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=21:14:7:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_monitor_0
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/119)
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.1 2
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.2 (null)
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=2
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources:  <lrm_resource id="rsc_DEV_CI" type="SAPInstance" class="ocf" provider="heartbeat"/>
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                                <lrm_rsc_op id="rsc_DEV_CI_last_0" operation_key="rsc_DEV_CI_monitor_0" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="21:14:7:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;21:14:7:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-id="-1" rc-code="193" op-status
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_perform_op:	++                                                                              </lrm_resource>
Feb 07 13:08:26 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/119, version=1.601.2)
Feb 07 13:08:26 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resources
Feb 07 13:08:26 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.2
Feb 07 13:08:26 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:08:31 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 01ab06d4efe6b1250de48d7f9f4646a1 for 1.601.2 (0x55d324c955f0 0)
Feb 07 13:08:40 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of probe operation for rsc_DEV_CI on vmi243500: 7 (not running) | call=118 key=rsc_DEV_CI_monitor_0 confirmed=true cib-update=120
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/120)
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.2 2
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.3 (null)
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=3
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;21:14:7:24d705d1-0549-478b-9776-868390dd465b, @call-id=118, @rc-code=7, @op-status=0, @exec-time=13770
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/120, version=1.601.3)
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.3
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:08:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=52:14:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_start_0
Feb 07 13:08:40 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:start call_id:119
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/121)
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.3 2
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.4 (null)
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=4
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @transition-key=52:14:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;52:14:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699720, @last-rc-change=1612699720, @exec-time=0
Feb 07 13:08:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/121, version=1.601.4)
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.4
Feb 07 13:08:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:08:45 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 662d711f688b09e93f6688fa6282804e for 1.601.4 (0x55d324c955f0 0)
Feb 07 13:09:10 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> red from vmi243500
Feb 07 13:09:23 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: red -> yellow from vmi243500
Feb 07 13:09:37 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 13:10:03 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 13:10:16 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 13:10:30 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 13:10:43 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 13:10:56 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 13:11:08 [1679] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 11.600000
Feb 07 13:11:08 [1679] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0010 (was 0000)
Feb 07 13:11:23 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 13:11:36 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: green -> yellow from vmi243500
Feb 07 13:11:38 [1679] vmi243500       crmd:     info: throttle_check_thresholds:	Moderate CPU load detected: 10.660000
Feb 07 13:11:40 [1676] vmi243500       lrmd:  warning: child_timeout_callback:	rsc_DEV_CI_start_0 process (PID 12820) timed out
Feb 07 13:11:40 [1676] vmi243500       lrmd:  warning: operation_finished:	rsc_DEV_CI_start_0:12820 - timed out after 180000ms
Feb 07 13:11:40 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:start call_id:119 pid:12820 exit-code:1 exec-time:180002ms queue-time:0ms
Feb 07 13:11:40 [1679] vmi243500       crmd:    error: process_lrm_event:	Result of start operation for rsc_DEV_CI on vmi243500: Timed Out | call=119 key=rsc_DEV_CI_start_0 timeout=180000ms
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/122)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.4 2
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.5 (null)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=5
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=2:1;52:14:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=119, @rc-code=1, @op-status=2, @exec-time=180002
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="52:14:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="2:1;52:14:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243500" call-i
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/122, version=1.601.5)
Feb 07 13:11:40 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243500]: (null) -> INFINITY from vmi243493
Feb 07 13:11:40 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243500]: (null) -> 1612699900 from vmi243493
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.5
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.5 2
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.6 (null)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=6
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/13, version=1.601.6)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.6 2
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.7 (null)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=7
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='771304931']/transient_attributes[@id='771304931']/instance_attributes[@id='status-771304931']:  <nvpair id="status-771304931-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1612699900"/>
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/14, version=1.601.7)
Feb 07 13:11:40 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=20:16:0:24d705d1-0549-478b-9776-868390dd465b op=rsc_DEV_CI_stop_0
Feb 07 13:11:40 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:rsc_DEV_CI action:stop call_id:120
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/123)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.7 2
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.8 (null)
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=8
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=20:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;20:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699900, @last-rc-change=1612699900, @exec-time=0
Feb 07 13:11:40 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/123, version=1.601.8)
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.8
Feb 07 13:11:40 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:11:45 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 057834bb2d18825960bab9761ea6fb13 for 1.601.8 (0x55d324c955f0 0)
Feb 07 13:11:49 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting #health-cpu[vmi243500]: yellow -> green from vmi243500
Feb 07 13:12:08 [1679] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0001 (was 0010)
Feb 07 13:12:19 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/15, version=1.601.8)
Feb 07 13:12:24 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 057834bb2d18825960bab9761ea6fb13 for 1.601.8 (0x55d324c955f0 0)
Feb 07 13:12:31 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:rsc_DEV_CI action:stop call_id:120 pid:19394 exit-code:0 exec-time:51284ms queue-time:0ms
Feb 07 13:12:31 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for rsc_DEV_CI on vmi243500: 0 (ok) | call=120 key=rsc_DEV_CI_stop_0 confirmed=true cib-update=124
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/124)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.8 2
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.9 (null)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=9
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;20:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=120, @rc-code=0, @op-status=0, @exec-time=51284
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/124, version=1.601.9)
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.9
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:31 [1676] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation vip_DEV_CI_monitor_10000
Feb 07 13:12:31 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=51:16:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_stop_0
Feb 07 13:12:31 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:stop call_id:122
Feb 07 13:12:31 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: Cancelled | call=107 key=vip_DEV_CI_monitor_10000 confirmed=true
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/125)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.9 2
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.10 (null)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=10
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_stop_0, @operation=stop, @transition-key=51:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;51:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699951, @last-rc-change=1612699951, @exec-time=0
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/125, version=1.601.10)
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.10
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:31 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:stop call_id:122 pid:21651 exit-code:0 exec-time:70ms queue-time:0ms
Feb 07 13:12:31 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for vip_DEV_CI on vmi243500: 0 (ok) | call=122 key=vip_DEV_CI_stop_0 confirmed=true cib-update=126
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/126)
Feb 07 13:12:31 [1676] vmi243500       lrmd:     info: cancel_recurring_action:	Cancelling ocf operation fs_DEV_CI_monitor_20000
Feb 07 13:12:31 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=48:16:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_stop_0
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.10 2
Feb 07 13:12:31 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:stop call_id:124
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.11 (null)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=11
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;51:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=122, @rc-code=0, @op-status=0, @exec-time=70
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/126, version=1.601.11)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/127)
Feb 07 13:12:31 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: Cancelled | call=105 key=fs_DEV_CI_monitor_20000 confirmed=true
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.11
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.11 2
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.12 (null)
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=12
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_stop_0, @operation=stop, @transition-key=48:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;48:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699951, @last-rc-change=1612699951, @exec-time=0
Feb 07 13:12:31 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/127, version=1.601.12)
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.12
Feb 07 13:12:31 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1676] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:21705:stderr [ umount: /usr/sap/DEV/DVEBMGS01: target is busy. ]
Feb 07 13:12:33 [1676] vmi243500       lrmd:   notice: operation_finished:	fs_DEV_CI_stop_0:21705:stderr [ ocf-exit-reason:Couldn't unmount /usr/sap/DEV/DVEBMGS01; trying cleanup with TERM ]
Feb 07 13:12:33 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:stop call_id:124 pid:21705 exit-code:0 exec-time:1938ms queue-time:0ms
Feb 07 13:12:33 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of stop operation for fs_DEV_CI on vmi243500: 0 (ok) | call=124 key=fs_DEV_CI_stop_0 confirmed=true cib-update=128
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/128)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.12 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.13 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=13
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;48:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=124, @rc-code=0, @op-status=0, @exec-time=1938
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/128, version=1.601.13)
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.13
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.13 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.14 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=14
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=49:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;49:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699953, @last-rc-c
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/137, version=1.601.14)
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.14
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.14 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.15 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=15
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;49:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=95, @rc-code=0, @op-status=0, @exec-time=158, @queue-time=1
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/138, version=1.601.15)
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.15
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.15 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.16 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=16
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']:  <lrm_rsc_op id="fs_DEV_CI_monitor_20000" operation_key="fs_DEV_CI_monitor_20000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="50:16:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;50:16:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" c
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/139, version=1.601.16)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.16 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.17 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=17
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=52:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;52:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699953, @last-r
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/140, version=1.601.17)
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='fs_DEV_CI']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.16
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.17
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.17 2
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.18 (null)
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=18
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;50:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=96, @rc-code=0, @op-status=0, @exec-time=65
Feb 07 13:12:33 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/141, version=1.601.18)
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.18
Feb 07 13:12:33 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.18 2
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.19 (null)
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=19
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;52:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=97, @rc-code=0, @op-status=0, @exec-time=123
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/142, version=1.601.19)
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.19
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.19 2
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.20 (null)
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=20
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']:  <lrm_rsc_op id="vip_DEV_CI_monitor_10000" operation_key="vip_DEV_CI_monitor_10000" operation="monitor" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="53:16:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="-1:193;53:16:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/143, version=1.601.20)
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.20 2
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.21 (null)
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=21
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: create lrm_resource[@id='vip_DEV_CI']
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_start_0, @operation=start, @crm-debug-origin=do_update_resource, @transition-key=54:16:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;54:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612699953, @last-r
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.20
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/144, version=1.601.21)
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.21
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.21 2
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.22 (null)
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=22
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;53:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=98, @rc-code=0, @op-status=0, @exec-time=63
Feb 07 13:12:34 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/145, version=1.601.22)
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.22
Feb 07 13:12:34 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:12:38 [1679] vmi243500       crmd:     info: throttle_send_command:	New throttle mode: 0000 (was 0001)
Feb 07 13:12:39 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: 7d367c6a26fe6492e6adbb22fb01077a for 1.601.22 (0x55d324c955f0 0)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.22 2
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.23 (null)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=23
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:7;54:16:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=99, @rc-code=7, @op-status=0, @exec-time=51177
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']:  <lrm_rsc_op id="rsc_DEV_CI_last_failure_0" operation_key="rsc_DEV_CI_start_0" operation="start" crm-debug-origin="do_update_resource" crm_feature_set="3.1.0" transition-key="54:16:0:24d705d1-0549-478b-9776-868390dd465b" transition-magic="0:7;54:16:0:24d705d1-0549-478b-9776-868390dd465b" exit-reason="" on_node="vmi243493" call-id=
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/146, version=1.601.23)
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.23
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting fail-count-rsc_DEV_CI#start_0[vmi243493]: (null) -> INFINITY from vmi243493
Feb 07 13:13:25 [1677] vmi243500      attrd:     info: attrd_peer_update:	Setting last-failure-rsc_DEV_CI#start_0[vmi243493]: (null) -> 1612700005 from vmi243493
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.23 2
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.24 (null)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=24
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']:  <nvpair id="status-96317541-fail-count-rsc_DEV_CI.start_0" name="fail-count-rsc_DEV_CI#start_0" value="INFINITY"/>
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/16, version=1.601.24)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.24 2
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.25 (null)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=25
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	++ /cib/status/node_state[@id='96317541']/transient_attributes[@id='96317541']/instance_attributes[@id='status-96317541']:  <nvpair id="status-96317541-last-failure-rsc_DEV_CI.start_0" name="last-failure-rsc_DEV_CI#start_0" value="1612700005"/>
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/attrd/17, version=1.601.25)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.25 2
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.26 (null)
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=26
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @operation_key=rsc_DEV_CI_stop_0, @operation=stop, @transition-key=4:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;4:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612700005, @last-rc-change=1612700005, @exec-time=0
Feb 07 13:13:25 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/150, version=1.601.26)
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.26
Feb 07 13:13:25 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:30 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: be9326892d97421746886f0e079550de for 1.601.26 (0x55d324c955f0 0)
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.26 2
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.27 (null)
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=27
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='rsc_DEV_CI']/lrm_rsc_op[@id='rsc_DEV_CI_last_0']:  @transition-magic=0:0;4:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=100, @rc-code=0, @op-status=0, @exec-time=18243
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/151, version=1.601.27)
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='rsc_DEV_CI_last_0']
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.27
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.27 2
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.28 (null)
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=28
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_stop_0, @operation=stop, @transition-key=51:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;51:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612700023, @last-rc-change=1612700023, @exec-time=0
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/152, version=1.601.28)
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.28
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.28 2
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.29 (null)
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=29
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;51:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=102, @rc-code=0, @op-status=0, @exec-time=93
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/153, version=1.601.29)
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.29
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.29 2
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.30 (null)
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=30
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_stop_0, @operation=stop, @transition-key=48:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;48:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612700023, @last-rc-change=1612700023, @exec-time=0, @queue-t
Feb 07 13:13:43 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/154, version=1.601.30)
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.30
Feb 07 13:13:43 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.30 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.31 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=31
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='96317541']/lrm[@id='96317541']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;48:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=104, @rc-code=0, @op-status=0, @exec-time=1469
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243493/crmd/155, version=1.601.31)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.31
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=49:18:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_start_0
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:fs_DEV_CI action:start call_id:125
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/129)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.31 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.32 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=32
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @operation_key=fs_DEV_CI_start_0, @operation=start, @transition-key=49:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;49:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612700025, @last-rc-change=1612700025, @exec-time=0
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/129, version=1.601.32)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.32
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:fs_DEV_CI action:start call_id:125 pid:23885 exit-code:0 exec-time:129ms queue-time:0ms
Feb 07 13:13:45 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for fs_DEV_CI on vmi243500: 0 (ok) | call=125 key=fs_DEV_CI_start_0 confirmed=true cib-update=130
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/130)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.32 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.33 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=33
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_last_0']:  @transition-magic=0:0;49:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=125, @rc-code=0, @op-status=0, @exec-time=129
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/130, version=1.601.33)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_last_0']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.33
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=50:18:0:24d705d1-0549-478b-9776-868390dd465b op=fs_DEV_CI_monitor_20000
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=52:18:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_start_0
Feb 07 13:13:45 [1676] vmi243500       lrmd:   notice: log_execute:	executing - rsc:vip_DEV_CI action:start call_id:127
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/131)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/132)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.33 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.34 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=34
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-key=50:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;50:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612700025, @exec-time=0
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.34
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/131, version=1.601.34)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.34 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.35 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=35
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @operation_key=vip_DEV_CI_start_0, @operation=start, @transition-key=52:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;52:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-run=1612700025, @last-rc-change=1612700025, @exec-time=0
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/132, version=1.601.35)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.35
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for fs_DEV_CI on vmi243500: 0 (ok) | call=126 key=fs_DEV_CI_monitor_20000 confirmed=false cib-update=133
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/133)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.35 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.36 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=36
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='fs_DEV_CI']/lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']:  @transition-magic=0:0;50:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=126, @rc-code=0, @op-status=0, @exec-time=71
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/133, version=1.601.36)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='fs_DEV_CI_monitor_20000']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.36
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1676] vmi243500       lrmd:   notice: log_finished:	finished - rsc:vip_DEV_CI action:start call_id:127 pid:23948 exit-code:0 exec-time:128ms queue-time:0ms
Feb 07 13:13:45 [1679] vmi243500       crmd:   notice: process_lrm_event:	Result of start operation for vip_DEV_CI on vmi243500: 0 (ok) | call=127 key=vip_DEV_CI_start_0 confirmed=true cib-update=134
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/134)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.36 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.37 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=37
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_last_0']:  @transition-magic=0:0;52:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=127, @rc-code=0, @op-status=0, @exec-time=128
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/134, version=1.601.37)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_last_0']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.37
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: do_lrm_rsc_op:	Performing key=53:18:0:24d705d1-0549-478b-9776-868390dd465b op=vip_DEV_CI_monitor_10000
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/135)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.37 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.38 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=38
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-key=53:18:0:24d705d1-0549-478b-9776-868390dd465b, @transition-magic=-1:193;53:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=-1, @rc-code=193, @op-status=-1, @last-rc-change=1612700025, @exec-time=0
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/135, version=1.601.38)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.38
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:45 [1679] vmi243500       crmd:     info: process_lrm_event:	Result of monitor operation for vip_DEV_CI on vmi243500: 0 (ok) | call=128 key=vip_DEV_CI_monitor_10000 confirmed=false cib-update=136
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Forwarding cib_modify operation for section status to all (origin=local/crmd/136)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: --- 1.601.38 2
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	Diff: +++ 1.601.39 (null)
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib:  @num_updates=39
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_perform_op:	+  /cib/status/node_state[@id='771304931']/lrm[@id='771304931']/lrm_resources/lrm_resource[@id='vip_DEV_CI']/lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']:  @transition-magic=0:0;53:18:0:24d705d1-0549-478b-9776-868390dd465b, @call-id=128, @rc-code=0, @op-status=0, @exec-time=81
Feb 07 13:13:45 [1674] vmi243500        cib:     info: cib_process_request:	Completed cib_modify operation for section status: OK (rc=0, origin=vmi243500/crmd/136, version=1.601.39)
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: update_cib_stonith_devices_v2:	Updating device list from the cib: modify lrm_rsc_op[@id='vip_DEV_CI_monitor_10000']
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:     info: cib_devices_update:	Updating devices to version 1.601.39
Feb 07 13:13:45 [1675] vmi243500 stonith-ng:   notice: unpack_config:	Watchdog will be used via SBD if fencing is required
Feb 07 13:13:50 [1674] vmi243500        cib:     info: cib_process_ping:	Reporting our current digest to vmi243493: c99009970b751fca5d154b6129b9f393 for 1.601.39 (0x55d324c955f0 0)
